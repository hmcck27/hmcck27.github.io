[ { "title": "Spring bean 중복 해결(2)", "url": "/posts/Spring-Bean-%EC%A4%91%EB%B3%B5-%ED%95%B4%EA%B2%B0(2)/", "categories": "", "tags": "", "date": "2022-04-15 00:00:00 +0800", "snippet": "Spring Bean 중복 해결 (2)앞서서 spring bean이 중복되는 상황 해결을 위한 여러가지 방법에 대해서 알아보았다. @Autowired의 필드명 매칭 @Autowired의 생성자 파라미터 매칭 @Qualifier 사용 @Qualifier와 @Primary 사용결국 우리가 유용하게 사용하게 되는 방법은 3번과 4번이다.직접 빈 네임 이외에도 빈을 구분하는 구분자를 추가로 만들어주기 때문에,더욱 자유도가 높다고 할 수 있다.예를 들어서 1,2번은 직접 생성자나 변수 선언의 코드를 건드리지만, 3번과 4번은 코드 수정에서 조금 더 자유롭기 때문이다.하지만 3번 4번을 사용하게 되면 하나의 문제점이 존재한다.바로 빈의 구분자를 string으로 선언하기 때문에 컴파일 타이밍에서 직접 에러를 잡기 어렵다는 점이다.이번에는 이 에러를 잡을 custom한 annotation을 직접 만들어보자.@Componentpublic class MemberServiceImpl implements MemberService { @Autowired public MemberServiceImpl(@Qulifier(&quot;remoteDB&quot;) MemberRepository memberRepository) { this.memberRepository = memberRepository; }}@Component@Qualifier(&quot;memeoryDB&quot;)public class MemoryMemberRepository implements MemberRepository {}@Component@Qualifier(&quot;remoteDB&quot;)public class JdbcMemberRepository implements MemberRepository {}코드를 살펴보면 우리가 하나의 인터페이스를 구현하는 두개의 구현체를 동시에 구현했었다.원래는 동일한 이름의 스프링 빈이 생성되면 에러가 발생하나,qualifier를 통해서 빈이름을 제외하고도 빈을 구분하는 구분자를 추가로 구현하였다.결국에는 빈을 주입할때, @Qualifier를 통해서 중복되는 빈중 어떤 빈을 사용할지 명시할 수 있었다.하지만 결국에 @Qualifier를 사용하는 방법은 다음과 같다.@Autowiredpublic MemberServiceImpl(@Qulifier(&quot;remoteDB&quot;) MemberRepository memberRepository) { this.memberRepository = memberRepository;}즉 @Qualifier의 내부 파라미터로 들어가는 string은 컴파일 타임에서 type check가 되지 않는다.따라서 아예 string을 제외한 annotation을 추가로 만들면 해결된다.@Target({ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER, ElementType.TYPE, ElementType.ANNOTATION_TYPE})@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@Qualifier(&quot;remoteDB&quot;)public @interface RemoteDB {}RemoteDB라는 새로운 annotation을 만든다.그러고 이 annotation에 @Qualifier가 붙는 대상을 명시하고 지속 시간을 명시하는 @Target, @Retention을 똑같이 붙인다.당연히 @Inherited랑 @Documented도 붙인다.그리고 해당 annotation이 @Qualifier의 역할을 동일하게 수행할 수 있도록 @Qualifier도 추가한다.그러면 이제 @RemoteDB라는 annotation은 @Qualifier의 역할을 동일하게 수행하고, 추가로 @Qualifier의 파라미터인 “remoteDB”을 아예붙임으로써 이제는 컴파일 타이밍에서 사전에 에러를 방지할 수 있다.다음과 같은 사용하면 된다.RemoteDB@Autowiredpublic MemberServiceImpl(@RemoteDB MemberRepository memberRepository) { this.memberRepository = memberRepository;}이렇게 붙임으로써 해당 생성자를 통해서 의존관계를 주입할때 jdbcMemberRepository를 사용할 것임을 명시할 수 있다.그리고 개발자가 직접 @Qualifier의 파라미터 스트링을 작성하지 않기 때문에 오타가 발생해도 컴파일 타이밍에 바로 에러를 잡을 수 있다.정리하지만 너무 남발하지는 말자 !이것도 관리의 일환이 되버리거나 개발자가 annotation을 follow하지 못하는 경우가 있을 수 있다…!" }, { "title": "Spring bean scope", "url": "/posts/spring-bean-scope/", "categories": "", "tags": "", "date": "2022-04-11 00:00:00 +0800", "snippet": "Spring bean Scope이전 ioc에 대해 알아보면서 간단하게 scope가 뭔지, 어떤 종류가 있는지 알아보았다.좀 더 자세하게 정리해보자 !!가장 먼저 bean의 scope는 다음과 같다. Singleton prototype request session우리가 가장 흔하게 사용하는 scope는 당연히 singleton이다.아무런 설정을 하지 않으면 spring은 자동으로 bean을 singleton으로 생성, 관리한다.하지만 우리가 명시적으로 scope를 지정할 수도 있다.다음과 같은 방식이다.@Scope(&quot;prototype&quot;)@Componentpublic class HelloBean {}만약 component scan을 사용한다면,bean으로 선언하고 싶은 클래스위에 @Scope annotation과 원하는 scope를 설정해서 붙여주면 된다.이제 각 scope의 특징을 한번 정리해보자.singletonspring container는 아무런 설정을 하지 않은 bean은 자동으로 singleton으로 설정한다.이 singleton bean은 말그대로 singleton이다.application context가 load되면서 container가 한번 생성을 하게 되고,이렇게 생성된 instance는 singleton으로 관리되기 때문에,client가 해당 instance를 호출하면 새로 생성하는게 아니라기존에 생성해두었던 bean을 application context에서 가져오게 된다.이렇게 만든 singleton은 내부의 변수를 수정하는 메소드를 만들게 되면stateless가 깨지게 되니까 내부 변수를 만든다해도 해당 변수를 수정하는 일을 최대한 지양해야 한다.동시성 문제가 발생하게 되기 때문이다.그리고 spring container의 가장 큰 핵심 역할이 바로 개발자가 직접 해당 bean을 singleton으로 만들지 않아도,자동으로 singleton으로 관리해준다는 것이다.이전에도 알아봤듯이 singleton에는 여러 문제가 있었다. 코드를 구현해줘야 한다. DIP 위반이다. -&amp;gt; 즉 클라이언트 코드가 해당 객체를 부르기 위해서는 구체화된 인스턴스를 가져오기 때문이다. OCP 위빈이다. -&amp;gt; 구체화된 클래스에 의존하기 때문에 사용할 클래스가 바뀌면 인스턴스도 바꿔줘야 한다. 테스트하기 어렵다. 내부 속성을 변경하거나 초기화하기 어렵다. -&amp;gt; 전역에서 관리되기 때문에 함부로 속성을 변경하면 이걸 사용하는 다른 클라이언트 코드들에 문제가 생길 여지가 많다. 유연성이 떨어진다.다음과 같으 문제들이 있었다.하지만 이런 문제들을 해결하는 것이 spring의 가장 큰 장점이다.또 이러한 singleton bean은 생성 의존관계 주입 초기화 callback 사용 소멸 callback 소멸까지의 모든 step을 spring contatiner가 관리해준다.prototypesingleton이 항상 같은 instance를 반환하는 것에 비해서,prototype은 조금 다르다.prototype은 다음과 같은 특징이 있다.client가 prototype bean을 요청하는 순간에 객체를 생성하며,언제나 새로운 객체를 반환해준다.즉 singleton이 늘 하나의 instance로 관리되었지만,prototype은 늘 새로운 객체를 생성하게 된다.prototype bean은 spring container가 모든 bean lifecycle을 책임지지 않는다.생성 - 의존관계 주입 - 초기화 callback까지는 해주지만 그 이후에는 container의 손을 떠나기 때문에,만약에 소멸 callback을 꼭 해줘야 한다면 그 부분은 객체를 호출한 client의 역할이 된다.따라서 뭐 @PreDestroy를 명시해준다고 해도 소멸 callback은 client가 알아서 호출해야 한다.이런 prototype bean은 그냥 알아서 잘 사용하면 큰 문제가 없지만,만약에 singleton bean과 같이 사용하면 문제가 생길 수 있다.예를 들어보자.만약에 어떤 singleton bean의 의존관계 주입에서 prototype bean을 주입한다고 가정해보자.그러면 우리는 당연히 이 singleton의 prototype bean을 호출할때 늘 새로운 bean일거라고 착각하기 쉽다.하지만 singleton bean의 의존관계 주입에서 주입된 prototype bean은 하나이고여러 client가 singleton bean을 통해서 prototype bean을 부른다고 해도이미 singleton이 생성될때 새로 받은 prototype bean이기 때문에늘 생성되는것이 아니다.따라서 이런 문제를 해결하기 위한 방법이 provider이다.provider만약에 singleton bean이 prototype bean을 사용할때마다 새로운 bean을 받고 싶다면우리는 다음과 같은 방법을 사용할 수 있다.static class ClientBean { @Autowired private ApplicationContext ac; public int logic() { PrototypeBean prototypeBean = ac.getBean(PrototypeBean.class); prototypeBean.addCount(); int count = prototypeBean.getCount(); return count; } }코드를 보면 logic()이라는 함수를 실행할때마다 우리는 application context에서 새롭게 bean을 조회한다.우리가 prototype bean은 조회될때마다 새로 생성된다고 했으니이렇게 코드를 작성하면 singleton bean에서 logic()을 호출하면 늘 새로운 bean을 container에게서 받아오게 된다.하지만 이렇게 코드를 작성하는것은 조금 이상하다.이런 방식을 dependency lookup이라고 한다.하지만 이제는 DL은 많이 사용하지 않는다.따라서 provider를 사용하면 이를 해결할 수 있다.일단 문제가 있는 상황부터 먼저 확인해보자.public class PrototypeTest { @Test void singletonClientUsePrototype() { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(ClientBean.class, PrototypeBean.class); ClientBean clientBean1 = ac.getBean(ClientBean.class); int count1 = clientBean1.logic(); assertThat(count1).isEqualTo(1); ClientBean clientBean2 = ac.getBean(ClientBean.class); int count2 = clientBean2.logic(); assertThat(count2).isEqualTo(2); } @Scope(&quot;singleton&quot;) static class ClientBean { private final PrototypeBean prototypeBean; @Autowired public ClientBean(PrototypeBean prototypeBean) { this.prototypeBean = prototypeBean; } public int logic() { prototypeBean.addCount(); int count = prototypeBean.getCount(); return count; } } @Scope(&quot;prototype&quot;) static class PrototypeBean { private int count = 0; public void addCount() { count++; } public int getCount() { return this.count; } @PostConstruct public void init() { System.out.println(&quot;PrototypeBean.init &quot; + this); } }}코드를 보면,singleton bean이 prototype bean을 사용하고 있다. 테스트 코드에서는 client bean을 두개 받은 다음에, 둘은 singleton이기 때문에같은 인스턴스이다.각 client에서 logic()를 호출을 하게된다.이때 이미 singleton이 갖고 있는 prototype은 새로 다시 생성되는게 아니기 때문에,singleton의 생성 시점에 한번 생성되고 쭉 유지되는 마치 그냥 변수와 같다.따라서 우리가 원하는 작동 방식인 1, 1로 값이 나오지 않는다.만약에 우리가 provider를 사용해서 늘 호출할때마다 새로운 prototype bean을 생성하게 하고 싶다면다음과 같이 코드를 작성하면 된다.public class PrototypeTest { @Test void singletonClientUsePrototype() { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(ClientBean.class, PrototypeBean.class); ClientBean clientBean1 = ac.getBean(ClientBean.class); int count1 = clientBean1.logic(); assertThat(count1).isEqualTo(1); ClientBean clientBean2 = ac.getBean(ClientBean.class); int count2 = clientBean2.logic(); assertThat(count2).isEqualTo(1); } @Scope(&quot;singleton&quot;) static class ClientBean { @Autowired private ObjectProvider&amp;lt;PrototypeBean&amp;gt; prototypeBeanProvider; public int logic() { PrototypeBean prototypeBean = prototypeBeanProvider.getObject(); prototypeBean.addCount(); int count = prototypeBean.getCount(); return count; } } @Scope(&quot;prototype&quot;) static class PrototypeBean { private int count = 0; public void addCount() { count++; } public int getCount() { return this.count; } @PostConstruct public void init() { System.out.println(&quot;PrototypeBean.init &quot; + this); } }}코드를 보면, singleton 내부에서는 ObjectProvider를 사용한다.그리고 logic()을 수행할때마다 늘 이 provider에서 새로운 prototype bean을 가져오게 된다.이때 getObject()를 수행하면 그때 spring container에게서 새로운 prototype instance를 받아서 반환해주게 되기 때문에우리가 의도한 대로 1,1의 결과값을 받을 수 있다.여기서 provider대신에 factory를 사용해도 된다.provider는 factory를 상속받고 좀 더 다양한 stream 기능이라던지를 제공해준다.하지만 두가지 방법다 spring 에 의존적이다.provider나 factory나 둘다 오로지 spring container에 접근해서 bean을 조회하는 것을 대리하는 기능이기 때문이다.따라서 우리가 spring에서 더 독립적인 provider를 사용하고 싶다면다음과 같은 방식이 가능하다.@Scope(&quot;singleton&quot;) static class ClientBean { @Autowired private Provider&amp;lt;PrototypeBean&amp;gt; prototypeBeanProvider; public int logic() { PrototypeBean prototypeBean = prototypeBeanProvider.get(); prototypeBean.addCount(); int count = prototypeBean.getCount(); return count; }}javax.inject의 provider를 사용하게 되면,좀더 spring에서 독립적으로 provider 패턴을 사용할 수 있다.Web Scopeweb 환경에서만 동작하는 scope이다.spring이 종료까지 다 관리를 해준다.웹 scope의 종류는 다음과 같다. request : http 요청이 들어와서 나갈때까지 유지되는 scope이다. 요청마다 별도의 bean이 생성된다. session : http session과 동일한 scope를 갖는 bean이다. application : 서블릿 컨텍스트와 동일한 scope를 가진다. web socket : 웹 소켓과 동일한 생명주기를 가진다.request scope먼저 request scope를 가진 bean을 언제 활용할까 ??바로 http 요청이 올때마다 로그가 쌓일텐데,tomcat은 요청당 thread를 만들어서 처리한다.이때 thread가 많아져서 요청마다 로그를 구분하기가 힘들어진다면,request scope로 logger를 만들어서 구현하면 된다.-&amp;gt; 옛날에는 이걸 몰라서 로그를 제대로 알아보지 못했던 기억이 난다.@Controller@RequiredArgsConstructorpublic class LogDemoController { private final LogDemoServicce logDemoServicce; private final Provider&amp;lt;MyLogger&amp;gt; myLoggerProvider; @RequestMapping(&quot;log-demo&quot;) @ResponseBody public String logDemo(HttpServletRequest request) { String url = request.getRequestURL().toString(); MyLogger myLogger = myLoggerProvider.get(); myLogger.setRequestUrl(url); myLogger.log(&quot;controller test&quot;); logDemoServicce.logic(&quot;testId&quot;); return &quot;OK&quot;; }}@Component@Scope(&quot;request&quot;)public class MyLogger { private String uuid; private String requestUrl; public void setRequestUrl(String requestUrl) { this.requestUrl = requestUrl; } public void log(String message) { System.out.println(&quot;[&quot; + uuid + &quot;]&quot; + &quot;[&quot; + requestUrl + &quot;]&quot; + message); } @PostConstruct public void init() { uuid = randomUUID().toString(); System.out.println(&quot;[&quot; + uuid + &quot;]&quot; + &quot;request scope bean create: &quot; + this); } @PreDestroy public void close() { System.out.println(&quot;[&quot; + uuid + &quot;]&quot; + &quot;request scope bean close: &quot; + this); }}@Service@RequiredArgsConstructorpublic class LogDemoServicce { private final Provider&amp;lt;MyLogger&amp;gt; myLoggerProvider; public void logic(String id) { MyLogger myLogger = myLoggerProvider.get(); myLogger.log(&quot;service id = &quot;+id); }}코드를 보면 이제 logger클래스는 request의 scope를 갖고 있다.그리고 요청이 올때마다 새로운 logger를 생성하고, logger의 id를 uuid로 구분하기 때문에,이는 요청마다 구분할 수 있는 구분자가 된다.따라서 실제로 log를 찍어보면 다음과 같다.[39d8f7ec-fd19-4ef0-98d4-d496b2ff9bbc]request scope bean create: hello.core.common.MyLogger@1f0bbad5[39d8f7ec-fd19-4ef0-98d4-d496b2ff9bbc][http://localhost:8080/log-demo]controller test[39d8f7ec-fd19-4ef0-98d4-d496b2ff9bbc][http://localhost:8080/log-demo]service id = testId[39d8f7ec-fd19-4ef0-98d4-d496b2ff9bbc]request scope bean close: hello.core.common.MyLogger@1f0bbad5[93ae1fef-decf-4857-919d-6ec19c5b97ba]request scope bean create: hello.core.common.MyLogger@2956bcba[93ae1fef-decf-4857-919d-6ec19c5b97ba][http://localhost:8080/log-demo]controller test[93ae1fef-decf-4857-919d-6ec19c5b97ba][http://localhost:8080/log-demo]service id = testId[93ae1fef-decf-4857-919d-6ec19c5b97ba]request scope bean close: hello.core.common.MyLogger@2956bcba[26fddf2a-5ce5-4ad3-9291-206902f86a2d]request scope bean create: hello.core.common.MyLogger@7e3f6487[26fddf2a-5ce5-4ad3-9291-206902f86a2d][http://localhost:8080/log-demo]controller test[26fddf2a-5ce5-4ad3-9291-206902f86a2d][http://localhost:8080/log-demo]service id = testId[26fddf2a-5ce5-4ad3-9291-206902f86a2d]request scope bean close: hello.core.common.MyLogger@7e3f6487이런식으로 총 요청이 3번있었음을 알수있고 어떤 url에 대한 요청인지도 알 수 있다.물론 log를 이렇게 남기기보다 여러가지 설정과 관심사 분리를 통해서 좀 더 예쁘게 구현할 수 있다. tomcat 로그 날짜별 설정 aop나 interceptor를 통한 로그 구현 등등…다음 시간이 로그를 예쁘게 남기는 방법에 대해서 알아볼 예정이다.그리고 이런 코드를 좀더 발전시킬 수 있는 방법이 있다.proxy를 사용하면 굳이 provider를 사용하지 않아도 된다.코드로 살펴보자.@Component@Scope(value = &quot;request&quot;, proxyMode = ScopedProxyMode.TARGET_CLASS)public class MyLogger { private String uuid; private String requestUrl; public void setRequestUrl(String requestUrl) { this.requestUrl = requestUrl; } public void log(String message) { System.out.println(&quot;[&quot; + uuid + &quot;]&quot; + &quot;[&quot; + requestUrl + &quot;]&quot; + message); } @PostConstruct public void init() { uuid = randomUUID().toString(); System.out.println(&quot;[&quot; + uuid + &quot;]&quot; + &quot;request scope bean create: &quot; + this); } @PreDestroy public void close() { System.out.println(&quot;[&quot; + uuid + &quot;]&quot; + &quot;request scope bean close: &quot; + this); }}이렇게 코드를 작성하면 proxy 객체로 만들 수 있다.jpa에서도 값이 초기회되지 않은 빈 객체를 proxy라고 하는데, 비슷하게 이해하면 될것 같다.그리고 controller와 service의 코드에서 provider를 없에고 기존의 mylogger를 주입받자.우리가 provider를 사용해야 했던 이유는 controller나 service의 경우는 singleton bean이다.따라서 application이 로드되면서 객체를 생성하고 의존관계를 주입하는데,이때 주입하는 객체인 mylogger는 scope가 request이기 때문에 현시점에는 존재하지 않는다.따라서 에러가 발생했다.이번에는 mylogger를 프록시로 만들면 controller나 service에서 객체를 주입받을때, 프록시 객체를 주입받는다.이 프록시객체는 진짜로 요청이 들어오는 내부에서 빈을 요청하는 로직이 들어가 있기 때문에런타임에서 request가 오면 그때 logger를 호출하게 된다." }, { "title": "Bean 생명주기 콜백", "url": "/posts/Bean-%EC%83%9D%EB%AA%85%EC%A3%BC%EA%B8%B0-%EC%BD%9C%EB%B0%B1/", "categories": "", "tags": "", "date": "2022-04-10 00:00:00 +0800", "snippet": "Bean 생명주기 call back지금까지 spring bean을 생성하고, 어떻게 spring이 이 bean을 각자의 의존관계에 맞춰서 주입했는지 알아봤다.하지만 spring bean도 생명주기가 있다.예를 들어서 DBCP나 socket같이 application이 사용할 것들을 미리 만들어두고 application이 종료되는 시점에 안전하게없에듯이 spring bean또한 이런 생명에서 소멸로 이어지는 life cycle이 있다.먼저 간단하게 life cycle을 훑어보자.아 참고로, 이 빈의 life cycle은 singleton bean인 경우에만 적용된다.만약에 singleton bean이 아닌 경우, prototype 등등. 이런경우는 다른 생명주기가 적용된다. spring application load spring application container 생성 spring bean 생성 (객체 생성) spring bean 의존관계 주입 spring bean 초기화 callback spring bean 작동 spring bean 소멸 callback spring container 종료일단 3번과 4번은 동시에 일어날 수 있다.만약에 spring bean의 생성자에서 의존관계 주입이 발생하는 경우, 즉 생성자 주입을 사용하는 경우에는 동시에 일어난다.하지만 생성자 주입도 당연히 생성할 빈이 이미 만들어져 있어야지 주입이 가능하다.초기화라는건 무엇을 의미할까 ?생성과 초기화는 조금 다른 의미이다.생성은 말그대로 객체 생성이고, 초기화는 해당 빈을 사용할 준비를 하는 것이다.그러면 초기화 callback, 소멸 callback은 뭘까 ?? 초기화 callback : bean이 생성되고 의존관계 주입이 끝난후 호출 소멸 callback : bean이 소멸되기 직전에 호출예를 들어보자.public class BeanLifeCycleTest { @Test public void lifeCycleTest() { // 부모는 자식을 담을 수 있다. ConfigurableApplicationContext ac = new AnnotationConfigApplicationContext(LifeCycleConfig.class); NetworkClient client = ac.getBean(NetworkClient.class); ac.close(); } @Configuration static class LifeCycleConfig { @Bean public NetworkClient networkClient() { NetworkClient networkClient = new NetworkClient(); networkClient.setUrl(&quot;http://hello-spring.dev&quot;); return networkClient; } }}public class NetworkClient { private String url; public NetworkClient() { System.out.println(&quot;생성자 호출, url = &quot; + url); connect(); call(&quot;초기화 연결 메시지&quot;); } public void setUrl(String url) { this.url = url; } public void connect() { System.out.println(&quot;connect : &quot; + url); } public void call(String message) { System.out.println(&quot;call : &quot; + url + &quot;message : &quot; + message); } public void disconnect() { System.out.println(&quot;close : &quot; + url); }}NetworkClient라는 클래스는 외부 네트워크와 연결하는 객체의 명세이다.이때 외부 네트워크의 주소와 연결을 미리 해놓고 필요할때마다 사용하는 객체이다.그러면 이 객체에서 초기화란 바로 url을 세팅하고, connect()를 미리 실행하는 단계를 의미한다.lifeCycleTest에서 우리는 @Configuration이 붙은 config 클래스를 대상으로 application context를 만들었다.이 config 클래스에는 NetworkClient라는 클래스를 bean으로 = singleton이다. 생성할 것임을 명시하였고,이 빈 생성자에는 빈 객체를 우선 생성하고 setter를 통해서 객체가 가질 값을 세팅해준다.한번 테스트를 돌려보자.그러면 다음과 같은 로그가 뜬다.생성자 호출, url = nullconnect : nullcall : nullmessage : 초기화 연결 메시지잘 보면, 생성자를 먼저 생성한다.만약에 수정자를 통해서 다른 bean을 주입하는 코드가 존재한다면,당연히 먼저 생성하고 의존관계를 주입하게 된다.하지만 url같은 경우를 살펴보자.우리가 만든 NetworkClient라는 객체가 application 로드하고 나서 자동으로 만들어두고,필요할때마다 사용하는 객체라면,당연히 이 객체의 url 세팅 + connect같은 경우는 초기화에 해당한다.하지만 객체를 생성하는 시점에는 당연히 url은 비어있을 수 밖에 없다.애초에 초기화단계는 객체 생성 -&amp;gt; 의존관계 주입 이후에 발생한다.이 초기화 단계의 코드 = url세팅, connect()실행은 나중에 초기화 callback으로 옮길것이다.config를 읽고 bean의 생성, 의존관계 주입까지 마치고 나서 초기화 callback을 실행한다.초기화 callback, 소멸 callback이 두개의 callback은 interface를 통해서 받을 수 있다. 코드로 살펴보자.public class NetworkClient implements InitializingBean, DisposableBean { private String url; public NetworkClient() { System.out.println(&quot;생성자 호출, url = &quot; + url); } public void setUrl(String url) { this.url = url; } public void connect() { System.out.println(&quot;connect : &quot; + url); } public void call(String message) { System.out.println(&quot;call : &quot; + url + &quot;message : &quot; + message); } public void disconnect() { System.out.println(&quot;close : &quot; + url); } @Override public void afterPropertiesSet() throws Exception { connect(); call(&quot;초기화 연결 메세지&quot;); } @Override public void destroy() throws Exception { disconnect(); }}우리가 초기화 callback을 구현하고 싶다면 다음과 같이 하면된다.먼저 구현하고 싶은 bean을 InitializingBean을 구현하자.그러면 afterPropertiesSet()이라는 함수를 구현하게 되는데,말 그대로 속성들을 세팅하고 난 이후에 실행되는 함수이다.즉 앞서 봤던 객체 생성, 수정자를 통한 의존관계 주입이 끝난 이후에 발생하는 함수이다.따라서 우리가 전에 작성했던 코드에서는 객체를 생성하면서 동시에 connection을 만들고, url을 세팅했다.이는 객체 생성과 초기화를 분리하지 않은 것이고,분리하기 위해서 callback을 직접 구현해서 초기화 callback에는 connect()를 넣고, 소멸 callback에는 disconnect를 넣었다. spring application load spring application container 생성 spring bean 생성 (객체 생성) -&amp;gt; config에서의 bean생성 spring bean 의존관계 주입 -&amp;gt; 코드에는 없지만, setter, constructor를 통해서 다른 빈 주입 spring bean 초기화 callback -&amp;gt; connect() spring bean 작동 spring bean 소멸 callback -&amp;gt; disconnect() spring container 종료이렇게 완성된 것이다.실행해보고 로그를 보자.생성자 호출, url = nullconnect : http://hello-spring.devcall : http://hello-spring.devmessage : 초기화 연결 메세지17:30:58.694 [main] DEBUG org.springframework.context.annotation.AnnotationConfigApplicationContext - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@14ec4505, started on Sun Apr 24 17:30:58 KST 2022close : http://hello-spring.dev생성자 호출에서는 url이 없고, 생성 + 의존관계 주입이 끝나고 나서, afterPropertiesSet에서 connect가 실행된다.그리고 container가 끝나고 나면, destroy가 실행되면서 disconnect가 실행된다.이러면 우리가 의도한 NetworkClient의 생성 라이프 사이클에 잘 맞게 되었다.그런데 좀 깨지만, 이런 초기화, 소멸 콜백은 현재는 잘 사용하지 않는다.왜냐하면 스프링에 너무 종속적이기 때문이다.custom의 가능성이 없다.그래서 좀 더 나은 초기화, 소멸 callback을 구현해보자.Bean()의 파라미터를 통한 초기화, 소멸 callback지정.앞서 봤던 방법이 객체를 구현하고, 메소드의 이름을 자유롭게 주지 못했고, 우리의 코드가 spring에 의존적이었다면,이 방법은 메소드 명도 자유롭게 주고, spring 에 덜 의존적이다.한번 코드로 보자.public class BeanLifeCycleTest { @Test public void lifeCycleTest() { // 부모는 자식을 담을 수 있다. ConfigurableApplicationContext ac = new AnnotationConfigApplicationContext(LifeCycleConfig.class); NetworkClient client = ac.getBean(NetworkClient.class); ac.close(); } @Configuration static class LifeCycleConfig { @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;close&quot;) public NetworkClient networkClient() { NetworkClient networkClient = new NetworkClient(); networkClient.setUrl(&quot;http://hello-spring.dev&quot;); return networkClient; } }}public class NetworkClient{ private String url; public NetworkClient() { System.out.println(&quot;생성자 호출, url = &quot; + url); } public void setUrl(String url) { this.url = url; } public void connect() { System.out.println(&quot;connect : &quot; + url); } public void call(String message) { System.out.println(&quot;call : &quot; + url + &quot;message : &quot; + message); } public void disconnect() { System.out.println(&quot;close : &quot; + url); } public void init() throws Exception { connect(); call(&quot;초기화 연결 메세지&quot;); } public void close() throws Exception { disconnect(); }}앞서 구현했던 코드와는 다르게 NetworkClient는 더이상 interface를 구현하지 않고, 내가 원하는 custom한 초기화, 소멸 메소드만 구현했다.그리고 중요한 점은 config에서 @Bean에서 파라미터로 초기화 메소드, 소멸 메소드를 지정했다.즉, 이런 과정을 통해서 원하는 메소드 이름으로 custom하게 구현이 가능했다.또 가장 큰 장점은 우리가 코드를 고칠 수 없는 외부 라이브러리에도 내가 원하는 초기화, 소멸 메소드를 적용할 수 있다.하지만 이것도 싫다면 결국 자바 개발자들이 가장 좋아하는 어노테이션을 사용해서 초기화, 소멸 메소드를 적용할 수 있다.@PostConstruct, @PreDestroy만약에 bean에서도 직접 초기화, 소멸 메소드를 적용하는것이 싫다면 다음의 방법을 사용하면 된다.public class BeanLifeCycleTest { @Test public void lifeCycleTest() { // 부모는 자식을 담을 수 있다. ConfigurableApplicationContext ac = new AnnotationConfigApplicationContext(LifeCycleConfig.class); NetworkClient client = ac.getBean(NetworkClient.class); ac.close(); } @Configuration static class LifeCycleConfig { @Bean() public NetworkClient networkClient() { NetworkClient networkClient = new NetworkClient(); networkClient.setUrl(&quot;http://hello-spring.dev&quot;); return networkClient; } }}public class NetworkClient{ private String url; public NetworkClient() { System.out.println(&quot;생성자 호출, url = &quot; + url); } public void setUrl(String url) { this.url = url; } public void connect() { System.out.println(&quot;connect : &quot; + url); } public void call(String message) { System.out.println(&quot;call : &quot; + url + &quot;message : &quot; + message); } public void disconnect() { System.out.println(&quot;close : &quot; + url); } @PostConstruct public void init() throws Exception { connect(); call(&quot;초기화 연결 메세지&quot;); } @PreDestroy public void close() throws Exception { disconnect(); }}코드를 보면 앞에서 했던 방법에서 @Bean에서 원하는 메소드를 지정하지 않았다.그냥 우리가 bean으로 만들 객체에 초기화 메소드는 @PostConstruct, 소멸 메소드에는 @PreDestroy를 지정했다.끝 !! 이렇게 작성하면 간편하게 설정이 가능하다. -&amp;gt; 가장 많이 사용하는 방법이다.이 방법은 최신 스프링에서 권장하는 방법이고,매우 편리하고, 자바 어노테이션이기 때문에 스프링에 종속적이지도 않다.컴포넌트 스캔과도 잘 어울린다. 직접 등록하는게 아니다.유일한 단점은 외부 라이브러리에 적용을 못한다는 점이다." }, { "title": "Http https", "url": "/posts/http-https/", "categories": "", "tags": "", "date": "2022-04-08 00:00:00 +0800", "snippet": "Http와 Https의 차이이번에 한번 http와 https의 차이를 정리해보자 !Http란 ?Hyper Text Transfer Protocolhttp는 클라이언트/서버의 데이터를 주고받기 위한 프로토콜이다. application layer(tcp/ip위의)에서 적용되는 프로토콜이다.특징 80번 포트 사용 stateless하다 비암호화구조 Method : GET / POST / PUT / DELETE Path : / /student version of protocol : HTTP/1.1 HTTP2하지만 http는 암호화되지 않은 평문이다.데이터를 담아서 전송하면 제 3자가 조회가 가능하다.Https란 ?Hyper Text Transfer Protocol SecureHTTP에 데이터 암호화가 추가되었다.특징 443포트 사용 대칭키 암호화, 비대칭키 암호화 사용대칭키 암호화란 ? 클라이언트와 서버가 동일한 키를 사용해서 암호화/복호화한다. 키가 노출되면 위험하지만 그만큼 연산 속도가 빠르다.비대칭키 암호화란 ? 1개의 쌍으로 구성된 공개키와 개인키를 암호화/복호화하는데 사용한다. 키가 노출되어도 안전하지만 연산속도가 느리다.공개키란 ? 모두에게 공개가능한 키개인키란 ? 나만 갖고 있는 키공개키 암호화란 ? 공개키로 암호화하고 개인키로만 복호화가 가능하다.개인키 암호화란 ? 개인키로 암호화하고 공개키로 복호화가 가능하다.Https 동작과정 hand-shaking이 선행된다. 서버와 클라이언트간의 세션키를 교환한다. 여기서 세션키는 주고 받는 데이터를 암호화하기 위한 대칭키이다. 데이터간의 교환에는 빠른 연산 속도가 필요하다. session key 교환은 비대칭키 사용. 처음 연결을 성립하여 안전하게 세션키를 공유하는 과정에서 비대칭키로 암호화한다. 즉 세션키 자체를 공유하는 과정은 비교적 연산은 느리지만 안전하게 진행하는 것이다.https 연결과정 클라이언트가 서버로 최초 연결시도 서버는 공개키로 된 인증서를 브라우저에게 넘겨줌 브라우저는 인증서의 유효성을 검증하고, 세션키를 발급 서버의 공개키로 세션키를 암호환후 서버로 전송 서버는 세션키를 서버의 개인키로 복호화해서 세션키를 얻음 클라이언트와 서버는 동일한 세션키를 공유하고 앞으로의 전송에서 세션키로 암호화/복호화를 진행.HTTPS의 발급과정일반적으로 서버는 클라이언트에게 보내줄 공개키를 생성해야 하는데,이걸 인증된 기관에게 받는다. 내 서버에서 개인키와 공개키를 미리 발급함 acm같은 인증서 발급 기관에게 돈을 지불하고 공개키를 저장하는 인증서를 받음 acm은 인증서를 생성하고 acm의 개인키로 암호화함. 내 서버는 인증서를 클라이언트에게 전달 클라이언트는 공개키를 통해서 복호화해서 공개키를 얻음" }, { "title": "Context switching", "url": "/posts/context-switching/", "categories": "", "tags": "", "date": "2022-04-08 00:00:00 +0800", "snippet": "Context Switching컴퓨터는 동시에 하나만 할 수 있다 !하지만 실제로 사용하다보면 유저입장에서는 동시에 여러 task들이 처리되고 있는것 처럼 느껴진다.그렇게 느껴지는 이유가 바로 context switching이다.컴퓨터는 여러 프로세스를 갖고 있고, 프로세스는 여러 thread를 갖고 있다.이걸 바로 멀티 프로세스 환경이라고 하는데,문제는 cpu는 하나의 프로세스만 실행가능하다.중간에 interupt라는 요청에 의해서 cpu는 계속해서 실행하고 있는 process를 교체하게 된다.즉 우리에게 여러가지가 동시에 일어나고 있는것 처럼 보이지만실제로는 cpu가 실행하고 있는 작업이 눈치채지 못할만큼 빠른 속도로 작업들을 교체하면서 실행하고 있는 것이다.이 교체의 작업의 context switching이라고 한다.자세하게 설명하면,멀티프로세스 환경에서 cpu가 하나의 프로세스를 실행하고 있는 상태에서 interupt 요청에 의해 다음 순위의 프로세스를 실행하게 될때,기존 프로세스의 상태 또는 register 값을 저장하고, cpu가 다음 프로세스를 수행하도록 새로운 프로세스의 상태 또는 register값을 교체하는 작업을 의미한다.Context란 무엇인가 ?문맥, 상태라는 번역이 되지만 os에서는 cpu가 프로세스를 실행하기 위한 해당 프로세스의 정보를 말한다.이 context는 프로세스의 pcb에 저장이 된다.PCBpcb는 무엇을 저장하고 있을까 ? 프로세스의 상태 : 생성, 준비, 수행, 대기, 중지 프로그램 카운터 : 프로세스가 다음에 수행할 명령어의 위치 레지스터 : 누산기, 스택, 색인 레지스터 프로세스 번호Interruptinterrupt란 cpu가 프로그램을 실행하고 있을때, 실행중인 프로그램 밖에서 예외상황이 발생해서 처리가 필요한 경우 발생한다.다음과 같은 종류가 있다. I/O request (입출력 요청할 때) time slice expired (CPU 사용시간이 만료 되었을 때) fork a child (자식 프로세스를 만들 때) wait for an interrupt (인터럽트 처리를 기다릴 때)Scheduling위에서 cpu가 처리하길 기다리는 프로세스들이 있고, 프로세스들간의 우선순위가 있다고 했다.중요한건 이 우선순위를 정하는 것을 scheduling이라고 하고,해당 scheduling은 여러가지 알고리즘이 있다.가장 대표적인 round robin으로 정해진 시간만큼을 두고 cpu가 실행하고 시간이 끝나면 다음 순위의 프로세스를 실행하는 알고리즘이다.이 시간 단위가 적으면 context switching이 그만큼 자주 발생하게 된다.정리context switching이 너무 자주 발생하면 좋지 않다.이 과정 자체에도 리소스와 시간이 소요되기 때문이다." }, { "title": "Spring bean 중복해결", "url": "/posts/Spring-Bean-%EC%A4%91%EB%B3%B5%ED%95%B4%EA%B2%B0/", "categories": "", "tags": "", "date": "2022-04-07 00:00:00 +0800", "snippet": "Spring Bean 중복 해결spring bean은 singleton으로 유지된다.DI container는 각 interface를 구현한 구현체 클래스를 spring bean으로 등록하게 되는데,의존성을 주입해줄 때는 구현체가 아니라 interface기준으로 주입하게 된다.중복을 허용하되 필요한 빈은 1개.하나의 interface를 두개의 빈이 동시에 구현하게 하고 싶다면 어떻게 해야할까 ?예를 들어보자.@Configuration@ComponentScanpublic class AutoAppConfig {}@Component@RequiredArgsConstructorpublic class MemberServiceImpl implements MemberService { private final MemberRepository memberRepository;}@Componentpublic class MemoryMemberRepository implements MemberRepository {}@Componentpublic class JdbcMemberRepository implements MemberRepository {}만약 이런 상황에서 autoappconfig를 읽고 component scan을 한다고 가정하자.그러면 MemberServiceImpl을 spring bean으로 올리고, 해당 bean이 의존하는 MemberRepository를 주입하게 된다.하지만 현재 상황은 memberRepository의 구현체가 두개이다.둘다 spring bean으로 올라가 있는 상황에서 어떤 구현체에 의존할것인지명확하지 않은 상황이고, 결국에 spring은 다음과 같은 error를 뱉는다.NoUniqueBeanDefinitionException: No qualifying bean of type &#39;MemberRepository&#39; available: expected single matching bean but found 2: jdbcMemberRepository,memoryMemberRepository즉 single을 예상했는데 2개의 bean을 찾았고, 어떤것을 채택하지 몰라 에러가 발생한 것이다.이런 상황에서는 3개의 해결 방법이 있다. @Autowired의 필드명 매칭```java@Componentpublic class MemberServiceImpl implements MemberService { @Autowired private MemberRepository jdbcMemberRepository;} @Componentpublic class MemoryMemberRepository implements MemberRepository {}@Componentpublic class JdbcMemberRepository implements MemberRepository {}다음과 같이 MemberServiceImpl이 의존하는 구현체를 @Autowired를 통해서 직접 엮어준다. @Autowired는 필드명을 보고 필요한 인스턴스를 주입해준다. DI container는 일단 interface = 타입을 보고 먼저 bean을 찾고, 만약에 해당하는 bean이 여러개라면 필드이름으로 bean을 찾는다.2. @Autowired를 이용한 생성자 파라미터 매칭```java@Componentpublic class MemberServiceImpl implements MemberService { @Autowired public MemberServiceImpl(MemberRepository jdbcMemberRepository) { this.memberRepository = jdbcMemberRepository; }}@Componentpublic class MemoryMemberRepository implements MemberRepository {}@Componentpublic class JdbcMemberRepository implements MemberRepository {}생성자를 통한 의존성 주입을 해줄때 파리미터로 구현체를 지정해서 넘기면 자동으로 jdbcMemberRepository가 주입된다. @Qualifier를 통한 매칭@Qualifier는 빈의 추가 구분자를 지정해주는 방식이다.원래 bean은 bean name으로 구분되지만, @Qualifier를 달아주면 해당 bean의 새로운 이름이 하나 더 생긴것과 같다.@Componentpublic class MemberServiceImpl implements MemberService { @Autowired public MemberServiceImpl(@Qulifier(&quot;remoteDB&quot;) MemberRepository memberRepository) { this.memberRepository = memberRepository; }}@Component@Qualifier(&quot;memeoryDB&quot;)public class MemoryMemberRepository implements MemberRepository {}@Component@Qualifier(&quot;remoteDB&quot;)public class JdbcMemberRepository implements MemberRepository {}겹치는 구현체에 @Qualifier를 달아준다.그러면 value로 주어진 name으로 새로운 bean의 구분자가 생성이 되고,만약에 겹치는 경우 내가 원하는 구현체의 Qualifier name을 주면 해당 qualifier를 가진 bean으로 주입한다.만약에 해당 qualifier를 가진 bean이 없다면 qualfier value를 name으로 가진 bean을 다시 찾아본다.그런데도 없으면 당연히 예외가 발생한다. primary bean을 지정.말그래도 여러 bean이 동일한 interface를 구현하고 있는 경우,primary가 붙은 빈이 가장 우선권을 가진다.@Componentpublic class MemberServiceImpl implements MemberService { @Autowired public MemberServiceImpl(MemberRepository memberRepository) { this.memberRepository = memberRepository; }}@Component@Qualifier(&quot;memeoryDB&quot;)public class MemoryMemberRepository implements MemberRepository {}@Component@Primarypublic class JdbcMemberRepository implements MemberRepository {}중복을 허용하되 여러개의 빈이 동시에 필요개발하다보면 동적으로 interface의 구현체를 선택해야 할일이 있다.따라서 빈을 중복으로 등록하고 로직에 따라서 빈을 선택하게 하면 된다.(당연히 중복으로 등록하기 위해서는 @Qualifier 또는 @Primary를 사용해야 한다.)코드로 한번 보자.@Component@Qualifier(&quot;memeoryDB&quot;)public class MemoryMemberRepository implements MemberRepository {}@Component@Primarypublic class JdbcMemberRepository implements MemberRepository {}@Component@RequiredArgsConstructorpublic class SelectRepositoryService{ private final Map&amp;lt;String, MemberRepository&amp;gt; repositoryMap; public MemberRepository selectOne(String code) { MemberRepository memberRepository = repositoryMap.get(code); return memberRepository; }}public enum RepositoryEnum { memoryMemberRepository, jdbcRepository}@RequiredArgsConstructor를 통해서 생성자 주입을 해주는데,문제는 Map&amp;lt;String, MemberRepository&amp;gt;를 주입해준다.현재 스프링이 관리하는 MemberRepository.class의 bean은 두개다.스프링은 자동으로 {bean이름 : repositoryInterface를 가진 bean} 페어를 등록해준다.따라서 selectOne()으로 원하는 repository를 가져올 수 있다.즉 동적으로 저장되는 저장소가 다를경우에 유용하게 사용할 수 있다.정리우리가 여러개의 bean을 띄우는 경우는 있을 수 있다.예를 들어서 로컬에서는 h2 데이터베이스를, 그리고 운영 테스트에서는 원격 postgres를 사용한다고 가정했을때, 두 데이터베이스를 번갈아 끼면서 테스트 한다던지 등등 다양한 상황이 있을 수 있다.즉 구현체를 바꿔끼는 경우가 있는 경우, 혹은 특정한 상황에서만 특정 빈을 이용하는 경우에서는 이렇게 중복되는 빈을 대처하기 위한 방법이 있어야 한다.@Primary와 @Qualifier를 잘 사용해서 조합하면 좋을 것 같다..!또한 의외로 동적으로 관리하는건 많이 사용되는 것 같다..!-&amp;gt; 지금 내가 짠 코드에서 수정할 부분이 스쳐지나간다.스프링이 제공해주는 전략패턴을 잘 활용해보자." }, { "title": "Python sort활용법", "url": "/posts/python-sort%ED%99%9C%EC%9A%A9%EB%B2%95/", "categories": "", "tags": "", "date": "2022-04-06 00:00:00 +0800", "snippet": "python sort 활용법기본적인 sort활용법은 다음과 같다.list.sort()list = sorted(list)파이썬에서 제공하는 sort는 다양하게 활용가능하다. reverse로 sort하기 list.sort(reverse=True) 위와 같이 reverse인자를 true로 주면, 원래의 sort방향(증가하는 방향)의 역순으로 정렬이 된다. key를 주고 sort하기만약에 다음과 같은 list가 있다고 가정하자. list = [[1,2], [1,9], [8,2], [5,5]] 이런 상황에서 list의 원소인 개별 list의 첫번째 원소를 기준으로 정렬할 수 있다. list = [[1,2], [1,9], [8,2], [5,5]]list.sort(key=lamdba x:x[0]) custom한 기준으로 sort하기reverse, key를 통해서 정렬하기 보다 더욱 custom한 기준으로 정렬하고 싶다면 어떻게 해야 할까 ?예를 들어서 list의 첫번째 원소는 내림차순, 첫번째 원소가 같다면 두번째의 원소를 오름차순으로 정렬하기…이런 경우는 python의 cmp변수를 활용하면 된다.key로 넘기는 parameter로 functools.cmp_to_key를 넘기면 된다.예시를 보자.def compare(a,b): if a[0] &amp;gt; b[0]: return 1 elif a[0] &amp;lt; b[0]: return -1 else: if a[1] &amp;lt; b[1]: return -1 elif a[1] &amp;gt; b[1]: return 1 else: return 0list = [[1,2], [1,9], [8,2], [5,5]]list.sort(key=cmp_to_map(compare))cmp_to_map의 인자로 넘겨주는 함수는 다음과 같이 구현하면 된다. a,b가 순서대로 있을때, a[0]이 b[0]보다 더 큰 경우는 1을 반환 -&amp;gt; a가 앞으로 간다. 내림차순 b[1]가 a[1]보다 큰 경우는 -1을 반환 -&amp;gt; b가 뒤로 간다. 오름차순 같은 경우에는 0을 반환즉 cmp_to_map함수의 파라미터로 들어가는 함수는 1,-1,0 셋중 하나를 반환하면 된다.그리고 1은 앞으로 가는 경우,-1은 뒤로 가는 경우,0은 그대로 유지하는 경우세가지 경우를 신경써서 구현하면 된다." }, { "title": "controller 파라미터 map -&gt; dto 변환과정", "url": "/posts/DTO%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B0%9B%EA%B8%B0/", "categories": "Java", "tags": "Java, Annotation, Jackson", "date": "2022-04-06 00:00:00 +0800", "snippet": "제목은 DTO로 데이터 받기지만 실제로는 다음과 같은 상황을 해결하는 과정이다.상황 ajax를 통한 통신 GET controller에서는 Map으로 받고 있는 상황 view의 json 코드의 네이밍 컨벤션 엉망(snake, camel, 대문자 혼재..)다음과 같은 상황에서 controller에서 받는 parameter를 dto로 수정하는 일이었다….일단은 왜 이게 난감한 상황인지 정리해보자. GETGET방식으로 데이터를 보내면 @RequestBody로 데이터를 받을 수 없다.애초에 json으로 오지 않는다. 혼재된 네이밍 query string으로 오는 데이터들이 네이밍이 다 혼재되어있다.{ &quot;MY_NAME : &quot;jk&quot;, &quot;_csrf&quot; : &quot;asdfasdf&quot;, &quot;yourName&quot; : &quot;jk2&quot;}그러면 controller와 dto는 다음과 같아야 한다.@RequestMapping(value = &quot;/my/name&quot;)@ResponseBodypublic Map&amp;lt;String, Object&amp;gt; MyName(MyDto dto) throws Exception {}@Datapublic class MyDto { private String MY_NAME; private String yourName;}이 상황의 문제점을 보자.Get이기 때문에 일단 @RequestBody를 사용하지 못한다.그리고 dto는 네이밍이 혼재되어 있다….이런 dto는 getter, setter를 설정하거나, 변수를 사용하게 되면 완전히 어플리케이션 영역의 네이밍 컨벤션이 깨진다.일단 처음 생각한 방법은 다음과 같았다. view의 모든 data의 네이밍 컨벤션을 바꾼다.-&amp;gt; 진짜 말도 안된다…. 이건 노가다의 영역이고 디버깅도 하려면 한참걸릴거다. view의 GET을 전부 POST로 수정하고 @RequestBody + @JsonNaming의 조합으로 해결한다.-&amp;gt; view 코드를 건드리기는 싫었다. 난 view 전문가도 아니고 이것도 결국은 노가다다.여기서 포기하고 노가다를 할까 싶었지만 custom annotation을 만든다면 해결할 수 있다. GET은 유지한다. requestDto는 전부다 camelCase로 작성한다. Custom annotation을 만든다. 이 annotation은 controller의 파라미터에 붙을 것이다. HandlerMethodArgumentResolver를 새롭게 구현한다. PropertyNamingStrategy을 상속받아서 대문자, 소문자 snake_case를 camelCase로 변환하도록 한다.(정확히 말하면 역변환)따라서 다음과 같이 수정가능했다. DTO@Data@JsonNaming(UpperSnakeCaseStrategy.class)public class MyDto { private String myName; private String yourName;} PropertyNamingStrategy를 상속받은 custom 변환기public class UpperSnakeCaseStrategy extends PropertyNamingStrategy.PropertyNamingStrategyBase { public static final PropertyNamingStrategy UPPER_SNAKE_CASE = new UnderCamelCaseToUpperSnakeCase(); @Override public String translate(String input) { if (input == null) return input; // garbage in, garbage out int length = input.length(); StringBuilder result = new StringBuilder(length * 2); int resultLength = 0; boolean wasPrevTranslated = false; for (int i = 0; i &amp;lt; length; i++) { char c = input.charAt(i); if (i &amp;gt; 0 || c != &#39;_&#39;) // skip first starting underscore { if (Character.isUpperCase(c)) { if (!wasPrevTranslated &amp;amp;&amp;amp; resultLength &amp;gt; 0 &amp;amp;&amp;amp; result.charAt(resultLength - 1) != &#39;_&#39;) { result.append(&#39;_&#39;); resultLength++; } c = Character.toUpperCase(c); wasPrevTranslated = true; } else { wasPrevTranslated = false; } result.append(Character.toUpperCase(c)); resultLength++; } } return resultLength &amp;gt; 0 ? result.toString() : input; }} Custom Annotation@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.PARAMETER)public @interface QueryStringArgsResolver {}// runtime으로 해야지 말그래도 runtime에 유지된다.// Parameter로 설정한다. Controller 수정@RequestMapping(value = &quot;/my/name&quot;)@ResponseBodypublic Map&amp;lt;String, Object&amp;gt; MyName(@QueryStringArgsResolver MyDto dto) throws Exception {}```javaqueryString을 통해서 즉 GET으로 받는 데이터들을 감쌀 dto 앞에 어노테이션을 붙인다. 4. HandlerMethodArgumentResolver 구현 1. annotion이 붙은 method parameter인 경우에 동작 2. 기존의 queryString을 jsonObject으로 변환 3. jsonObject에서 _csrf는 제거 4. 다시 stringify한다 5. ObjectMapper를 통해서 dto로 변환 ```java@Componentpublic class QueryStringArgumentResolver implements HandlerMethodArgumentResolver { @Override public boolean supportsParameter(final MethodParameter methodParameter) { return methodParameter.getParameterAnnotation(QueryStringArgsResolver.class) != null; } @Override public Object resolveArgument(final MethodParameter methodParameter, final ModelAndViewContainer modelAndViewContainer, final NativeWebRequest nativeWebRequest, final WebDataBinderFactory webDataBinderFactory) throws Exception { final HttpServletRequest request = (HttpServletRequest) nativeWebRequest.getNativeRequest(); final String json = qs2json(request.getQueryString()); JSONObject jObject = new JSONObject(json); if (jObject.has(&quot;_csrf&quot;)) { jObject.remove(&quot;_csrf&quot;); } ObjectMapper objectMapper = new ObjectMapper(); String s = jObject.toString(); final Object a = objectMapper.readValue(s, methodParameter.getParameterType()); System.out.println(&quot;a = &quot; + a); return a; } private String qs2json(String a) { String res = &quot;{\\&quot;&quot;; for (int i = 0; i &amp;lt; a.length(); i++) { if (a.charAt(i) == &#39;=&#39;) { res += &quot;\\&quot;&quot; + &quot;:&quot; + &quot;\\&quot;&quot;; } else if (a.charAt(i) == &#39;&amp;amp;&#39;) { res += &quot;\\&quot;&quot; + &quot;,&quot; + &quot;\\&quot;&quot;; } else { res += a.charAt(i); } } res += &quot;\\&quot;&quot; + &quot;}&quot;; return res; }}이러면 원하는 방식으로 작동한다.전체적인 흐름을 먼저 보면 view에서 ajax호출 @QueryStringArgsResolver를 통해서 query string -&amp;gt; json object -&amp;gt; dto로의 변환 실제 obejctmapper의 string to json 변환시에는 @JsonNaming 규칙으로 변환이러면 어떤 혼재된 형태의 query string이던 잘 처리가능하다…추가적으로는 objectmapper를 빈으로 만들어서 사용하면 좋겠고,_csrf를 빼는 과정으로 좀 더 복잡하겠지만 효율적으로 구성할 수 있다.그건 내일 해야지…." }, { "title": "Dto to Map, with naming convention", "url": "/posts/DtoToMap/", "categories": "Java", "tags": "Java, Annotation, Jackson", "date": "2022-04-05 00:00:00 +0800", "snippet": "이번에 개발하다가,심각한 문제점을 발견했다.우리 서비스는 spring mvc모델인데 다음과 같은 방식으로 구현되어 있다. rest api -&amp;gt; @ResponseBody를 통해서 반환 modelandview에 담아서 mv를 반환하지만 아직 view에서의 변수 네이밍이 일치되지 않은 상황이고,따라서 view에서는 다음과 같은 방식으로 data를 받고 있었다. upper case + snake case lower case + snake case camel case세가지의 경우로 네이밍 컨벤션이 뒤죽박죽이었기 때문에,controller에서 반환하는 map, dto, mv의 네이밍 컨벤션도 뒤죽박죽이었다.일단은 view에서의 수정을 최소화하고 싶기 때문에 다음과 같은 작업이 필요했다. dto를 반환시 내 마음대로 네이밍 컨벤션을 정해서 반환할 수 있어야 했다. mv에 담은 dto 또는 map도 네이밍 컨벤션을 정해서 반환할 수 있어야 했다.return DTO의 경우DTO를 반환하는 경우, @ResponseBody를 사용하게 된다.@ResponseBody는 반환하는 객체를 json으로 변환함을 명시하는 어노테이션이다.이때 반환하는 dto에 @JsonNaming()을 붙이면 json으로 변환시 자동으로 파라미터로 들어가는 클래스에 맞게 변환이 된다.@Data@AllArgsConstructor@JsonNaming(UnderCamelCaseToUpperSnakeCase.class)@NoArgsConstructorpublic class Temp{ private Long seq;}public class UnderCamelCaseToUpperSnakeCase extends PropertyNamingStrategy.PropertyNamingStrategyBase { public static final PropertyNamingStrategy UPPER_SNAKE_CASE = new UnderCamelCaseToUpperSnakeCase(); @Override public String translate(String input) { if (input == null) return input; // garbage in, garbage out int length = input.length(); StringBuilder result = new StringBuilder(length * 2); int resultLength = 0; boolean wasPrevTranslated = false; for (int i = 0; i &amp;lt; length; i++) { char c = input.charAt(i); if (i &amp;gt; 0 || c != &#39;_&#39;) // skip first starting underscore { if (Character.isUpperCase(c)) { if (!wasPrevTranslated &amp;amp;&amp;amp; resultLength &amp;gt; 0 &amp;amp;&amp;amp; result.charAt(resultLength - 1) != &#39;_&#39;) { result.append(&#39;_&#39;); resultLength++; } c = Character.toUpperCase(c); wasPrevTranslated = true; } else { wasPrevTranslated = false; } result.append(Character.toUpperCase(c)); resultLength++; } } return resultLength &amp;gt; 0 ? result.toString() : input; }}UnderCamelCaseToUpperSnakeCase는 직접 구현한 클래스이다.@JsonNaming()의 파라미터로 사용하려면 PropertyNamingStrategy를 상속받아야 한다.translate함수를 override해서 내가 원하는 방식으로 만들면 된다.나같은 경우는 camel case를 Upper case + snake case로 만들어야 했기 때문에위와 같이 클래스를 구성했다.만약에 필요한 네이밍 컨벤션이 있다면 그에 맞게 또 구현하면 된다.mv를 반환하는 경우이러면 이야기가 좀 복잡해진다.mv.addObject(“”, object)에서 object를 반환해야하는데,object는 map이라고 가정하자.그러면 dto에서 map으로 변환하면서 동시에 네이밍 컨벤션을 수정해야 한다.다음과 같이 작성해보자.@Data@AllArgsConstructor@JsonNaming(UnderCamelCaseToUpperSnakeCase.class)@NoArgsConstructorpublic class Temp{ private Long seq; @Override public Map&amp;lt;String, Object&amp;gt; toMap() { try { Field[] fields = this.getClass().getDeclaredFields(); Map&amp;lt;String, Object&amp;gt; results = new HashMap&amp;lt;&amp;gt;(); for (Field field : fields) { results.put(StringUtils.camelToSnake(field.getName(), Boolean.TRUE), field.get(this)); } return results; } catch (IllegalAccessException | IllegalArgumentException e) { return null; } }}public class StringUtils { /** * Converts camel case string (lower or upper/Pascal) to snake case, * for example &#39;helloWorld&#39; or &#39;HelloWorld&#39; -&amp;gt; &#39;hello_world&#39;. * * @param camel Input string. * @param upper True if result snake cased string should be upper cased like &#39;HELLO_WORLD&#39;. **/ public static String camelToSnake(String camel, boolean upper) { StringBuilder stringBuilder = new StringBuilder(); for (char c : camel.toCharArray()) { char nc = upper ? Character.toUpperCase(c) : Character.toLowerCase(c); if (Character.isUpperCase(c)) { stringBuilder.append(&#39;_&#39;).append(nc); } else { stringBuilder.append(nc); } } return stringBuilder.toString(); }}dto에 내부 함수를 통해서 field를 순환하면서 key를 네이밍 컨벤션에 맞게 수정해주고 map을 구성한다.그러면 실제로 사용할때는,Temp.toMap()를 통해서 dto -&amp;gt; (컨벤션을 재정의한)map으로의 변환이 가능하다.만약에 List -&amp;gt; List&amp;lt;Map&amp;gt;으로 변환하고 싶다면 stream()을 이용하면 한줄로 코드가 작성가능하다.List&amp;lt;Temp&amp;gt; temps = tempService.findAll()List&amp;lt;Map&amp;lt;String, Object&amp;gt;&amp;gt; listMap = temps.stream().map(temp -&amp;gt; temp.toMap()).collect(Collectors.toList())끝 ! 여기서는 결국에 view에 맞추기 위해서 controller의 코드가 변경되었는데내 생각에는 그냥 view의 컨벤션과 controller + business logic의 컨벤션을 다 맞추는게 가장 좋아보인다." }, { "title": "Annotation", "url": "/posts/Annotation/", "categories": "Java", "tags": "Java, Annotation", "date": "2022-04-04 00:00:00 +0800", "snippet": "Annotation우리가 자바로 개발하면 필요할때마다 annotation을 사용한다.interface를 만들면 @Override를 사용하게 되고lombok을 사용하면 @Getter, @Setter등을 사용하게 된다.또 validation에서는 @NotNull과 같은 annotation을 사용한다.문제는 @Getter라고 적어준다고 해도 실제 우리 코드에는 get 함수가 구현되어 있지 않다.하지만 난 단순히 code에 annotation을 작성했을 뿐인데,어떻게 실제 코드가 변화할 수 있는건지 의문이 있었다.Annotation이 뭘까 ? Annotation은 metadata이다. 즉 data에 대한 data이다.예를 들어서 다음 코드를 보자. @Overridepublic String toString() {return &quot;This is String Representation of current object.&quot;;} 코드에서 우리는 toString()함수를 override했다.그리고 메소드 위에 @Override를 작성했다.@Override annotation을 붙이지 않아도 물론 override된다.그렇다면 왜 Annotation을 사용하는 걸까 ?@Override는 javac에게 해당 메소드는 override하는 메소드임을 알려준다.즉 메소드에 대한 metadata이다.그리고 만약에 parent class에 override할 method가 없다면 compile 에러를 만든다. 만약에 @Override를 붙이지 않았다면 실제로 parent에 toString()이 있는지 체크하지 않을것이고, 개발자가 원하는 방향 = 이 메소드는 override 메소드야 임을 compiler에서는 알 수가 없다. 물론 compile은 제대로 될겠지만 워하는 방향으로 작동하지 않을 것이다.따라서 왜 annotation을 붙이는지 명확하게 알 수 있다. Annotation은 적절한 코드를 생성한다.Lombok의 @Getter같은 경우는 개발자가 직접 getter를 구현하지 않아도 실제로 컴파일 타이밍시 코드를 생성해준다.만약에 boilerplate code를 줄이고 생산성을 늘리고 싶다면 코드를 삽입해주는 Annotation은 큰 도움이 된다. run time시 특정 기능을 실행하도록 정보를 제공한다. spring 같은 framework에서는 DI를 위한 annotation을 다는 경우가 많다. 이런 annotation은 run time에서 annotation이 적용된 element의 역할을 정의하게 된다. 왜 Annotation이 필요할까 ?annotation이전에는 xml을 사용했다.하지만 xml은 유지보수가 쉽지 않았다.xml보다 코드에 친숙한 metadata를 위해서 annotation을 만들게 되었다.물론 xml과 annotation은 각각 장단점이 있다.xml은 코드 자체에서 loosely coupled 즉 의도적으로 느슨한 결합을 만들 수 있다.즉 configuration과 code의 결합성을 약하게 하는것이다.만약에 application 전역에서 적용되는 상수, 파라미터를 설정하고 싶은 경우 code에 묶여있지 않은 xml를 사용하는것이 더 좋은 선택일 수 있다.하지만 code의 일부분에만 적용되도록 하고 싶다면 그런 경우에는 xml보다는 annotation을 사용하게 나을 것이다.Custom Annotation을 만드는 방법일단은 @Override 어노테이션을 확인해보자.@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override {}해당 어노테이션에서는 별일 안한다.그냥 단순하게 parent class에 해당 method가 존재하는지 체크할 뿐이다.Annotation에는 본질적으로 buisness logic이 들어가 있지 않다.마치 interface처럼 logic은 제외하고 target element가 사용할 수 있어야 한다.해당 annotation을 보고 jvm은 bytecode level에서 동작할 수 있게끔 작동한다.일단은 Annotation이 들어갈 수 있는 여러 기본적인 Annotation들에 대해서 알아보자. @Target - 어노테이션의 적용 대상 @Retention - 어노테이션이 유지 되는 기간Target의 경우는 다음과 같다.public enum ElementType { /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Formal parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE}보면 적용되는 대상에 따라서 element를 설정해주면 됨을 알 수 있다.예를 들어서 @Getter는 클래스대상이니까 TYPE,@Override의 경우는 method대상이니까 METHOD이다.Retention의 경우에는 다음과 같다.public enum RetentionPolicy { /** * Annotations are to be discarded by the compiler. */ SOURCE, /** * Annotations are to be recorded in the class file by the compiler * but need not be retained by the VM at run time. This is the default * behavior. */ CLASS, /** * Annotations are to be recorded in the class file by the compiler and * retained by the VM at run time, so they may be read reflectively. * * @see java.lang.reflect.AnnotatedElement */ RUNTIME}예시로 몇개의 annotation을 살펴보자. @Override @Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override {} target은 method이다.retention은 source이다. -&amp;gt; compile되고 이후에는 버려진다. @Getter```java@Target({ElementType.FIELD, ElementType.TYPE})@Retention(RetentionPolicy.SOURCE)public @interface Getter { /** If you want your getter to be non-public, you can specify an alternate access level here. @return The getter method will be generated with this access modifier. */ lombok.AccessLevel value() default lombok.AccessLevel.PUBLIC; /** Any annotations listed here are put on the generated method. The syntax for this feature depends on JDK version (nothing we can do about that; it’s to work around javac bugs). up to JDK7: {@code @Getter(onMethod=@__({@AnnotationsGoHere}))} from JDK8: {@code @Getter(onMethod_={@AnnotationsGohere})} // note the underscore after {@code onMethod}. @return List of annotations to apply to the generated getter method. */ AnyAnnotation[] onMethod() default {}; boolean lazy() default false; /** Placeholder annotation to enable the placement of annotations on the generated code. @deprecated Don’t use this annotation, ever - Read the documentation. */ @Deprecated @Retention(RetentionPolicy.SOURCE) @Target({}) @interface AnyAnnotation {}}```Target은 FIELD, TYPE으로 field과 class, enum, interface에 선언가능하다. Retention은 source이다. @SpringBootApplication@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface SpringBootApplication { // 생략}target은 class이고 retention은 runtime이다.spring이 작동되고 있는 runtime에도 해당 annotation은 유지된다. javax의 @NotNull@Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE })@Retention(RUNTIME)public @interface NotNull { // 생략}validation이라 그런지 다양한 target에 적용이 가능하고,validation은 runtime에 필요하니까 Retention은 run time이다.한번 custom annotation을 만들어보자.우리가 만들 annotation은 메소드 위에 붙여서 해당 메소드의 진행 시간을 체크하는 메소드이다.aop를 통해서 구현하고, 해당 메소드가 끝나면 log로 시간을 찍어보자.@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface LogExecutionTime {}일단 annotation을 만들어주자. method가 target이니까 method로 설정해준다. 로그를 남기려면 runtime으로 설정해야 한다.@Component@Aspectpublic class LogAspect { Logger logger = LoggerFactory.getLogger(LogAspect.class); @Around(&quot;@annotation(LogExecutionTime)&quot;) public Object logExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable{ StopWatch stopWatch = new StopWatch(); stopWatch.start(joinPoint.getSignature().toString()); Object ret = joinPoint.proceed(); stopWatch.stop(); logger.info(stopWatch.prettyPrint()); return ret; }} LogAspect에서는 logger를 선언한다. stopwatch 객체를 활용해서 시간을 측정하고, start()의 taskname으로 joinPoint의 signature로 설정한다. proceed가 끝나면 logger.info로 log를 출력한다.@Controllerpublic class TestController { @LogExecutionTime @GetMapping(&quot;/logCheck&quot;) public String logCheck(logCheckRequestDto dto) { return dto.getName(); }}그리고 해당 url로 request를 날리면 다음과 같이 log가 남겨진다.---------------------------------------------ns % Task name---------------------------------------------013841600 100% String com.example.demo.TestController.logCheck(logCheckRequestDto)끝 !Annotaion processorAnnotation을 붙이고 컴파일 타이밍때 우리가 원하는 동작을 하게 하는 핵심은 annotation processor이다.annotation processor는 javac의 일부이다.즉 컴파일 타이밍에 작동한다. javac가 소스 코드를 compile한다. 이때 annotation processor는 annotation을 보고 기존의 코드를 수정하거나 변경한다.한번 직접 실습으로 확인해보자.여기서 우리는 custom한 annotation과 기존 annotation으로 샘플 클래스를 만들어보자.@Getter@Setter@NoArgsConstructorpublic class MyClass extends MyParentClass{ @NotNull private String name; private String age; @Override @LogExecutionTime public void printMyName() { System.out.println(&quot;this is child class name&quot;); }}해당 클래스를 작성하고나서 build를 해보자.즉 compile이후에 코드가 어떻게 작성되는 확인해보는 것이다.// 해당 코드는 compile되고 나서 byte code를 decompile한 결과입니다.public class MyClass extends MyParentClass { @NotNull private String name; private String age; @LogExecutionTime public void printMyName() { System.out.println(&quot;this is child class name&quot;); } public String getName() { return this.name; } public String getAge() { return this.age; } public void setName(final String name) { this.name = name; } public void setAge(final String age) { this.age = age; } public MyClass() { }}다음과 같이 getter, setter같은 경우는 retention이 source였기 때문에compile된 이후에는 사라지는 것을 확인할 수 있다.그리고 @LogExecutionTime과 @NotNull같은 경우는 retention이 run time이었기 때문에 compile이후에도 유지됨을 알 수 있다." }, { "title": "JDBC와 Database Connection Pool", "url": "/posts/Database-Connection-Pool/", "categories": "DBCP", "tags": "DBCP, JDBC, Hikari CP", "date": "2022-04-01 00:00:00 +0800", "snippet": "JDBC자바의 database connection은 보통 jdbc(java Database Connectivity)를 사용한다.jdbc란 자바 프로그램 내부에서 sql을 실행하기 위한 데이터베이스를 연결해주는 application programming interface이다.즉 데이터베이스 사용을 위한 api이다.jdbc는 interface이기 때문에 실제 어떠한 데이터 베이스를 사용하던지, 즉 데이터베이스의 종류에 종속되지 않는다.음 만약에 이런 jdbc api가 없었더라면 = interface가 없다면,우리는 사용하는 database 종류에 맞춘 sql문을 각각 작성해야 했을것이다.jdbc의 역할은 다음과 같다. java application 에서 DB서버에 접속 sql을 수행하고 그 결과를 resultSet에 받아온다. DB 자체에 대한 정보를 갖고온다.즉 그림을 보면 알 수 있지만 외부 DB에 접근하는 작업을 jdbc api를 통해서 하게 된다.jdbc interface는 다음과 같다. JDBC driver manager : java application과 jdbc driver간의 접속을 공급한다. JDBC driver API : Driver manager와 driver간의 접속 interface JDBC driver : DBMS 접속을 제어하는 모듈, DBMS와의 통신 담당정리하면 다음과 같은 순서대로 java application에서 DBMS로 연결된다. Java application JDBC Driver Manager JDBC Driver DBMSDatabase Connection어플리케이션과 Database어플리케이션 간의 통신을 위한 객체이다.우리의 어플리케이션에서 외부 서버에 존재하는 database에 접근하려면 다음과 같은 정보가 필요할 것이다. 어떤 데이터베이스인지 -&amp;gt; 어떤 driver가 필요할지(h2, postgreSql, 등등) 데이터베이스가 위치한 서버의 url + port -&amp;gt; 데이터베이스의 url 데이터 베이스 접근을 위한 username, passwordJDBC를 통해서 Database Connection을 가져와 보자.public class DatabaseConn { static final String driverName = &quot;org.h2.Driver&quot;; static final String dbUrl = &quot;jdbc:h2:~/test&quot;; static final String username = &quot;sa&quot;; static final String password = &quot;&quot;; public static void main(){ PreparedStatement pstmt = null; ResultSet rs = null; try { sql = &quot;&quot; // 1. h2 driver 등록 Class.forName(driverName); // 2. get connection connection = DriverManager.getConnection(dbUrl, username, password); // 3. PreparedStatement 객체 생성 pstmt = conn.createStatement(); // 4. execute query rs = pstmt.executeQuery(sql); } catch (Exception e) { } finally { conn.close(); pstmt.close(); rs.close(); } } }}Database Connection PoolDatabase Connection Pool이란, 말 그대로database와의 connection을 담고 있는 pool이다.위 코드를 살펴보면 다음과 같은 절차로 이루어져 있다. Driver를 등록하고 DriverManager를 통해서 connection을 얻고 PreparedStatement 객체를 생성하고 이를 통해서 쿼리를 수행한다.즉, 개발자가 직접 connection을 생성하고 쿼리를 날려야 함을 알 수 있었는데,만약에 쿼리를 날리는 모든 부분에 다 이렇게 코드를 작성해야 한다면 이건 조금 골치가 아파진다.이런 순간을 위해서 Database Connection Pool이 존재한다.쿼리를 날리거나 DB에 뭔가를 반영하고 싶을때, 이미 pool안에 만들어둔 Database Connection을 가져와서 수행하면 된다.DBCP의 장점은 무엇일까 ? 미리 객체를 생성해뒀기 때문에 런타임에 동적으로 객체 생성, 소멸의 cost가 없고 빠르게 메모리에서 이미 만들어진 객체를 이용할 수 있다. 직접 코드 작성을 하지 않아도 된다. connection의 수를 관리 또는 제한해서 부하를 줄이고, 효율적으로 connection들을 이용하게 한다.DBCP의 경우 다음과 같은 특징을 가진다. WAS가 실행하면서 connection 객체를 미리 만들고 pool에 저장해놓는다. request를 수행하면서 db connection이 필요할때마다 가져다 사용하고 다시 반환한다. connection의 수는 설정가능하다. 만약 현재 사용가능한 connection이 없을 경우, request는 connection을 기다린다.그렇다면 connection의 수를 크게 설정하면 꼭 좋은 것일까 ?일단 connection객체를 생성한다는 것은 그만큼 메모리를 사용한다는것과 동일하다.만약에 너무 많은 connection을 만들어두면, 메모리를 많이 사용하게 되고,그렇다고 너무 적게 만들어두면, thread가 connection을 갖기 위해 대기하는 시간이 길어진다.그럼 어떻게 connection의 수를 관리해야 할까 ?결국에 connection을 이용하는건 thread이다. thread pool의 크기가 connection pool의 크기보다 크다면 대기하는 시간이 있을 수 있다. thread pool의 크기가 connection pool의 크기보다 작다면 대기하는 시간은 없겠지만, 남은 connection이 있을 수 밖에 없다.즉 connection pool의 크기를 조절해서 성능을 증가시키는것은 어쨋든 한계가 있다.결국에 thread의 수보다 크면 그 이상 증가해도 의미가 없다.Hikari CPDatabase Connection Pool을 관리하는 기술이다.hikari cp가 어떻게 connection pool을 관리하는지 알아보자.만약에 request가 하나들어온다고 생각해보자. request 요청됨 해당 request는 thread1에서 실행된다. thread1에서 database connection을 필요로 하게 되면, 이전에 사용했던 Connection이 존재하는지 확인한다. 있다면 현재 사용가능한 connection이 있는지 확인한다. 없다면 전체 connection pool에서 사용가능한 connection이 있는지 확인한다. 아예 connection을 get하지 못하면, 가능한 connection이 생길때까지, handoffqueue에서 대기한다. 다른 thread에서 connection을 반환하면 해당 connection의 사용정보를 pool에 기록하고 반납된 connection은 handoffqueue에 삽입된다. thread1에서 connection을 get한다.hikari cp에서는 connection의 수를 어떻게 설정하는게 좋을지 가이드를 제시한다. num of connections = core_count * 2 + effective spindle count즉 cpu 갯수 * 2 + DB가 동시에 관리할 수 있는 io 요청 수로 설정하는게 좋다고 한다.spring boot를 사용하게 되면 default connection pool로 hikari cp를 사용하게 되는데,이때 위의 가이드에서 제시하는 것처럼, connection의 수를 조절해보자.spring의 properties나 yaml로 해당 설정이 가능하다." }, { "title": "JAVA와 JVM", "url": "/posts/Java%EC%99%80-JVM/", "categories": "Java", "tags": "Java, JVM, JRE, JDK", "date": "2022-03-30 00:00:00 +0800", "snippet": "JAVA와 JVMJava로 개발하는 사람들은 기본적으로 java의 작동원리에 대해서는 알고 있어야 한다고 생각한다.학교 전공 수업에서 컴파일, 기계어 이런 용어들은 많이 들어봤을 것이다.java도 마찬가지다 결국에는 기계어로 번역되고 해당 기계어가 실행이 된다.하지만 java는 중간에 jvm이라는 가상 환경이 필요하다.왜 가상환경이 필요한건지 의문이 생길 수 있다.그런거에 대해서 한번 정리해보자.JRE와 JDK우리가 자바로 개발하다보면, JRE 또는 JDK를 설치하게 된다.뭐.. 프로그래밍 언어마다 설치해주는게 있을 수 있지~ 라고 생각할 수 있지만뭐 자바를 실행시키기 위해서 ide를 켰더니 jdk가 필요하다고 하고,또 tomcat을 실행시키려고 보니까 jre가 필요하다고 하고,뭔가 java 컴파일러랑 jvm같은 것들을 묶어서 jre, jdk라고 하는 것 같은데이번에 정확하게 정리해보자.일단 둘의 차이점 먼저 알아보자.JRE = Java Runtime EnvironmentJDK = Java Development KitJRE는 java 프로그램이 실행되는 환경을 의미한다.당연히 JVM + 라이브러리 + java api를 포함한다.javac 같은 경우는 jre에는 포함되지 않는다.JDK는 java를 개발하기 위해서 필요한 kit이다.개발단계니까, JRE에다가 java compiler도 추가되어 있다.JVM의 필요성JVM은 java만의 특징이라고 생각한다.결국 java가 실행되기 위한 환경을 의미하는데,중요한 점은 virtual machine이 os위에서 돌아간다는 점이다.일단 왜 가상 머신이 돌아가는 걸까 ?jvm은 java virtual machine의 약자이다.os는 직접 java 프로그램을 실행하지 않는다.java compiler가 소스 프로그램으로부터 바이트 코드를 만들고,해당 바이트 코드를 기계어로 번역해야 하는데,이때 jvm이 바이트 코드를 기계어로 번역한다.즉 바이트 코드를 이해하고 기계어로 번역해서 os가 실행할 수 있게 해준다.jvm이 필요한 이유는 뭘까 ?바로 os마다 환경이 다 다르기 때문이다.os별로 다른 java program을 개발할 수는 없으니까,os에 종속되지 않고 개발하고 os위에 jvm이 os가 잘 실행할 수 있도록 번역하게 한다.즉 잘 생각해보면 jvm 자체는 os에 종속적이다.java 프로그램을 작성하고 javac가 컴파일하면 .class 파일이 만들어진다.이게 바이트 코드이다.실제로 tomcat으로 자바 프로그램을 실행해보면,실행 폴더 내부에는 .class 파일만 존재한다.톰캣은 jre의 jvm을 갖고 있고jvm이 해당 파일들을 기계어로 번역해서 os가 실행할 수 있도록 해주는 것이다.이 바이트 코드는 일반적인 os에서는 실행할 수 없다.jvm이 중간에 실행하기 때문에 java의 가장 큰 장점인 다른 플랫폼에게서의 독립성을 보장해준다.JVM의 작동 원리jvm이 왜 필요한지 왜 중요한지 알았으니구체적으로 jvm이 어떤 방식으로 작동되는지 알아보자.자바 개발자들이 소스를 작성하고 해당 소스는 javac에 의해서 .class를 생성하게 된다.이건 아직 os가 읽을 수 없는 반기계어이다.바이트 코드는 다음과 같은 절차를 따른다. class loader에 의해서 JVM내로 로드 된다. 실행 엔진에 의해서 기계어로 번역되고 메모리상의 Runtime Data Area에 배치된다.여기서 실행 엔진에는 두가지가 있다. -&amp;gt; interpreter와 Just in time compilerinterpreter는 바이트 코드를 한줄씩 읽기 때문에 실행 속도 느리지만 JIT compiler는 적절한 시점에 바이트 코드 전체를 컴파일하고 직접 실행한다.즉 interpreter로 실행하다가 중간에 전체 컴파일해서 실행한다는 것이다.Class Loaderjava는 동적으로 객체들을 로드한다.즉 컴파일 타임이 아니라 런타임에 클래스를 처음 참조할때, 해당 클래스를 로드하고 링크하는 특징이 있다.이 동적 로드를 담당하는 부분이 JVM의 class loader이다. 계층 구조클래스 로더도 여러가지 있고, 이 로더들은 계층구조로 존재한다. 위임 모델클래스를 로드할때 먼저 상위 클래스 로더를 확인하고 상위 클래스 로더에 클래스가 존재한다면 상위 클래스 로더를 사용하고 없으면 직접 로드한다. 즉 언제나 상위 클래스 로더를 확인하고 있으면 위임한다. 가시성 제한하위 클래스 로더는 상위 클래스 로더를 볼 수 있지만, 상위 클래스 로더는 하위 클래스 로더를 확인할 수 없다. 언로드 불가클래스 로더는 로더만 가능하고 언로드는 불가능하다.Runtime Data Area pc registerprogram counter 레지스터는 각 스레드마다 존재한다.스레드가 실행될때 생성된다. pc register는 현재 수행중인 jvm 명령의 주소를 갖는다. -&amp;gt; 즉 어떤 명령을 수행하고 있는지 알고 있다. jvm stack스레드마다 하나씩 갖고 있으며 스레드가 생성될때 생성된다. stack frame이라는 구조체를 저장한다.즉 데이터 저장의 단위가 이 구조체이다.스택이니까 당연히 pop, push의 연산만 한다.이 stack frame은 메소드가 수행될때마다 생성되고 해당 스레드의 stack frame에 쌓인다.우리가 에러가 발생했을때, e.printstacktrace()가 해당 스레드의 jvm stack에 있는 stack frame들을 하나씩 꺼내서 출력하는 것이다.stack frame에는 지역 변수 배열, 피연산자 스택, 실행중인 메소드가 속한 클래스의 런타임 상수 풀에 대한 레퍼런스를 갖는다.이들은 컴파일 시점에 이미 결정되기 때문에 컴파일 타임에 stack의 크기가 결정된다. native method stack자바 외의 프로그래밍 언어로 작성된 네이티브 코드를 위한 스택이다. heap인스턴스, 객체를 저장하는 공간이고 GC의 대상이다. method모든 스레드가 공유하는 공간이다. jvm이 시작될때 생성된다.jvm이 읽은 클래스들과 인터페이스에 대한 런타임 상수 풀, 필드와 메소드 정보, static 변수, 메소드의 바이트 코드를 저장한다. runtime constant pool메소드 영역에 포함되고, 각 클래스와 인터페이스의 상수, 메소드와 필드에 대한 모든 레퍼런스를 담고 있다.Garbage CollectionC로 프로그래밍을 하다보면, malloc같은 동적 할당을 통해서 배열이나 변수의 메모리 공간을 할당해준다.이때 우리는 꼭 잊지 않고 사용하고 남은 공간들의 할당을 해제해줘야 한다.java의 경우는 기본적으로 heap영역에 대해서 Garbage Collection 기능을 제공한다.즉 heap영역의 사용하지 않는 메모리 공간에 대해서는 자동으로 할당을 해제한다.heap의 경우는 new Object()와 같이 새롭게 생성하는 객체들이 저장되기 때문에우리는 따로 메모리 해제를 안해줘도 된다.하지만 static이나 final 변수들이 저장되는 method영역은 GC의 대상이 아니기 때문에 (물론 하도록 할 순 있다.)이런 경우에는 메모리 설정에 조심해야 한다." }, { "title": "Database와 실무", "url": "/posts/Database%EA%B0%9C%EB%85%90%EA%B3%BC%EC%8B%A4%EB%AC%B4/", "categories": "Database", "tags": "Database", "date": "2022-03-28 00:00:00 +0800", "snippet": "DatabaseDatabase는 아주 중요하다.사실 개념적으로 데이터들의 집합이니까 어떤 서비스던 본체는 database라고 생각한다.중간 spring같은 application은 단순하게 생각하면 database에 작업 처리를 부탁하는 역할만 한다.database의 특징을 한번 정리해보려고 한다.뭐 지식 정리라기 보다는 공부하면서 본 개념들이 실무에서 어떻게 느껴지는 감상평처럼 정리하고자 한다.참 학교에서 공부할때는 뭔 뜬구름 잡는 소리지 했는데실제로 일하다 보면 뼈아프게 다가오는 개념들이 많다.학교에서 공부하면서 동시에 예시를 잘 들어줬으면 더 시행착오가 없었을 텐디….DBMSDatabase Management System. 즉 데이터 베이스 관리 시스템이다.예를 들어보자. MySql이던 PostgreSql이던 기본적으로 DBMS를 통해서 관리가 가능하다.뭐 쿼리를 날리던 데이터 베이스에 어떠한 작업을 할때 기본적으로 그걸 매개해서 적용을 시켜주는 관리 시스템이다.RDBRelational Database. 관계형 데이터 베이스라고 한다.정규화된 방식으로 데이터를 저장한다.정규화된 방식이라 함은 테이블을 생각하면 된다.왜 RDB를 사용할까 ?웹 서비스의 대부분은 RDB를 사용한다.그 이유는 테이블 형태로 데이터를 저장하고 관리하기 때문에즉 정해진 형식이 있기 때문에해당 형식만 지키면서 데이터를 관리한다면 관리가 용이해진다.개발자가 어떤 방식으로 데이터를 관리할지를 고민하지 않고 RDB의 규칙만 맞춰서 잘 저장하고 관리하면대용량 데이터를 저장한다 하더라도 혼동없이 잘 관리가 가능하기 때문이다.내 생각에는 RDB를 사용하는 이점은 테이블이다.테이블을 컬럼으로 구성되기 때문에 예를 들어서 user table이 있다면,우리는 user에 대한 정보를 마구잡이 저장하는게 아니라 무조건적으로 column단위로 생각하게 된다.개발자 입장에서도 데이터의 정합성을 고려하게 만드는 구조인것 같다.테이블 연관관계 일대일 일대다 다대다중요한건 다대다는 사용하지 않는다.말로는 다대다라고 하지만 다대다로 직접 테이블을 구성하는 것보다 다대일 일대다 로 중간 매핑 테이블을 두는 방식으로 개발해야 한다.정규화기존에 존재하던 relation을 분해하는 것을 의미한다.정규화를 하는 것의 장점은 구조 확장시 재디자인을 최소화한다는 것이다.정규화는 진짜 정말로 중요하다고 생각한다.잘못 설계된 그니까 잘 정규화가 안되고 서비스가 릴리즈되고기능을 확장할때 이미 굳혀진 구조를 바꾸는 건 너무 어려운 작업이다.그럴때마다 아… 처음부터 나눠놓을걸 이라고 후회하는 경우가 너무 많았다.ER diagram중요한것처럼 보이지 않은 수 있다…그냥 개발하면 되지 왜 필요하지 ? 라고 생각한다면 오산이다.실제로 개발할때는 무조건적으로 ER diagram을 작성해야 한다.하지 않으면 나중에 무조건 후회한다.서비스가 커지면 테이블들이 어떻게 연관관계를 맺고 있는지 한눈에 안보이는 경우가 많아지고,이러면 나중에 쓸데 없이 복잡하게, 혹은 효율성이 떨어지고 데이터를 조회하는 경우가 많아진다.그리고 서비스를 이어받아서 개발하게 되는 사람입장에서 ERD가 없으면 정말 난감하다….Transaction데이터 베이스에 날라가는 쿼리들의 묶음 단위라고 생각하면 편하다.트랜잭션이 반영되야지 실제로 database에 update가 일어난다.자 그러면 왜 transaction이 필요할까 ?transaction이 필요한 것에 의문이 있다면 그건 아직 공부가 덜된거다.의문을 가질게 아니라 그냥 쿼리를 실행하는 단위를 지칭하는것이다.여러 쿼리를 묶을 수도 있지만 단일 쿼리가 트랜잭션이 담길 수도 있다.DBMS 입장에서 보는 쿼리를 담은 구조체라고 생각하면 된다.그런데 트랜잭션하면 떠오르는 ACID가 있다. Atomicity트랜잭션은 반영되던지, 반영안되던지 둘중 하나라는 의미이다. 트랜잭션에 담긴 쿼리가 10개라면, 이 10개는 항상 같이 움직인다. Consistency트랜잭션이 반영되고 나서도 일관성있는 데이터 베이스 상태를 유지해야 한다는 것이다. Isolation가장 중요하다. 트랜잭션이 완료되기 전에는 데이터베이스를 참조할 수 없다. 만약에 update치고 있는데 중간에 read하면 대참사가 발생할 거다. Durability성공적으로 반영됬다면 이후에 문제가 생겨도 영구적으로 반영되야 한다는 의미이다.Index보통 데이터 베이스에서 특정 row를 찾는 경우는 무지막지하게 빈번하다.검색에서 index가 없다면 보통은 테이블 전체를 full scan으로 탐색한다.만약에 테이블의 크기가 커진다면 이는 성능을 저하시킨다.이런 성능 저하를 막기 위해서 우리는 index를 만든다.index는 b-tree 알고리즘을 사용해서 효율적으로 테이블을 검색할 수 있게 해준다. -&amp;gt; 이진 탐색 트리의 효율성을 생각해보자.아… 개발할때는 직접 만들일은 많이 없었던것 같다.spring data jpa의 구현체로 hibernate를 사용하면 기본적으로 기본키로 인덱스를 만든다.물론 기본키를 제외하고 다른 컬럼값으로 데이터를 검색하는 일이 빈번하다면 index를 구성하는것에 대해서 고려해봐야 한다.물론 단점도 있다. index는 기법이라던가 그런게 아니다. 실제로 별도의 index 자료구조를 만들어야 하기 때문에저장 공간을 소모할뿐더러 C, U, D시 테이블이외애도 index에도 변경사항이 반영되야 한다.나같은 경우는 데이터가 많아지고 + 조회하는 컬럼이 한정적이면 index를 만들어보고효율이 떨어지면 index를 사용하지 않는다." }, { "title": "Tomcat", "url": "/posts/tomcat/", "categories": "Tomcat", "tags": "Tomcat, WAS", "date": "2022-03-27 00:00:00 +0800", "snippet": "Tomcat 이란 ?이전에 우리는 nginx와 apache의 차이점을 알아봤다.거기서 우리는 apache, nginx는 웹서버.tomcat은 웹 어플리케이션 서버로 소개했다.웹 서버와 웹 어플리케이션 서버의 차이점은 뭘까 ?Web ServerWeb Server는 정적인 자료들을 처리한다.html, css, image등 내용이 변하지 않는 정적인 파일들을 만들어 준다..Server에 페이지를 요청하면 서버는 해당하는 화면을 client pc에 html 파일로 전송한다.html 파일 이외의 화면의 레이아웃 구성이나, 화면에 첨부된 image등은 내용이 변하지 않는 정적인 파일이다.그러한 파일들을 웹서버에서 처리한다.하지만, 서버에 정적인 모든 파일을 저장하고 클라이언트에서 요청이 왔을때, 서버에 저장된 파일을 내려주기 때문에 서버 자원의 한계가 있을 수 있다. 이를 보완해서 생긴게 WAS이다.Web Application Server기존의 웹 서버에 컨테이너가 추가되었다.컨테이너를 추가한 이유는 서버의 한계를 보완하기 위해서이다.기존의 서버는 정적인 파일을 처리하며 리소스가 부족할 수 있다는 단점이 있었다.그래서 웹 서버의 기능 일부에 컨테이너를 추가해서,정적인 파일 이외에도 동적인 파일들을 생성할 수 있으며, 요청이 올때마다 필요한 데이터를 그때그때 생성하니까 리소스 문제로 해결한다. 또 서블릿을 관리하고, 생명 주기에 기반해서 관리, 세션, 네트워크 등 다양한 서비스를 제공한다.tomcat자바 어플리케이션을 위한 WAS.jsp, html등을 처리할 수 있다.스프링의 경우 보통 tomcat과 연동하며spring boot는 내장 tomcat이 이미 설치되어 있다.tomcat과 web server를 같이 사용 ?사실 토비님에 따르면 굳이 apache를 앞에 두고 tomcat을 사용할 이유는 없다고 한다.하지만 우리는 트래픽에 대비해야 한다.만약에 우리가 보안을 위해서 reverse proxy가 필요하다던가 아니면 로드 밸런싱을 필요로 한다면 여러 서버들로 요청이 가기 전에 중간에 nginx같은 리버스 프록시 기능을 제공하는 웹 서버를 앞에 둘 필요가 있다." }, { "title": "Log4j2", "url": "/posts/Log4j2/", "categories": "Log4j2", "tags": "Log4j2, log, trouble shooting", "date": "2022-03-25 00:00:00 +0800", "snippet": "log4j2log는 개발하면서, 혹은 운영하면서 중요한 역할을 한다.실제로 개발하면서는 우리가 원하는 흐름대로 실행이 되는지 체크할 수도 있고,운영 단계에서는 기존의 로그를 보고 분석할 수도, 또 장애가 생겼을시 로그를 보고 대처할 수 있다.이번에 하는 프로젝트에서 한번 문제가 생긴적이 있었다.스프링 어플리케이션이 죽은 것이다.이해가 되지 않는 상황이었는데,확인해보니 로그가 무작위로 쌓이고 있었다.무려 로그 파일의 크기가 몇십 기가….이번에 해당 장애를 해결하고 왜 장애가 생겼는지 알아보았다.log levellog에는 위계가 있다.ALL &amp;gt; DEBUG &amp;gt; INFO &amp;gt; WARN &amp;gt; ERROR &amp;gt; FATAL &amp;gt; OFF다음과 같은 순서대로 log level이 정해진다.무슨 말이냐. protected Logger log = LoggerFactory.getLogger(MyName.class); log.setLevel(&quot;INFO&quot;) log.info(&quot;info&quot;) log.debug(&quot;debug&quot;)아 여기서 setLevel은 없는 함수 인데, 해당 로거의 레벨을 설정할수 있는 메소드가 있다고 가정하자.해당 로그를 info로 debug로 찍어봤다.이러면 결과는 다음과 같이 나온다. infodebug 레벨의 로그는 찍히지 않는다.debug가 info보다 상위의 레벨이고,logger의 레벨 설정이 info로 되어 있느니,debug 로그는 찍히지 않는다.Trouble Shooting개발하면서 로그가 찍히는 것을 보고 의문이 조금 있었다.info 레벨의 로그는 한번 찍히는데, debug레벨의 로그는 중복되서 찍히는 현상이 있음을 알았다.그리고 원하지 않던 jdbc관련 로그가 무더기로 찍히고 있었다.실제로 이런 현상이 지속된다면, 서버의 용량 부족으로 대참사가 발생한다. -&amp;gt; 이번에 겪은 문제로그를 남기는 설정을 가보았다.&amp;lt;Loggers&amp;gt; &amp;lt;Logger name=&quot;a.b.c&quot; level=&quot;debug&quot;&amp;gt; &amp;lt;AppenderRef ref=&quot;console&quot; /&amp;gt; &amp;lt;AppenderRef ref=&quot;file&quot; /&amp;gt; &amp;lt;/Logger&amp;gt; &amp;lt;Root level=&quot;info&quot;&amp;gt; &amp;lt;AppenderRef ref=&quot;console&quot; /&amp;gt; &amp;lt;AppenderRef ref=&quot;file&quot; /&amp;gt; &amp;lt;/Root&amp;gt;&amp;lt;Loggers&amp;gt;??루트 레벨에서 INFO레벨로 logger 정의가 되어 있고,a.b.c 라는 특정 패키지 밑의 클래스에서 발생하는 DEBUG레벨의 로그를 찍고 있었다.즉 두번 반복해서 로그를 찍고 있었던 것이다.하지만 debug가 2번 찍히고 info는 한번 찍혔다.사실 처음에 생각했을때는 루트에서 info로 찍고, 특정 패키지 내부에서는 debug로 찍히니까위계를 생각했을때, 당연히 info가 두번찍히고, debug가 한번 찍혀야 했다.그래서 log4j2의 공식 문서로 가보았다.[공식 문서] (https://logging.apache.org/log4j/2.x/manual/configuration.html).Additivity 라는 개념이 있다.만약 우리가 com.foo.bar 에서만 TRACE를 출력하고 나머지에서는 출력하지 않고 싶다면 다음과 같이 설정할 수 있다.&amp;lt;Logger name=&quot;com.foo.Bar&quot; level=&quot;TRACE&quot;/&amp;gt;&amp;lt;Root level=&quot;ERROR&quot;&amp;gt; &amp;lt;AppenderRef ref=&quot;STDOUT&quot;&amp;gt;&amp;lt;/Root&amp;gt;루트에서는 ERROR고 com.foo.Bar 밑에서만 TRACE이다.위계를 생각하면 당연히 con.foo.Bar에서만 TRACE가 찍히고 나머지 패키지에서는 ERROR이하만 찍힌다.만약에 Appender를 설정해준다면 어떻게 될까 ?&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&amp;lt;Configuration status=&quot;WARN&quot;&amp;gt; &amp;lt;Appenders&amp;gt; &amp;lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&amp;gt; &amp;lt;PatternLayout pattern=&quot;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n&quot;/&amp;gt; &amp;lt;/Console&amp;gt; &amp;lt;/Appenders&amp;gt; &amp;lt;Loggers&amp;gt; &amp;lt;Logger name=&quot;com.foo.Bar&quot; level=&quot;trace&quot;&amp;gt; &amp;lt;AppenderRef ref=&quot;Console&quot;/&amp;gt; &amp;lt;/Logger&amp;gt; &amp;lt;Root level=&quot;error&quot;&amp;gt; &amp;lt;AppenderRef ref=&quot;Console&quot;/&amp;gt; &amp;lt;/Root&amp;gt; &amp;lt;/Loggers&amp;gt;&amp;lt;/Configuration&amp;gt;다음과 같은 상황에서 로그를 찍으면 결과는 다음과 같다. 17:13:01.540 [main] TRACE com.foo.Bar - entry17:13:01.540 [main] TRACE com.foo.Bar - entry17:13:01.540 [main] ERROR com.foo.Bar - Did it again!17:13:01.540 [main] TRACE com.foo.Bar - exit (false)17:13:01.540 [main] TRACE com.foo.Bar - exit (false)17:13:01.540 [main] ERROR MyApp - Didn’t do it.보시다시피 trace는 두번 찍히게 된다.그 이유는 다음과 같다 한다.첫번째 로그는 com.foo.Bar에서 TRACE로 발생한다.이 event는 com.foo.Bar의 appender로 가고, 동시에 부모 로그 config(root)로 간다.com.foo.Bar의 appender가 실행된다. 그리고 콘솔에 로그를 찍는다.그리고 com.foo.Bar에 additivity가 false로 되어 있으면,root에 엮인 appender로 직행한다.그리고 한번 더 trace로그가 찍히게 되는 것이다.이게 우리 장애의 원인중 일부였다.여튼 다음과 같이 설정하면 두번찍히는 일은 없다.&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&amp;lt;Configuration status=&quot;WARN&quot;&amp;gt; &amp;lt;Appenders&amp;gt; &amp;lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&amp;gt; &amp;lt;PatternLayout pattern=&quot;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n&quot;/&amp;gt; &amp;lt;/Console&amp;gt; &amp;lt;/Appenders&amp;gt; &amp;lt;Loggers&amp;gt; &amp;lt;Logger name=&quot;com.foo.Bar&quot; level=&quot;trace&quot; additivity=&quot;false&quot;&amp;gt; &amp;lt;AppenderRef ref=&quot;Console&quot;/&amp;gt; &amp;lt;/Logger&amp;gt; &amp;lt;Root level=&quot;error&quot;&amp;gt; &amp;lt;AppenderRef ref=&quot;Console&quot;/&amp;gt; &amp;lt;/Root&amp;gt; &amp;lt;/Loggers&amp;gt;&amp;lt;/Configuration&amp;gt;additivity를 false로….해결 끝 !!" }, { "title": "Spring IoC (2)", "url": "/posts/spring-IoC(2)/", "categories": "Spring", "tags": "Spring, IoC", "date": "2022-03-24 00:00:00 +0800", "snippet": "Spring IoC (2)저번 포스트에서 spring IoC의 원리에 대해서 잠깐 알아보았고,DI를 어떻게 하는지도 알아보았다.DI의 여러가지 방법이 있는데,그중 우리는 xml을 통한 방법만 알아보았다.이번에는 xml 이외의 다른 방법들과 Spring IoC의 또 다른 기초 개념들에 대해서도 짚어볼 생각이다.Spring BeanSpring Bean은 Spring IoC Container가 관리하는 객체를 말한다.즉 Spring IoC Container가 직접 생성과 제어를 담당하는 객체를 의미한다.앞선 프로젝트에서 MyService에서는 Spring IoC에 의해서직접 개발자가 생성하는 객체를 바꿔주지 않고도 즉 제어권을 개발자가 가진 상태가 아니라Spring IoC Container가 갖고 Container가 직접 객체 생성과 관리를 제어했다.먼저 코드를 다시 한번 살펴보자.public class MyService implements MyServiceInterface{ private MyRepositoryInterface myRepositoryInterface; public MyService(MyRepositoryInterface myRepositoryInterface) { this.myRepositoryInterface = myRepositoryInterface; } @Override public String getName() { return &quot;jk&quot;; }}여기서 우리는 MyRepository의 구현체를 직접 설정하지 않고도xml 파일로 DI 설정을 해주고 Spring IoC Container가 그 설정을 보고MyService의 생성자가 호출되는 시점에서 직접 파라미터로 interface가 아니라MyRepositoryBefore를 생성해서 넘겨주었다.이 상황에서 MyRepositoryBefore가 Spring IoC에 의해서 생성되고 관리되는 객체이기 때문에이를 Spring Bean이라고 한다.따라서 개발자는 어떤 객체가 있고 그 객체가 Spring IoC 관리 대상임을 Spring IoC에게 알려줄 뿐이지, 직접 관리하지는 않았다.Spring Bean Factory와 application contextSpring Bean Factory는 Spring IoC Container이다.Spring Bean을 등록, 생성, 조회, 반환, 또 그 이외의 역할을 한다.그리고 우리는 Spring Bean Factory를 직접 사용하지는 않는다.이 Factory를 확장한 클래스인 Application Context를 직접 사용하게 된다.전의 포스트에서 xml에 Spring IoC가 관리하는 객체들의 정보를 담았는데,그 xml 파일의 이름이 applicationContext.xml이었다.즉 application context는 applicationContext.xml이라는 설정 정보를 읽어서spring IoC Container, applicaton context가 관리할 spring bean 객체들에 대한 정보를 얻었다.Container들의 종류와 각 역할위에서 spring bean은 생성, 관계 설정, 삭제등의 기능들을 실제 코드 대신에역할이 위임된 IoC Container가 담당했다.이 container에는 여러가지가 있고 각각 서로를 확장하면서 기능들을 추가시켜 나간다. Bean Factory가장 작은 단위의 interface이다.이 interface는 다음과 같은 기능을 한다. bean 객체에 대한 생성과 제공을 담당 단일 유형의 객체를 생성하는게 아니라 여러 유형의 객체를 생성, 제공 객체 간의 연관 관계를 설정 bean이 요청될 시 bean 생성 bean의 라이프 사이클 관리. ApplicationContextBean Factory를 확장한 interface이다.다음과 같은 기능들을 제공한다. Bean Factory의 기능 모두 제공 I18N 제공 (국제화=프로그램을 다양한 지역에 맞게 조정, 언어, 인코딩 등등…) 리소스 로딩 container 생성시 모든 bean 정보를 메모리에 로드 singleton registry를 통해서 bean의 단일 객체 생성. WebApplicationContextWeb 환경에서의 Application Context.웹에서의 application context기능을 제공한다.Java class를 이용한 관리xml은 사실 실무에서는 많이 사용하지는 않는다.이번에는 자바 클래스를 통한 bean 생성에 대해서 알아보자.@Configurationpublic class AppConfig { @Bean public MyServiceInterface myServiceInterface() { return new MyService(myRepositoryInterface()); } @Bean public MyRepositoryInterface MyRepositoryInterface() { return new MyRepository(); }}다음과 같이 config 클래스를 작성하고 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(AppConfig.class); MyServiceInterface myServiceInterface = applicationContext.getBean(&quot;myServiceInterface&quot;);위와 같은 코드를 통해서 @Bean으로 스프링 컨테이너가 관리하는 빈임을 명시하고,실제 application context에서 직접 bean을 가져올 수 있다. bean name은 기본적으로 method이름으로 설정된다. 물론 바꿀 수 있지만 왠만해선 바꿀일은 없었던것 같다.Annotaion을 이용한 관리앞서서는 xml을 통해서 application context가 spring bean 정보를 읽었다.하지만 spring 2. 대까지는 주로 이렇게 사용을 했고,5버전까지 업그레이드된 지금은 xml보다는 annotation을 이용해서 설정을 하게 된다.물론 spring boot로 까지 넘어가면 이 설정들은 더욱 간편해진다.Annotation을 사용하는 방법은 다음과 같다.spring bean으로 사용할(Spring IoC Container가 관리할) 클래스에 특정 annotaion을 붙이면자동으로 spring bean으로 등록된다.코드로 한번 보자.앞서서의 MyService 같은 경우에는 다음의 방식으로 spring bean으로 관리된다.@Service(&quot;MyServiceInterface&quot;)public class MyService implements MyServiceInterface{ private MyRepositoryInterface myRepositoryInterface; public MyService(MyRepositoryInterface myRepositoryInterface) { this.myRepositoryInterface = myRepositoryInterface; } @Override public String getName() { return &quot;jk&quot;; }}@Repository(&quot;MyRepositoryInterface&quot;)public class MyRepository implements MyRepositoryInterface{ @Override public String getMyName() { return &quot;jkRepository&quot;; }}각 클래스 위에 @Service, @Repository를 달고 이름으로 interface를 지정해줬다.그리고 이렇게 annotation을 붙이고, applicationContext.xml에다음과 같이 명시한다.&amp;lt;context:component-scan base-package=&quot;a.b.base&quot;&amp;gt;base-package로 적은 디렉토리부터 시작해서 각 트리 형태의 디렉토리를 순환하면서spring bean으로 등록된 component들을 scan해달라는 의미다.xml을 통해서 일일히 각 bean을 관리하는게 아니라 간단한게 Annotation을 통해서 bean으로 관리할 수 있다.Spring Boot로 넘어가면 이런 xml의 설정들도 생략가능하다. -&amp;gt; 사실 spring boot에서 xml로 설정해줄 일은 거의 없다. -&amp;gt; 주관입니다.Spring Bean으로 등록하기 위해서 @Service, @Repository를 달아줬는데,이 annotation의 이름들은 streotype annotation으로 자동으로 spring bean으로 인식된다.좀 더 자세히 설명하면,Spring Bean으로 등록되는 객체들은 각각의 역할에 따라서 다른 streotype annotation이 붙게 된다. @Repository @Repository annotation의 경우에는 DAO(Data Access Object)에 붙어야 한다. 예를 들어서 데이터 베이스을 잡아서 쿼리를 날리는 클래스, 혹은 jpa를 사용한다면 enttitymanager를 통해서 프록시 객체를 갖고 오는 부분이다. @Service @Service의 경우는 서비스 계층의 클래스들에게 붙인다. @Controller @Controller는 웹으로 만들면서 외부의 요청을 받아 처리하는 controller 클래스에 붙인다. @Component repository, service, controller 클래스 이외의 클래스에 붙인다.우리가 spring bean을 등록할때는 각 클래스들이 어떤 역할을 하는지 보고 그에 맞는 Annotation을 붙이면 된다.Spring Bean 조회우리가 만든 spring bean들이 실제로 spring bean으로 잘 등록되었는지 확인해보자.spring IoC container가 관리하는 빈 객체들은 다음과 같은 방법으로 조회가 가능하다.public class ApplicationContextInfoTest { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(AppConfig.class); @Test @DisplayName(&quot;모든 빈 출력하기&quot;) void findAllBean() { String[] beanDefinitionNames = ac.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) { Object bean = ac.getBean(beanDefinitionName); System.out.println(&quot;beanDefinitionName = &quot; + beanDefinitionName); } }}이러면 우리가 어플리케이션에서 설정한 모든 빈 + 기본 스프링 빈이 추가되서 출력된다. beanDefinitionName = org.springframework.context.annotation.internalConfigurationAnnotationProcessorbeanDefinitionName = org.springframework.context.annotation.internalAutowiredAnnotationProcessorbeanDefinitionName = org.springframework.context.annotation.internalCommonAnnotationProcessorbeanDefinitionName = org.springframework.context.event.internalEventListenerProcessorbeanDefinitionName = org.springframework.context.event.internalEventListenerFactorybeanDefinitionName = appConfig beanDefinitionName = myServiceInterface beanDefinitionName = myRepositoryInterface만약에 실제 어플리케이션에서 사용하는 빈들만 보고싶다면 다음과 같이 작성해보자. @Test @DisplayName(&quot;애플리케이션 빈 출력하기&quot;) void findAllApplicationBean() { String[] beanDefinitionNames = ac.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) { BeanDefinition beanDefinition = ac.getBeanDefinition(beanDefinitionName); // if (beanDefinition.getRole() == BeanDefinition.ROLE_APPLICATION) { System.out.println(&quot;beanDefinitionName = &quot; + beanDefinitionName); } } }그러면 어플리케이션에서 개발자가 직접 설정한 빈들이 출력된다. beanDefinitionName = appConfigbeanDefinitionName = myServiceInterfacebeanDefinitionName = myRepositoryInterface beanDefinition.getRole()에서 알 수 있듯이 각 bean은 역할이 있다. 역할들은 enum으로 관리된다. int ROLE_APPLICATION = 0; int ROLE_SUPPORT = 1; int ROLE_INFRASTRUCTURE = 2; Spring Bean의 생성 scopeSpring Bean의 생성 범위에는 singleton, prototype, request, session이 있다. Singleton Singleton에 대해서는 더 자세하게 나중에 다뤄볼 예정이다. 간단하게 설명하면, 어플리케이션이 실행되는 동안 단일의 인스턴스만 생성된다. 즉 singleton으로 생성된 객체는 전 어플리케이션 흐름에서 하나만 생기고, 우리가 이 객체의 메소드를 호출하거나 변수를 사용할때, 단일의 객체에서만 호출하거나 사용하게 된다. 뭐 예를 들어서 Singleton 객체의 변수값을 어플리케이션 흐름상 수정하는 행위는 상당한 위험 부담이 있다. 단일의 인스턴스를 보장하는데, 변수를 바꾸는 순간 후의 접근에서는 바뀐 값이 참조된다. Spring IoC에서는 Annotation으로 관리되는 클래스들은 기본적으로 Singleton이다. 우리 코드에서 MyService, MyRepository같은 경우가 그러하다. Singleton은 스프링 컨테이너가 생성되면서 소멸까지 관리한다. 가장 긴 scope이다. Prototype prototype은 우리가 객체를 호출하거나 요청하는 순간에 새롭게 객체를 생성한다. 즉 Container에 spring bean을 요청하는 순간에 새로운 인스턴스를 제공한다. 종료 메소드 호출까지 관리하지 않는다. container는 생성, 의존관계 주입, 초기화까지만 관여하고 이후에는 관리하지 않는다. 따라서 해당 빈의 소멸은 호출한 client가 직접 관리해야 한다. Request Request는 Request 별로 새로운 객체를 생성한다. spring web에 있어야지 사용가능 하다. 요청이 들어오고 나갈때까지만 유지된다. 요청이 들어오면 생성, 주입, 초기화까지 하고, 요청이 끝나면 소멸된다. Session Session은 Session 별로 새로운 객체를 생성한다. 웹 세션이 생성되고 종료될때까지 유지되는 bean이다.prototype, request, session은 거의 사용되지 않고,우리는 기본적으로 singleton 객체를 사용한다.이때 singleton 기법을 사용해서 생성하는게 아니라, singleton registry라는 기법을 사용해서단일 객체를 보장한다.scope의 지정은 xml로도 annotation으로도 사용할 수 있다. xml 로 scope 지정 &amp;lt;beans&amp;gt; &amp;lt;bean id = &quot;MyRepository&quot; class = &quot;a.b.MyRepository&quot; scope = &quot;prototype&quot;/&amp;gt; &amp;lt;beans/ &amp;gt; annotation으로 scope 지정 @Repository(&quot;MyRepositoryInterface&quot;)@Scope(&quot;prototype&quot;)public class MyRepository implements MyRepositoryInterface{ @Override public String getMyName() { return &quot;jkRepository&quot;; }} 정리이론적으로 살펴봤지만 사실 사용하는 것들은 개발자마다 굳어져 있는것 같다.나같은 경우는 annotation 위주로 사용한다.그리고 scope같은 경우는 필요할 경우가 있을때가 가끔있다.예를 들어서 정말 session, request 별로 다른 변수를 갖는 객체가 필요한 경우가 있을 수 있다.처음에 아무것도 모르고 spring 개발할때는 xml도 써봤는데 관리가 쉽지 않았다.그리고 xml의 경우는 가아끔 config에서 사용하긴 하지만, 왠만해서는 @Configuration으로 관리하는게 좋다고 느껴진다.가독성 차원에서 조금 차이가 있고, xml 문법 자체가 한눈에 이해되는게 조금 어려웠던것 같다.Spring IoC 정리 끝 !" }, { "title": "Spring IoC (1)", "url": "/posts/spring-IoC(1)/", "categories": "Spring", "tags": "Server, IoC", "date": "2022-03-23 00:00:00 +0800", "snippet": "Spring IoCSpring에 대해서 원론적으로 공부해본적은 많이 없다.그래서 시간 남을때마다 원론 공부로 돌아가고는 하는데,이번 기회에 Spring Ioc가 뭔지 깔끔하게 정리해보자.-&amp;gt; 사실 누군가가 물어봤었는데 개념은 알지만 내 언어로 구체적으로 설명을 제대로 못해준게 한이다.객체와 객체들간의 의존성일단 IoC에 대해서 깊게 알기 전에 우리가 객체지향 프로그래밍으로 여러 객체를 구성한다고 가정했을때의벌어질 수 있는 흔한 상황에 대해서 먼저 짚어보자.현재 우리는 이름을 반환하는 어떤 서비스 함수, 레포지토리 함수들을 작업하고 있다.예를 들어서 이런 클래스, 인터페이스들이 존재한다고 가정하자.MyService Beforepublic class MyService implements MyServiceInterface{ private MyRepositoryInterface myRepositoryInterface; public MyService() { this.myRepositoryInterface = new MyRepositoryBefore(); } @Override public String getMyName() { return &quot;jkService&quot;; }}일단 MyService는 MyRepository 인터페이스를 갖고, 해당 인터페이스의 구현체 중에서 MyRepositoryBefore를 가진다.일반적인 객체 지향 프로그래밍에서는 이런식으로 객체를 사용하는 시점에 객체를 생성한다.즉 MyService를 사용할때, 생성자를 호출할때 MyRepositoryBefore()를 또 생성해줘야 한다.하지만 우리의 개발은 여기서 끝나지 않는다.예를 들어서 새로운 Repository가 필요한 경우에는 어떻게 해야 할까 ?이런식으로 수정해야 한다.MyService Afterpublic class MyService implements MyServiceInterface{ private MyRepositoryInterface myRepositoryInterface; public MyService() { // this.myRepositoryInterface = new MyRepositoryBefore(); this.myRepositoryInterface = new MyRepositoryAfter(); } @Override public String getMyName() { return &quot;jkService&quot;; }}즉 우리는 실제 코드의 수정으로 기존의 MyRepositoryBefore를 MyRepositoryAfter로 교체해줘야 한다.우리가 객체간의 의존성을 줄이기 위해서 인터페이스를 사용하지만 실제로 이런 경우에는 코드의 수정이 불가피하다.어쨋든 소스코드에서 하드코딩을 통해서 직접 생성하는 객체를 바꿔야만 하기 때문이다.수정에는 닫혀있고 추가에만 열려있는게 바람직하다면 직관적으로 이건 그렇게? 바람직하지 못하다.결국 객체간의 의존성은 피할 수 없다.객체지향은 신이 아닌것이다… 결국 이런점은 어쩔 수 없다.자 여기서 Spring IoC가 등장한다.Spring IoC이전의 MyService에서 우리는 원하는 Repository를 바꾸기 위해서 직접 코드를 수정해야 했다.하지만 우리가 이 부분을 Spring IoC에게 맡긴다면 이런 과정을 일일히 해주지 않아도 된다.IoC는 inversion of control의 약자디. control 주체의 역전이라는 것이다.spring 내부의 객체들과 메소드의 호출을 개발자가 결정하는 것이 아니라, 외부의 개입으로 결정된다는 뜻이다.기존의 Spring IoC가 없었을 때(일반적인 객체 지향)에서는 우리는 내부 객체들의 control을 개발자가 정해주었다.Inversion of Control은 이런 control의 주체가 개발자에서 외부로 이동한다는 의미이다.위의 코드에서는 개발자는 MyRepositoryInterface만 사용해주고, 그 구현체에 대해서는 신경쓰지 않아도 된다는 것이다.즉 쉽게 말하면 구현체 이런거 일일히 안고쳐줘도 된다 ! 인거다.Spring IoC는 Spring IoC Container가 해준다.개발자의 역할을 이 컨테이너에게 위임하게 된다.IoC Container는 객체 생성부터, 객체들의 관리, 객체들간의 관계 정의까지 많은 부분들을 관리한다.그리고 그런 부분들에 대해서는 개발자는 신경쓰지 않아도 된다.IoC Container의 역할과 Dependency Injection자 이제 이 Spring IoC Container가 하는 일을 알아보자.우리가 기존의 객체 지향을 다시 살펴보면,위의 MyService는 객체가 사용될때, 직접 MyRepositoryBefore를 생성하고 앞으로 이 클래스의 참조정보를 갖고메소드, 변수들을 사용하게 된다.이게 일반적인 방법이었다.Spring IoC Container는 다음과 같은 방식으로 객체를 제어 한다.MyService는 MyRepositoryBefore의 존재를 모른다.다만 MyRepositoryBefore가 구현하는 MyRepositoryInterface에 대한 참조 정보만 갖고 있다.그리고 IoC Container가 MyRepositoryBefore를 생성해주고, 생성된 인스턴스의 정보를 MyService에게 알려주게 된다.이러한 과정을 의존관계 주입, Dependency Injection이다.우리가 해야 하는 부분은 IoC Container가 MyRepositoryBefore를 관리할 수 있도록 (생성, 의존관계 주입)그 설정정보들을 기록해주면 된다.IoC는 구현하는 방법에 따라서 Dependency Lookup, Dependency Injection이 있다.우리는 Dependency Lookup은 신경쓰지 말자. 지금은 사용되지 않는다. -&amp;gt; 그 이유는 결국 Dependency Lookup은 컨테이너 api를 사용하게 되면서 여기에 의존하게 되기 때문이다. -&amp;gt; 나도 정확하지는 않다..! 요즘은 사용하지 않는다니까 대충 단점만 알고 넘어가자.Dependency Injection의존관계 주입의 방법은 3가지이다. setter constructor method사실 이전 포스트에 다 작성했다. 궁금하면 여길 찾아보자.https://hmcck27.github.io/posts/Spring-%EC%9D%98%EC%A1%B4%EA%B4%80%EA%B3%842/기본적으로 생성자 주입 방식을 많이 사용한다.그렇다면 Spring IoC Container에게는 어떻게 설정정보를 전달할까 ?여러가지 방법이 있다.일단 지금은 XML 설정 방법을 알아보자.MyService Beforepublic class MyService implements MyServiceInterface{ private MyRepositoryInterface myRepositoryInterface; public MyService(MyRepositoryInterface myRepositoryInterface) { this.myRepositoryInterface = myRepositoryInterface; } @Override public String getMyName() { return &quot;jkService&quot;; }}다음과 같이 MyService를 구성한다.보면 생성자 주입방식을 사용했고, 우리는 어떤 구현체를 사용할지에 대해서는 명시하지 않았다.그냥 인터페이스만 넣어줬다.그리고 다음과 같이 applicationContext.xml파일을 만든다.&amp;lt;beans&amp;gt; &amp;lt;bean id = &quot;MyRepositoryInterface&quot; class=&quot;a.b.MyRepositoryBefore&quot; /&amp;gt; &amp;lt;bean id = &quot;MyService&quot; class=&quot;a.b.MyService&quot;&amp;gt; &amp;lt;construtor-arg name=&quot;MyRepositoryInterface&quot; ref=&quot;MyRepositoryInterface&quot;&amp;gt; &amp;lt;/bean&amp;gt;&amp;lt;beans/&amp;gt;그러면 IoC Container는 이 xml 파일을 읽고 자동으로 생성자의 MyRepositoryInterface 파라미터에 구현체인 MyRepositoryBefore 클래스를 생성해서 넣어준다.자 그러면, 꼭 xml로만 해야할까 ?그건 아니다 -&amp;gt; 난 xml이 싫다.component scan과 annotation, java 소스를 사용해서 설정정보를 넣어줄 수 있다.그냥 annotation을 사용하는게 가장 편한것 같다.병행해서 사용할 경우가 있으면 어쩔 수 없지만…결국에는 코드에서는 interface만 알고 있기 때문에 객체들의 의존도가 떨어지게 된다.정리 IoC 의 정체 DI 종류 어떻게 Container에 설정을 전달하는지 -&amp;gt; 이건 다음에 한번 더 자세하게 정리할 예정이다." }, { "title": "Singleton과 Spring", "url": "/posts/singleton%EA%B3%BC-Spring/", "categories": "Spring", "tags": "Spring, Singleton", "date": "2022-03-23 00:00:00 +0800", "snippet": "Singleton Pattern여기서 자바 싱글톤 = spring singleton을 예시로 생각해보자.Singleton은 어플리케이션 전역에서 하나만 존재하는 객체이다.자바 JVM에서 딱 하나만 존재하는 객체 혹은 이런 디자인 패턴을 singleton이라고 한다.Singleton Design Pattern클래스의 인스턴스가 딱 1개만 생성되는 것을 보장하는 디자인 패턴이다.그래서 복수로 인스턴스를 생성하는 것을 막는 로직이 객체 생성에 필요하다.다음과 같은 패턴을 말한다.public class SingletonService { private static final SingletonService instance =new SingletonService(); public static SingletonService getInstance(){ return instance; } private SingletonService() { } public void logic() { System.out.println(&quot;call singleton instance&quot;); }}이렇게 클래스를 만들면,처음 static으로 선언하면서 static 영역에 객체가 생성된다.그리고 해당 클래스의 생성자는 private이기 때문에 외부에서 생성자 호출이 불가능하다.즉 그냥 생성자 자체를 막아놓은 것이다.그리고 해당 객체를 가져오려면 getInstance()를 호출해야만 한다.instance는 이미 static 영역에 선언되어 있고 해당 instance를 가져오게 된다.즉 외부에서는 늘 static 영역에 미리 선언되었던 instance만을 가져올 수 있게 된다. @Test @DisplayName(&quot;singleton pattern obejct use&quot;) void singletonServiceTest() { SingletonService instance1 = SingletonService.getInstance(); SingletonService instance2 = SingletonService.getInstance(); System.out.println(&quot;instance1 = &quot; + instance1); System.out.println(&quot;instance2 = &quot; + instance2); assertThat(instance1).isSameAs(instance2); }테스트 통과 !singleton pattern 구현의 문제점. 코드를 구현해줘야 한다. DIP 위반이다. -&amp;gt; 즉 클라이언트 코드가 해당 객체를 부르기 위해서는 구체화된 인스턴스를 가져오기 때문이다. OCP 위빈이다. -&amp;gt; 구체화된 클래스에 의존하기 때문에 사용할 클래스가 바뀌면 인스턴스도 바꿔줘야 한다. 테스트하기 어렵다. 내부 속성을 변경하거나 초기화하기 어렵다. -&amp;gt; 전역에서 관리되기 때문에 함부로 속성을 변경하면 이걸 사용하는 다른 클라이언트 코드들에 문제가 생길 여지가 많다. 유연성이 떨어진다.web application과 singleton현대적인 application의 대부분은 web application이지만,사실 application이라 함은 web만을 지칭하는 것은 아니다.서버내에서 즉 컴퓨터내에서 특정 작업을 처리해주는 데몬같은 것도 어플리케이션이고일정 시간마다 대용량의 작업을 처리하는 배치 프로그램도 어플리케이션이다.스프링으로도 이렇게 데몬이나 배치같은 어플리케이션을 만들 수 있다.스프링 배치라는 모듈이 있다 ! 물론 내가 개발해보지는 않았다…대부분은 스프링 어플리케이션은 웹이다.웹에서는 여러 고객이 동시에 요청한다.그러면 요청마다 새로운 객체를 생성해서 반환하게 된다.만약에 스프링의 DI container가 없는 상태에서 요청마다 객체를 생성하게 되면 다음과 같다.public class SingletonTest { @Test @DisplayName(&quot;no spring only pure di container&quot;) void pureContainer() { AppConfig appConfig = new AppConfig(); // 1. 조회 MemberService memberService1 = appConfig.memberService(); MemberService memberService2 = appConfig.memberService(); System.out.println(&quot;memberService1 = &quot; + memberService1); System.out.println(&quot;memberService2 = &quot; + memberService2); }}테스트 코드를 실행시켜보면,다음과 같은 결과가 나온다. memberService1 = hello.core.member.MemberServiceImpl@71623278memberService2 = hello.core.member.MemberServiceImpl@768b970c보다 싶이 새롭게 memberService를 할당받은 모습임을 알 수 있다.만약 웹 어플리케이션 같은 경우 이런식으로 객체를 늘 생성하면당연히 자원의 소모가 커진다.따라서 웹에서는 이렇게 singleton패턴이 아닌 경우 메모리라던가 관리에 지장이 생길 수 밖에 없다.singleton같은 경우는 어플리케이션 전역에 하나만 존재한다.요청이 동시에 복수가 들어와도 하나만 있는 객체를 반환한다면 늘 새로운 객체를 생성하는 자원 소모를 줄일 수 있다.여기서 memberService를 스프링 빈으로 생성하고 spring container가 관리하도록 한다면우리는 해당 객체를 다시 생성할 필요없이 전역으로 생성된 인스턴스를 갖다 쓰면 된다.Spring Containerspring에서는 spring container가 기본적으로 bean으로 생성된 객체는 singleton으로 만든다.이게 singleton의 패턴의 문제점을 해결하면서 객체를 singleton으로 관리하게 해준다.DIP, OCP를 지키면서 객체의 단일성을 보장해주고 개발자가 추가적으로 singleton 패턴 디자인을 할 필요가 없다.public class SingletonTest { @Test @DisplayName(&quot;spring container and singleton&quot;) void springContainer() { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(AppConfig.class); // 1. 조회 MemberService memberService1 = ac.getBean(MemberService.class); MemberService memberService2 = ac.getBean(MemberService.class); System.out.println(&quot;memberService1 = &quot; + memberService1); System.out.println(&quot;memberService2 = &quot; + memberService2); assertThat(memberService1).isSameAs(memberService2); }} memberService1 = hello.core.member.MemberServiceImpl@1349883memberService2 = hello.core.member.MemberServiceImpl@1349883다음과 같이 bean 설정을 주입한 ApplicationContext에서 가져온 객체는 동일한 instance이다.spring container가 지원하는 bean들은 대부분 singleton이다.물론 bean scope에 맞춰서 다른 bean 종류도 있긴하다.그건 IoC Container 포스트에서 자세히 다룰 예정이다.singleton 방식의 주의점위에서 간단히 짚고 넘어갔듯이 singleton 패턴으로 디자인된 객체들은절대로 !! 절대로 state가 존재해서는 안된다.만약에 이런 singleton 객체가 있다고 가정해보자.public class SingletonService { private static final SingletonService instance =new SingletonService(); private int price; public static SingletonService getInstance(){ return instance; } private SingletonService() { } public void order(int price) { this.price = price; } public int getPrice() { return this.price; } public void logic() { System.out.println(&quot;call singleton instance&quot;); }}SingletonService는 price라는 가변 변수가 있다.해당 변수를 바꾸는 함수 order가 있다면 이는 추후에 큰 문제가 될 수 있다.@Testvoid statefulServiceSingleton() { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(TestConfig.class); SingletonService service1 = ac.getBean(SingletonService.class); SingletonService service2 = ac.getBean(SingletonService.class); // threadA : 10000원 주문 service1.order(10000); // threadB : 10000원 주문 service2.order(20000); int price1 = service1.getPrice(); int price2 = service2.getPrice(); System.out.println(&quot;price1 = &quot; + price1); System.out.println(&quot;price2 = &quot; + price2); Assertions.assertThat(service1.getPrice()).isEqualTo(service2.getPrice());}이 코드에서의 결과물은 price1 = 10000price2 = 20000가 아니구다음과 같다. price1 = 20000price2 = 20000결국 변수를 함부로 바꾸니까 문제가 생긴것이다." }, { "title": "nginx와 apache", "url": "/posts/nginx%EC%99%80apache/", "categories": "Server", "tags": "Server, Nginx, Apache", "date": "2022-03-22 00:00:00 +0800", "snippet": "Apache VS Nginx최근에 서비스를 릴리즈할 날이 다가오고 있어서 포스트를 작성을 많이 못했다.흔히 백엔드 서버를 구성할때 어떤 종류의 서버를 사용하지 고민이 있을 수 있다.뭐 사실 난 nginx만 사용해봤는데,이번에 nginx를 깔면서 든 의문이 있었다.nginx와 apache는 무엇이 다르길래 최근에 죄다 nginx를 사용하는 걸까 ?사실 nginx를 위주로 많이 사용했던 나에게 apache라는 서버는 많이 들어는 봤지만 아예 생소한 개념이었다.그래서 이번에 apache와 nginx의 차이점을 한번 정리해보고자 한다.웹 서버일단은 apache나 nginx나 둘다 웹 서버이다.웹 서버가 뭐하는 친구일까 ?웹 서버는 사용자의 브라우저에 페이지나 소스를 내려주는 역할을 한다.주로 정적인 데이터를 처리한다.그냥 예시를 한번 들어보자.우리가 웹 서비스를 만들어서 실제로 배포한다고 가정해보자.많은 사람들이 흔히 사용하는 AWS의 ec2 인스턴스를 하나 구독했다.ec2 인스턴스는 그냥 하나의 컴퓨터라고 보면 된다. 대신 네트워크에 연결되어 있는 컴퓨터.자 우리는 컴퓨터를 하나 샀다.이 컴퓨터가 네트워크에 연결되어 있다고 해서, 이 컴퓨터에 뭔가 요청을 보내면 응답이 올까 ?궁금하면 당장 집 노트북 ip로 해서 아무거나 쏴보자…당연히 아무것도 안온다.우리는 배포를 하지 않았다.무언가 요청을 보냈을때 해당 요청을 받고, 복작복작 작업해서 작업물을 다시 요청자에게 리턴해주는 역할을 할 프로그램이 필요하다.그게 웹 서버다.그래서 우리는 ec2에 웹서버인 nginx를 깔았다.자 이제 요청을 보내면 뭐가 올까 ?당연히 에러 페이지만 온다. 아마 nginx 에러 페이지가 렌더링 될거다.당연하다. 요청은 받았는데, 복작복작 작업을 해서 결과물을 만들어 줄 친구가 없다.우리는 그 친구를 어플리케이션이라고 불른다.바로 흔하게 사용하는 백엔드 어플리케이션 예를 들면 스프링, 장고, 플라스크가 그 작업을 해준다.그래서 우리는 ec2에 스프링 war를 옮겨 넣었다.이제 스프링을 로드시키면 된다 !근데 어떻게 스프링 어플레케이션을 로드하지 ?그냥 자바 파일 실행 ?아니다. 자바 프로그램을 실행시킨다고 해보자.프로세스는 하나만 떠있다.nginx로 요청은 받았는데 해당 요청을 자바 프로그램이 처리하기 위해서는자바 서블릿을 사용한다.자바 서블릿을 누가 만들어 줄까 ?거기서 tomcat이 나온다.tomcat은 WAS라고 한다. Web application server.was는 웹 서버가 받은 요청을 전달 받아서 자바 서블릿으로 만든후 스프링 어플리케이션으로 전달한다.그럼 우리는 요청이 들어오고 요청을 처리하는 하나의 라이프 사이클을 이제 알 수 있다.컴퓨터 - 웹 서버 - 웹 어플리케이션 서버 - 어플리케이션얘기가 길어졌는데, 결국 웹 서버가 없으면 아무것도 못한다.이 웹서버에는 크게 두가지 종류가 있다. apache와 nginx. 어 근데 웹 서버는 정적인 리소스를 처리한다고 했는데…? 실제 서버는 다양하게 내려줘야 하잖아 ?-&amp;gt; 동적인 데이터를 다루는 것은 was + application이 한다 !Apache요청당 스레드를 처리하는 구조를 가진다.즉 하나의 요청의 하나의 스레드이다.많은 요청이 들어올 수록 메모리 사용량을 비례해서 증가한다.또 프로세스 하나가 관리하는 스레드의 수가 많아지고, process의 수도 증가하게 되면,context-swtiching의 비용이 증가하게 된다.아니 요청이 백만개 들어오면 ? 백만개의 스래드를 생성한다….그러면 메모리가 작살난다.apache의 이런 메모리 문제를 “일만개의 클라이언트 문제”라고 한다.즉 동시에 1만명이 접속해 있는 상황이라면, 요청에 비례해서 process, thread의 수가 증가한다면,아무리 효율적일 관리 전략을 사용한다고 해도 이미 thread가 10000개 라면 정말 처리가 곤란해진다.물론 이런 문제를 MPM에서도 apache 2.4 이후로 도입했다고 하는 event 전략으로 해결하고자 노력한다.MPMMPM은 apache의 요청 처리 전략이다.multi-module-process의 약자인데총 3가지의 전략이 있다. prefork 자식 프로세스 하나가 싱글 쓰레드이다. 하나의 요청이 하나의 프로세스를 차지한다. 그 프로세스안에는 하나의 쓰레드가 존재한다. 여분의 자식 프로세스를 만들어서 요청이 들어왔을때, 새로 만들지 않아도 되게 동작한다. 그래서 prefork이다. 높은 성능이 필요할때 사용한다. 하나의 프로세스가 정지해도 다른 프로세스에는 영향이 없다. 프로세스 간에 메모리를 공유하지 않는다. worker 자식 프로세스가 여러개의 쓰레드를 가지고, 하나의 요청은 하나의 쓰레드를 차지한다. 위의 prefork보다 당연히 성능이 낮다. 프로세스 하나가 여러개의 멀티 쓰레드니까. 상대적으로 경량화한것이다. 자원도 당연히 적게 사용한다. 메모리 공간을 복수의 쓰레드가 공유하므로 리소스 경합이 발생할 수 있다. event nginx와 유사한 전략이다. 이벤트 리스너를 사용한다. 리스닝 소켓과 기타 모든 소켓을 처리하는 각 프로세스를 위한 전용 리스너 스레드를 사용한다. apache의 장점근데 단점만 설명한것 같은데 그래도 apache를 사용해야 하는 순간이 있을 수 있다.그걸 위해서 장점이 뭐일지 알아보자.일단 단점은 곧 장점이 될수 있다.메모리를 많이 사용함은 고성능 처리에는 역으로 유리할 수 있다는 말이다.그리고 apache는 다양한 모듈이 있다.apache가 안정성, 확장성, 호환성에는 큰 장점이 있다.따라서 복잡한 cgi 처리, 동영상 데이터 전송같은 안정성이 높아야 하는 경우에는 사용하면 괜찮을 것 같다..!(근데 cgi는 이제는 사용하는 사람을 못봤다. 학교에서만 실습으로만 하는듯…)cgi는 was없이 web server에서 동적인 데이터를 처리하는 프로그램이다.Nginx위에서 apache의 경우 메모리 문제, 잦은 context-switching의 문제가 있을 수 있었다.이런 문제를 해결하기 위해서 nginx가 있다.nginx는 대용량을 트래픽을 수월하게 처리하기 위해서 가벼움과 높은 성능에 초점을 맞춘 웹서버이다.그리고 단순 웹 서버의 기능을 넘어서 reverse-proxy, load-balancing, mail-proxy, http caching의 기능들을 지원한다.nginx은 event-driven 구조를 가진다.event-driven이 무슨 말이냐..프로그램의 흐름이 event에 의해서 결정된다는 말이다.단순하게 설명하면, 하나의 thread에서 여러 request를 처리하고,event-handler에서 비동기 방식으로 request를 처리한다.request가 들어오면 해당 request를 처리하는 구체적인 흐름은 event-listener에게 맡기고,서버는 다른일을 하게 된다. -&amp;gt; 비동기이다.nginx를 깔아본 사람들은 알겠지만,service nginx start를 실행하면, system에 내장된 명령어를 통해서 nginx가 실행된다.그리고 ps -ef를 쳐보자.기본적으로 nginx가 두개의 프로세스를 사용함을 알 수 있다. -&amp;gt; 물론 더 늘릴 수도 있다.이 두개의 프로세스는 두 종류이다. master와 worder. 어떤 상황에서도 master는 1개이다. worder는 원한다면 개발자가 복수로 늘릴 수 있다.-&amp;gt; 여기서 의문이 생긴다. 원한다면 복수로 늘린다는 말은 요청의 수가 증가, 감소함에 따라서 자동으로 더 process, thread를 생성하지 않는다는 말이다. 우리가 원하는 설정대로 process의 수를 제한하는 것이다.이게 바로 apache와의 핵심 차이이다.apache가 request에 따라서 process, thread를 증가시킨다면, nginx는 제한된 수로만 운영된다.그러면 위에서 언급한 “일만개의 클라이언트 문제”를 해결할 수 있다.Nginx의 장점적은 양의 자원으로 많은 트래픽을 처리할 수 있다.요청이 많아진다고 추가적으로 자원을 사용하지 않기 때문이다.근데 당연하지만 요청이 많아지면 그거 처리는 또 쉽지 않다…! nginx는 무적이 아니다." }, { "title": "트리로 구현한 디렉토리 시스템", "url": "/posts/%ED%8A%B8%EB%A6%AC%EB%A1%9C-%EA%B5%AC%ED%98%84%ED%95%9C-%EB%94%94%EB%A0%89%ED%86%A0%EB%A6%AC-%EC%8B%9C%EC%8A%A4%ED%85%9C/", "categories": "Algorithm", "tags": "Algorithm, implementation, Tree", "date": "2022-03-21 00:00:00 +0800", "snippet": "트리를 통해 구현한 디렉토리 시스템이번에 알고리즘을 공부하면서 생각보다 구현에 있어서는 클래스를 활용하는게 좋다는 생각이 많이 들었다.그래서 가장 먼저 떠올랐던건 디렉토리 구조(파일 시스템)이었다.보통 트리 구조로 많이 구현되어 있다고 알고 있어서이번 기회에 파이썬으로 디렉토리 구조를 만들어 보았다.기능 정의 원하는 디렉토리 리스트를 받아서, 구조에 맞게 이를 트리로 구현한다. 디렉토리의 삭제 기능을 추가한다. 디렉토리 추가 가능을 만든다. 디렉토리 복사 기능을 만는다.코드import copydef addPath(Node, params): addedPath = params[0] Node.entirePath = addedPath + Node.entirePathclass Node(): def __str__(self): return self.getNodePath() def __init__(self, entirePath=None): self.entirePath = entirePath self.name = self.getNameFromEntirePath(entirePath=entirePath) self.childNodeList = [] self.parentNode = None def getNameFromEntirePath(self, entirePath): dirList = entirePath.split(&quot;\\\\&quot;) if len(dirList) == 2 and dirList[-1] == &#39;&#39;: return &quot;\\\\&quot; return dirList[-1] def haveNoChild(self): if len(self.getChildNodeList()) == 0: return True else: return False def iterNodes(self, startNode, nodeList = []): # 딸린 노드들 포함해서 반복하는 함수 if startNode.haveNoChild: return [startNode] else: for child in startNode.getChildNodeList(): nodeList.extend(self.iterNodes(child)) nodeList.extend([child]) return nodeList def iterNodes(self, startNode, func, params): # 딸린 노드들 포함해서 반복하고 노드마다 함수를 적용한다. func(startNode, params) for child in startNode.getChildNodeList(): self.iterNodes(child, func, params) def getNodeName(self): return self.name def setParentNode(self, parentNode): self.parentNode = parentNode def addChild(self, childNode): added = False if self.childNodeList == []: self.childNodeList.append(childNode) added = True else: for i in range(len(self.childNodeList)): if self.childNodeList[i].getNodeName() &amp;lt; childNode.getNodeName(): added = True self.childNodeList.insert(i, childNode) if added == False: self.childNodeList.append(childNode) def getChildNodeList(self): return self.childNodeList def getChildNode(self, name): for node in self.childNodeList: if node.getNodeName() == name: return node def getNodePath(self): return self.entirePath def getParentNode(self): return self.parentNodeclass dirTree(): def __init__(self): self.rootNode = Node(entirePath=&quot;\\\\&quot;) self.nodeCount = 1 def getRootNode(self): return self.rootNode def getParentNodePath(self, entirePath): return &quot;\\\\&quot; + &quot;\\\\&quot;.join(entirePath.split(&quot;\\\\&quot;)[1:-1]) def addNode(self, entirePath): if entirePath == &quot;\\\\&quot;: return newNode = Node(entirePath=entirePath) parentNode = self.findNode(self.getParentNodePath(entirePath=entirePath)) parentNode.addChild(newNode) newNode.setParentNode(parentNode) self.nodeCount += 1 def findNode(self, entirePath): dirListFromRoot = entirePath.split(&quot;\\\\&quot;)[1:] searchStartNode = self.rootNode # root node 인 경우 바로 반환 if entirePath == &quot;\\\\&quot;: return self.rootNode for dirName in dirListFromRoot: for childNode in searchStartNode.getChildNodeList(): if childNode.getNodeName() == dirName: searchStartNode = searchStartNode.getChildNode(dirName) break return searchStartNode def printAllNode(self, startNode): print(startNode.getNodePath()) for i in startNode.getChildNodeList(): self.printAllNode(i) def rm(self, entirePath): # 전체 패스를 통해서 노드를 찾는다. # 해당 노드에 딸린 자식 노드들을 삭제한다. findNode = self.findNode(entirePath) if len(findNode.getChildNodeList()) == 0: # 자식이 없으면 del하고 빠져나온다. parentNode = findNode.getParentNode() # 부모 노드에서 자식 노드를 담아서 노드를 지운다. parentNode.getChildNodeList().remove(findNode) # 객체도 삭제한다. del findNode else: # 자식이 있으면 다시 rm을 실행해서 leaf 노드를 찾아간다. for i in findNode.getChildNodeList(): self.rm(i.getNodePath()) # 지우고 나면 이제 부모도 지워준다. self.rm(findNode.getNodePath()) def copy(self, fromPath, toPath): # fromPath의 Node를 떼서 toPath로 붙인다. 이때 둘은 경로가 겹쳐도 무관 copiedNode = self.findNode(fromPath) copiedNode = copy.deepcopy(copiedNode) # 이제 copiedNode를 돌면서 패스를 수정해줘야 한다. copiedNode.iterNodes(startNode=copiedNode, func=addPath, params=[toPath]) # copyToNode copyToNode = self.findNode(toPath) copyToNode.addChild(copiedNode)if __name__ ==&quot;__main__&quot;: dirs = [ &quot;\\\\&quot;, &quot;\\\\root&quot;, &quot;\\\\jk&quot;, &quot;\\\\root\\\\jk1&quot;, &quot;\\\\jk\\\\jk2&quot; ] dirSystem = dirTree() ## dir 추가 끝 for dir in dirs: n = Node(entirePath=dir) dirSystem.addNode(dir) dirSystem.printAllNode(startNode=dirSystem.getRootNode()) ## dir 명령어 # 1. rm # jk 폴더 삭제 print(&quot;--rm--&quot;) dirSystem.rm(&quot;\\\\jk&quot;,) dirSystem.printAllNode(startNode=dirSystem.getRootNode()) print(&quot;------&quot;) # 2. copy # 디렉토리들을 카피해서 경로에 붙이기 dirSystem.copy(&quot;\\\\root&quot;, &quot;\\\\root\\\\jk1&quot;) print(&quot;--copy--&quot;) dirSystem.printAllNode(startNode=dirSystem.getRootNode())정리혼자 그냥 심심해서 해본건데, 생각보다 쉽지 않았다.왜냐면 단순 트리가 아니라 다중 자식을 가질 수 있는 트리이고트리의 순환을 재귀로 만들어야 했다.그리고 각 트리를 iterate하는 방법을 고안하는것도 고민을 해야했다.결국 클래스를 어떻게 만드느냐의 문제였고, 결과적으로 좋은 클래스를 만드는 방법에 대해서 시간을 투자해야 했다.어쨋든 결론은 클래스를 잘 활용할 줄 알면 어떤걸 구현하던지 실생활에 존재하는 개념을 잘 표현하는데 유리하다는 점이다." }, { "title": "URL과 URI의 차이점", "url": "/posts/URI%EC%99%80-URL%EC%9D%98-%EC%B0%A8%EC%9D%B4%EC%A0%90/", "categories": "Web", "tags": "Web, URL, URI", "date": "2022-03-20 00:00:00 +0800", "snippet": "웹 개발을 하다보면 우리는 URL이라는 단어를 참 많이 사용한다. 하지만 URL이 아닌 URI라는 단어를 봤을때 의문점을 느낄 수 있다.인터넷 주소라는 의미로 URL을 많이 썼는데 URI는 도대체 뭐지 ?나같은 경우는 OAUTH2 인증, 인가를 구현하다가 카카오 문서에서 URI라는 단어를 보고 의문점을 가졌었다.그래서 이번 기회에 둘의 차이점에 대해서 조사해봤다.사실 URL과 URI은 비슷해보이지만 엄연한 차이가 있는 개념이다.구체적으로 말하면 URI는 URL을 포함한다.URL은 Uniform Resource Locator라는 뜻이다. 즉 자원이 위치하는 곳을 의미한다. URI는 Uniform Resource Identifier이다. 자원데 대한 고유 식별자이다.그래서 생각해보면 URI는 URL을 포함할 수 밖에 없다. 자원의 위치는 식별자가 될 수 있기 때문이다.우리가 하나의 도메인에서 자원을 식별하는 방법은 크게 두가지가 있다. Query parameter path variableQuery ParameterQuery parameter는 다음과 같다. www.mysite.com/me?name=jk여기서 name = jk 는 key-value 페어가 query paramter이다.즉 자원을 필터링하는 구조다. 특정 자원을 찾고 싶은데 해당 자원의 name이 jk인것이다.Path VariablePath Variable은 다음과 같다. www.mysite.com/me/3이는 특정한 자원을 보여준다.그리고 3은 me의 내부 규약으로 매긴 특정한 자원이다.URL과 URI의 차이점그래서 둘의 다른점은 뭘까 ?위의 자원을 식별하는 두가지 방법을 생각해보자.우리는 자원을 식별한다고 했다. 즉, 두가지 방법 모두 특정 자원을 찾는데 해당 자원을 식별해서 가져온다.따라서 URI이다.그런데 URL은 자원의 위치를 말한다고 했다. www.mysite.com/me라는 건 mysite에서 me라는 경로를 나타낸다.그리고 해당 경로의 자원을 내려준다.그리고 경로는 해당 사이트에서 자원의 위치를 나타낸다.즉 위와 같은 예시는 URL을 의미한다.정리정리해보면 URI는 URL을 포함한다.자원의 경로, 위치는 자원을 식별하는데 쓰이기 때문이다.앞으로 특정 자원을 식별하는 query parameter나 path variable이 나타나면 이건 URI라고 부르도록 습관을 들이자 !" }, { "title": "백준 16935 배열 돌리기 3", "url": "/posts/%EB%B0%B1%EC%A4%80-16935/", "categories": "Algorithm", "tags": "Algorithm, implementation", "date": "2022-03-19 00:00:00 +0800", "snippet": "백준 16935 배열 돌리기3속칭 빡구현 문제인 시뮬레이션, 구현문제다.이런 유형의 문제는 답이 없다.그냥 구현하면 된다….문제를 먼저 보자.하나의 배열이 주어지고, 해당 배열에 연산을 적용하면 된다.연산의 종류는 다음과 같다. 상하 반전 좌우 반전 오른쪽으로 90도 회전 왼쪽으로 90도 회전 4개의 사분면으로 나누고 각 사분면의 시계방향 이동 4개의 사분면으로 나누고 각 사분면의 반시계방향 이동입력으로는 배열의 크기, N,M이 주어지고 수행해야 하는 연산의 수 R이 주어진다.둘째줄에는 배열이 주어진다.마지막줄에는 수행해야 하는 연산의 번호가 주어진다.자 이제 구현해보자.유의해야 하는 점은 이 문제는 노가다처럼 보이지만 머리를 좀 잘 굴리면 공식같이 변형이 가능하다.직접 공식을 만들어서 적용하는것이 중요하다.import sysdef printArray(array): for i in range(len(array)): for j in range(len(array[i])): print(array[i][j], end=&quot; &quot;) print()def operationOne(n,m,array): # 상하 반전 newArray = list() for i in range(n): newArray.append(array[n-i-1]) return newArraydef operationTwo(n,m,array): # 좌우 반전 newArray = [[0 for i in range(m)] for j in range(n)] for i in range(n): for j in range(m): newArray[i][j] = array[i][m-j-1] return newArraydef operationThree(n,m,array): # 오른쪽으로 90도 회전 연산 # col은 위치만 row로 이동 # row는 col의 n- 로 이동 newArray = [[0 for i in range(n)] for j in range(m)] for i in range(n): for j in range(m): newArray[j][n-i-1] = array[i][j] return newArraydef operationFour(n,m,array): # 왼쪽으로 90도 회전 연산 # n-col 이 row로 이동 # row는 col로 이동 newArray = [[0 for i in range(n)] for j in range(m)] for i in range(n): for j in range(m): newArray[m-j-1][i] = array[i][j] return newArraydef operationFive(n,m,array): # 시계방향 이동 # 1 -&amp;gt; 2, 2 -&amp;gt; 3, 3 -&amp;gt; 4, 4 -&amp;gt; 1 divedArray = divFour(n,m,array) newDivedArray = [divedArray[3], divedArray[0], divedArray[1], divedArray[2]] combedArray = combFour(n,m,newDivedArray) return combedArraydef operationSix(n,m,array): # 반시계방향 이동 # 1 -&amp;gt; 4, 2 -&amp;gt; 1, 3 -&amp;gt; 2, 4 -&amp;gt; 3 divedArray = divFour(n, m, array) newDivedArray = [divedArray[1], divedArray[2], divedArray[3], divedArray[0]] combedArray = combFour(n, m, newDivedArray) return combedArraydef combFour(n,m,divArray): newArray = [[0 for i in range(m)] for j in range(n)] for k,tempList in zip([[0, 0], [0, m // 2], [n // 2, m // 2], [n // 2, 0]], divArray): for i in range(n//2): for j in range(m//2): newArray[k[0] + i][k[1] + j] = tempList[i][j] return newArraydef divFour(n,m,array): divArray = [] for k in [[0,0],[0,m//2],[n//2,m//2], [n//2,0]]: temp = [] for i in range(n//2): temp2 = [] for j in range(m//2): temp2.append(array[k[0] + i][k[1] + j]) temp.append(temp2) divArray.append(temp) return divArrayif __name__ == &quot;__main__&quot;: n,m,o = map(int, sys.stdin.readline().split()) array = list() for _ in range(n): array.append(list(map(int, sys.stdin.readline().split()))) on = list(map(int, sys.stdin.readline().split())) for num in on: if num == 1: array = operationOne(n,m,array) elif num == 2: array = operationTwo(n,m,array) elif num == 3: array = operationThree(n,m,array) temp = n n = m m = temp elif num == 4: array = operationFour(n,m,array) temp = n n = m m = temp elif num == 5: array = operationFive(n,m,array) elif num == 6: array = operationSix(n,m,array) printArray(array)나름 고민한 부분은 이동에 맞는 공식을 생각하는 부분이다.그리고 4뷴면으로 나누고, 합치는 부분을 따로 작성하면복잡하게 공식을 사용하지 않고도 연산 5,6번을 해결할 수 있다 !!" }, { "title": "백준 14226 이모티콘", "url": "/posts/%EB%B0%B1%EC%A4%80-14226/", "categories": "Algorithm", "tags": "Algorithm, BFS", "date": "2022-03-18 00:00:00 +0800", "snippet": "백준 14226 이모티콘 BFS일단 문제를 읽어보면 이걸 어떻게 풀어야 할지 감이 잘 오질 않는다.한번 조건을 잘 살펴보자.시작 조건 화면에는 이미 이모티콘 1개가 있다.연산의 종류 화면에 있는 이모티콘을 모두 복사해서 클립보드에 저장한다. ctrl+c 클립보드에 있는 이모티콘을 화면에 붙여넣기 한다. ctrl+}v 화면에 있는 이모티콘 중 하나를 삭제한다. delete, backspace 모든 연산은 1초가 걸린다. 새롭게 복사를 하면 기존의 클립보드에 있던건 지워진다. 클립보드가 비어있으면 붙이기를 할 수 없다. 클립보드를 붙여넣으면 화면에 클립보드에 존재하던 이모티콘의 수 만큼 이모티콘이 추가된다.우리의 목표는 총 s개의 이모티콘을 만드는데 걸리는 최소한의 시간을 구하는 것이다. = 최소한의 연산 횟수최소한의 시간을 구한다는건 최소한의 연산 횟수를 구한다는 것이다.현재 클립보드의 상태 * 할 수 있는 연산의 종류다음과 같은 가짓수를 갖게 되고 우리가 할 일은 각 경우의 수를 살펴보면서 하나하나씩 탐색해보면 된다. -&amp;gt; 그리고 마지막에 최소 연산을 구하면 된단. !일단 BFS로 탐색해보자.현재 가능한 연산을 큐에 넣고, 큐에서 하나씩 빼면서 연산 실행하고 연산 결과에 따른 가능한 연산을 또 큐에 넣고… 이런식으로 구현해보자.방문 - 탐색에서는 2차원 list를 사용한다.방문 확인용 2차원 배열은 다음과 같은 방식으로 사용된다.visited[x][y] 를 사용하게 되는데,이때, x는 화면에 있는 이모티콘의 개수, y는 클립보드에 있는 이모티콘의 갯수이다.앞으로의 실행할 연산으로는 queue에 다음과 같이 저장한다.queue.push([x,y,t])x는 화면의 있는 이모티콘의 갯수, y는 클립보드에 있는 이모티콘의 갯수, t는 걸린 시간이다.처음에는 한개의 이모티콘이 있다고 했으니까,visited[1][0] = true 이고 queue에는 [[1,0,0]]를 push한다.queue에서 하나의 원소를 빼고 해당 x,y좌표를 true로 수정 + 원소에서 파생가능한 연산을 queue에 push.이렇게 구현하면 되겠다.codeimport sysdef bfs(visited, queue): # min time을 구하기 위한 초기값 세팅이다. 뭘해도 2000을 넘지는 않는다. min_value = 2000 # queue가 빌때까지 실행한다. while len(queue) != 0: # 하나 pop하구 pop_value = queue.popleft() # 탈출 조건 # 화면에 있는게 n개로 똑같고, min_value보다 작으면 Min_value를 갱신한다. if pop_value[0] == n and min_value &amp;gt; pop_value[2]: min_value = pop_value[2] continue # 복사 # 방문하지 않았고, min_value보다 큰 값이라면 애초에 방문할 필요가 없다. if not visited[pop_value[0]][pop_value[0]] and pop_value[2] + 1 &amp;lt; min_value: temp = [pop_value[0], pop_value[0], pop_value[2]+1] queue.append(temp) visited[pop_value[0]][pop_value[0]] = True # 븥이기 # 리스트 범위안에 들어가는지 체크하고, 방문하지 않았으며 min_value보다 크다면 애초에 실행할 필요도 없다. if pop_value[0] + pop_value[1] &amp;lt;= n and pop_value[0] + pop_value[1] &amp;gt;= 0: if not visited[pop_value[0]+pop_value[1]][pop_value[1]] and pop_value[2] + 1 &amp;lt; min_value: temp = [pop_value[0]+pop_value[1], pop_value[1], pop_value[2] + 1] visited[pop_value[0]+pop_value[1]][pop_value[1]] = True queue.append(temp) # 삭제 # 리스트 범위 체크하고, 방문하지 않았으며 min_value보다 크다면 애초에 실행할 필요도 없다. if pop_value[0] - 1 &amp;gt;= 0: if not visited[pop_value[0]-1][pop_value[1]] and pop_value[2] + 1 &amp;lt; min_value: temp = [pop_value[0]-1, pop_value[1], pop_value[2] + 1] visited[pop_value[0]-1][pop_value[1]] = True queue.append(temp) # min return # 참고로 min_value보다 작을때만 실행하는 처리 + 미리 방문 처리를 안해주면 메모리 터질 가능성이 높다..! queue에 너무 많이 쌓인다. return min_valueif __name__ == &quot;__main__&quot;: from collections import deque n = int(sys.stdin.readline().rstrip()) operationQueue = deque() visited = [[False for j in range(n+1)] for i in range(n+1)] operationQueue.append([1,0,0]) visited[1][0] = True print(bfs(visited, operationQueue))난잡하긴 한데 핵심 구현이 중요한 거니까…!중간 중간 메모리를 위한 처리를 더 깔끔하게 할 수 있겠지만 그건 각자해보자…ㅎㅎ총평하면 이 문제는 bfs로 푼다는 생각을 하기가 빡센것 같았다. 처음에는 DP인가? 했는데 어차피 dp로 해도 탐색을 깊게 해야될것 같았다." }, { "title": "백준 13549 숨바꼭질3", "url": "/posts/%EB%B0%B1%EC%A4%80-13549/", "categories": "Algorithm", "tags": "Algorithm, BFS", "date": "2022-03-17 00:00:00 +0800", "snippet": "백준 13549 숨바꼭질3 BFS 탐색숨바꼭질 시리즈다 !문제 먼저 보자.문제수빈이는 동생과 숨바꼭질을 하고 있다. 수빈이는 현재 점 N(0 ≤ N ≤ 100,000)에 있고, 동생은 점 K(0 ≤ K ≤ 100,000)에 있다. 수빈이는 걷거나 순간이동을 할 수 있다. 만약, 수빈이의 위치가 X일 때 걷는다면 1초 후에 X-1 또는 X+1로 이동하게 된다. 순간이동을 하는 경우에는 0초 후에 2*X의 위치로 이동하게 된다.수빈이와 동생의 위치가 주어졌을 때, 수빈이가 동생을 찾을 수 있는 가장 빠른 시간이 몇 초 후인지 구하는 프로그램을 작성하시오.딱봐도 수빈이의 움직임의 경우의 수를 탐색하고 최솟값을 구하는 문제같다.탐색 문제로 풀어보자.일단 조건을 잘 살펴보자. 수빈이와 동생의 위치는 수직선에 있다. 수빈이는 한칸 걸어서 움직일 수 있다. -&amp;gt; 당연히 범위 예외처리 들어가야 할것 같다. 순간이동하면 곱하기 2한 칸으로 움직인다. -&amp;gt; 이것도 예외처리.가장 빠른 시간 내에 찾아야 한다.음 딱봐도 큐를 사용해서 큐에 움직일 위치 넣고, visited에 방문 처리하면 될것 같다.수빈이의 처음위치는 n이다.따라서 visited[n]은 true로 초기화한다.queue에는 [n,t]을 push한다. n은 위치, t는 시간이다. 초기화니까 t는 0이다.초기화는 끝났구, 이제 본격적으로 반복문을 iterate하면서 값을 구하면 된다.그리고 현재 수빈이의 위치에서 이동할 수 있는 장소 n-1. n+1, 2*n을 범위가 허락한다면 시간을 t+1로 큐에 넣고 해당 장소를 visited[]에 true로 처리한다.그리고 queue에서 pop하면서 이를 반복한다.Codedef bfs(n,m,queue, visited): min_value = 100001 while len(queue) != 0: pop_value = queue.popleft() if pop_value[0] == m and min_value &amp;gt; pop_value[1]: min_value = pop_value[1] continue # 2 * 이동 if pop_value[0] * 2 &amp;lt;= 100000 and not visited[pop_value[0]*2] and pop_value[1] &amp;lt;= min_value: temp = [pop_value[0] * 2, pop_value[1]] queue.append(temp) visited[pop_value[0] * 2] = True # -1이동 if pop_value[0] - 1 &amp;gt;= 0 and not visited[pop_value[0]-1] and pop_value[1]+1 &amp;lt; min_value: temp = [pop_value[0] - 1, pop_value[1]+1] queue.append(temp) visited[pop_value[0]-1] = True # +1 이동 if pop_value[0] + 1 &amp;lt;= 100000 and not visited[pop_value[0]+1] and pop_value[1]+1 &amp;lt; min_value: temp = [pop_value[0] + 1, pop_value[1] + 1] queue.append(temp) visited[pop_value[0] + 1] = True # 참고 여기서 곱하기 이동을 큐에 가장 먼저 넣어야 한다. # 간선의 가중치가 달라서 원래는 bfs말고 다익스트라를 사용해야한다. # 굳이 bfs로 해결하려면 위와 같이 가중치가 0인 위치를 먼저 큐에 넣어야한다. 가중치가 0이기 때문에 외의 다른 이동보다 항상 t가 작기 때문에 먼저 고려해야한다. return min_valueif __name__ == &quot;__main__&quot;: from collections import deque import sys n, m = map(int, sys.stdin.readline().rstrip().split()) visited = [False for i in range(100001)] queue = deque() visited[n] = True queue.append([n,0]) print(bfs(n,m,queue,visited))곱하기 이동만 조심하면 깔끔하게 해결되는 문제였다.곱하기 이동이 가중치가 없는 이동이기 때문에 항상 곱하기 이동을 먼저해야지 최소 횟수를 구할 수 있다.그래서 먼저 큐에 push하는 부분을 잊지 말자 !" }, { "title": "백준 1261 알고스팟", "url": "/posts/%EB%B0%B1%EC%A4%80-1261/", "categories": "Algorithm", "tags": "Algorithm, BFS", "date": "2022-03-15 00:00:00 +0800", "snippet": "백준 1261 알고스팟 BFS 탐색문제 먼저 보자. 알고스팟 운영진이 모두 미로에 갇혔다.미로는 N*M 크기이며, 총 1 * 1 크기의 방으로 이루어져 있다. 미로는 빈 방 또는 벽으로 이루어져 있고, 빈 방은 자유롭게 다닐 수 있지만, 벽은 부수지 않으면 이동할 수 없다.알고스팟 운영진은 여러명이지만, 항상 모두 같은 방에 있어야 한다. 즉, 여러 명이 다른 방에 있을 수는 없다. 어떤 방에서 이동할 수 있는 방은 상하좌우로 인접한 빈 방이다. 즉, 현재 운영진이 (x, y)에 있을 때, 이동할 수 있는 방은 (x+1, y), (x, y+1), (x-1, y), (x, y-1) 이다. 단, 미로의 밖으로 이동 할 수는 없다.벽은 평소에는 이동할 수 없지만, 알고스팟의 무기 AOJ를 이용해 벽을 부수어 버릴 수 있다. 벽을 부수면, 빈 방과 동일한 방으로 변한다.만약 이 문제가 알고스팟에 있다면, 운영진들은 궁극의 무기 sudo를 이용해 벽을 한 번에 다 없애버릴 수 있지만,안타깝게도 이 문제는 Baekjoon Online Judge에 수록되어 있기 때문에, sudo를 사용할 수 없다.현재 (1, 1)에 있는 알고스팟 운영진이 (N, M)으로 이동하려면 벽을 최소 몇 개 부수어야 하는지 구하는 프로그램을 작성하시오.일단 미로가 일반적인 미로가 아니다.011111110 의 미로가 존재한다고 가정해보자. 벽을 부수면 해당 방은 0으로 바뀐다. 1,1애서 시작하고 3,3까지 가는 경우를 생각해보자.만약에 1,2 좌표의 벽을 부순다고 생각하면 다음과 같이 된다.001111110여기서 1,3을 부순다면000111110또 2,3을 부순다면000110110으로 된다. 이러면 탈출 가능하다.현재 위치를 기준으로 상 하 좌 우 의 좌표를 큐에 넣고,해당 큐에서 하나씩 pop하면서 pop 좌표의 상하좌우를 또 큐에 넣는다.물론 미로의 범위를 벗어나는 경우는 예외처리를 해줘야된다.그리고 시작 지점과 목표지점이 0으로 이어졌다면 탈출가능하게 된다.구현해보자.여기서 그냥 bfs를 사용하면 큰일난다.조심해야 하는 부분은 벽을 최소한으로 부시고 횟수를 구한다는 부분이다.그래서 벽이 없는 부분을 항상 큐에 먼저 push해야 한다. -&amp;gt; appendLeft추가로 벽이 있는 부분을 큐에 push -&amp;gt; append 하기 이전에 해당 벽에 다다르는 최소 횟수가 미리 구해진 경우가 있을 수 있다.이 경우를 잘 예외처리해주면 되는 문제다.또 큐에 지나치게 많이 쌓이는 것을 방지하기 위해서 값을 구함과 동시에 방문 처리를 해줘야 한다.그렇게 안하면 큐에 반복되서 쌓이게 된다 !def bfs(miro, col, row, visited, queue): while len(queue) != 0 : pop_value = queue.popleft() new_row = pop_value[0] new_col = pop_value[1] # 상하좌우 큐 넣기 -&amp;gt; 무조건 큐에는 벽이 없는곳을 먼저 넣어야 한다. for i,j in zip(dx, dy): # 미로 범위 체크 if new_col + i &amp;lt; col and new_row + j &amp;lt; row and new_row + j &amp;gt;= 0 and new_col + i &amp;gt;= 0: # 방문하지 않은 곳. if not visited[new_row + j][new_col + i]: temp = [new_row + j, new_col + i] # 벽이 없는 곳 먼저. if miro[new_row + j][new_col + i] == 0: visited2[new_row + j][new_col + i] = visited2[new_row][new_col] visited[new_row+j][new_col+i] = True queue.appendleft(temp) else: # 벽 있는 경우는 나중에 넣어야한다. if (visited2[new_row+j][new_col + i] != 0 and visited2[new_row][new_col] + 1 &amp;gt; visited2[new_row + j][new_col + i]): visited2[new_row + j][new_col + i] = visited2[new_row][new_col] else: visited2[new_row + j][new_col + i] = visited2[new_row][new_col] + 1 visited[new_row + j][new_col + i] = True queue.append(temp) return visited2[row-1][col-1]if __name__ == &quot;__main__&quot;: from collections import deque import sys col_num, row_num = map(int, sys.stdin.readline().split()) miro = [] for i in range(row_num): temp = sys.stdin.readline().rstrip() list_ = [i for i in temp] miro.append(list(map(int, list_))) visited = [[False for i in range(col_num)] for i in range(row_num)] visited2 = [[0 for i in range(col_num)] for i in range(row_num)] # 상하가 y좌표, 좌우가 x좌표 dx = [0,0,-1,1] dy = [1,-1,0,0] queue = deque() queue.append([0,0]) visited[0][0] = 1 print(bfs(miro, col_num, row_num, visited, queue))" }, { "title": "백준 14499 주사위 굴리기", "url": "/posts/%EB%B0%B1%EC%A4%80-14499/", "categories": "Algorithm", "tags": "Algorithm, implementation", "date": "2022-03-12 00:00:00 +0800", "snippet": "계속해서 구현문제다…문제 먼저 보자. 크기가 N×M인 지도가 존재한다.지도의 오른쪽은 동쪽, 위쪽은 북쪽이다.이 지도의 위에 주사위가 하나 놓여져 있으며, 주사위의 전개도는 아래와 같다.지도의 좌표는 (r, c)로 나타내며, r는 북쪽으로부터 떨어진 칸의 개수, c는 서쪽으로부터 떨어진 칸의 개수이다. 주사위는 지도 위에 윗 면이 1이고, 동쪽을 바라보는 방향이 3인 상태로 놓여져 있으며, 놓여져 있는 곳의 좌표는 (x, y) 이다. 가장 처음에 주사위에는 모든 면에 0이 적혀져 있다. 지도의 각 칸에는 정수가 하나씩 쓰여져 있다. 주사위를 굴렸을 때, 이동한 칸에 쓰여 있는 수가 0이면, 주사위의 바닥면에 쓰여 있는 수가 칸에 복사된다. 0이 아닌 경우에는 칸에 쓰여 있는 수가 주사위의 바닥면으로 복사되며, 칸에 쓰여 있는 수는 0이 된다. 주사위를 놓은 곳의 좌표와 이동시키는 명령이 주어졌을 때, 주사위가 이동했을 때 마다 상단에 쓰여 있는 값을 구하는 프로그램을 작성하시오. 주사위는 지도의 바깥으로 이동시킬 수 없다. 만약 바깥으로 이동시키려고 하는 경우에는 해당 명령을 무시해야 하며, 출력도 하면 안 된다.흐음…일단 문제를 보고 하나씩 기능을 생각해보자.주사위 클래스를 만들어서 하면 굉장히 편할것 같다 !주사위 클래스를 만들고, 초기화 움직임 정의 움직임 가능성 체크 정의 움직이고 나서 현재 위치 수정 움직이고 나서 맵과 주사위 downside간의 수정import sysfrom enum import Enumclass dir(Enum): east = 1 west = 2 north = 3 south = 4 def returnDir(self): return self.name def returnNum(self): return self.valueclass dice(): def __init__(self, pos): self.pos = pos self.upSide = 0 self.eastSide = 0 self.downSide = 0 self.westSide = 0 self.northSide = 0 self.southSide = 0 def changeDice(self): if myMap[self.pos[0]][self.pos[1]] == 0: myMap[self.pos[0]][self.pos[1]] = self.downSide else: self.downSide = myMap[self.pos[0]][self.pos[1]] myMap[self.pos[0]][self.pos[1]] = 0 def rollEast(self): if self.movePos(dir.east): temp = self.upSide self.upSide = self.westSide self.westSide = self.downSide self.downSide = self.eastSide self.eastSide = temp self.changeDice() return True else: return False def rollWest(self): if self.movePos(dir.west): temp = self.upSide self.upSide = self.eastSide self.eastSide = self.downSide self.downSide = self.westSide self.westSide = temp self.changeDice() return True else: return False def rollNorth(self): if self.movePos(dir.north): temp = self.upSide self.upSide = self.southSide self.southSide = self.downSide self.downSide = self.northSide self.northSide = temp self.changeDice() return True else: return False def rollSouth(self): if self.movePos(dir.south): temp = self.upSide self.upSide = self.northSide self.northSide = self.downSide self.downSide = self.southSide self.southSide = temp self.changeDice() return True else: return False def checkPosMove(self, dir): dx = [0,0,-1,1] dy = [1,-1,0,0] if dir == dir.east: new_pos = (self.pos[0] + dx[0], self.pos[1] + dy[0]) elif dir == dir.west: new_pos = (self.pos[0] + dx[1], self.pos[1] + dy[1]) elif dir == dir.north: new_pos = (self.pos[0] + dx[2], self.pos[1] + dy[2]) elif dir == dir.south: new_pos = (self.pos[0] + dx[3], self.pos[1] + dy[3]) if new_pos[0] &amp;gt;= 0 and new_pos[0] &amp;lt;= n-1 and new_pos[1] &amp;gt;= 0 and new_pos[1] &amp;lt;= m-1: return True else: return False def printDice(self): print(&quot; &quot;, self.northSide, &quot; &quot;) print(self.westSide, self.upSide, self.eastSide) print(&quot; &quot;, self.southSide, &quot; &quot;) print(&quot; &quot;, self.downSide, &quot; &quot;) def movePos(self, dir): if dir == dir.north and self.checkPosMove(dir): self.pos = (self.pos[0] - 1, self.pos[1]) elif dir == dir.south and self.checkPosMove(dir): self.pos = (self.pos[0] + 1, self.pos[1]) elif dir == dir.east and self.checkPosMove(dir): self.pos = (self.pos[0], self.pos[1] + 1) elif dir == dir.west and self.checkPosMove(dir): self.pos = (self.pos[0], self.pos[1] - 1) else: return False return True def getPresentPos(self): return self.pos def getUpsideNum(self): return self.upSideif __name__ == &quot;__main__&quot;: n, m, x, y, k = map(int, sys.stdin.readline().split()) myMap = list() for i in range(n): myMap.append(list(map(int, sys.stdin.readline().rstrip().split()))) commandList = list(map(int, sys.stdin.readline().rstrip().split())) dice = dice((x,y)) for i in commandList: if i == 1: if dice.rollEast(): print(dice.getUpsideNum()) elif i == 2: if dice.rollWest(): print(dice.getUpsideNum()) elif i == 3: if dice.rollNorth(): print(dice.getUpsideNum()) elif i == 4: if dice.rollSouth(): print(dice.getUpsideNum())아 역시 빡구현은 쉽지 않다…디버깅이 좀 힘들었다.아무래도 머리속에서 주사위 굴러가는걸 상상해야 했어서 머리가 아픈 문제였다.근데 클래스로 푸니까 쉬운것 같기도,,," }, { "title": "백준 16926 배열 돌리기1", "url": "/posts/%EB%B0%B1%EC%A4%80-16926/", "categories": "Algorithm", "tags": "Algorithm, implementation", "date": "2022-03-10 00:00:00 +0800", "snippet": "백준 16926 배열 돌리기 1배열 돌리기 1탄이다.배열 돌리는 방법도 참 다양하다…ㅎㅎ일단 문제 먼저 보자.배열을 반시계 방향으로 돌리는데, 그 방식이 조금 특이하다….그냥 돌리는게 아니라 배열의 뎁스를 생각하면서 회전시켜야 한다.각 뎁스에 맞게 회전시키는 모듈이 있으면 될것 같다 !사실 그냥 인덱스별로 풀었다.구현해보자…def printArray(n,m,array): for i in range(n): for j in range(m): print(array[i][j], end=&quot; &quot;) print()def rotate(n,m,array): newArray = [[0 for i in range(m)] for j in range(n)] for i in range(n): for j in range(m): # print(i,j) # 모서리 아닌 경우만 먼저 if (i &amp;gt; j and i + j &amp;lt; n-1 and j &amp;lt; m//2): # 밑으로 이동 # print(&quot;down&quot;) newArray[i+1][j] = array[i][j] elif ((m &amp;gt; n and j - i &amp;gt; m-n) or (n &amp;gt; m and i - j &amp;lt; n - m) or (m==n and j &amp;gt; i)) and i + j &amp;gt; m-1 and j &amp;gt;= m//2: # 위로 이동 # print(&quot;up&quot;) newArray[i - 1][j] = array[i][j] elif (i &amp;lt; j and i + j &amp;lt; m-1 and i &amp;lt; n//2): # 왼쪽 이동 # print(&quot;left&quot;) newArray[i][j-1] = array[i][j] elif ((m &amp;gt; n and j - i &amp;lt; m-n) or (n &amp;gt; m and i - j &amp;gt; n - m) or ( m==n and i &amp;gt; j)) and i + j &amp;gt; n-1 and i &amp;gt;= n//2 : # 오른쪽 이동 # print(&quot;right&quot;) newArray[i][j+1] = array[i][j] else: # print(&quot;else&quot;) # 모서리 위치 if i == j and i &amp;lt; n // 2 and j &amp;lt; m // 2: # 아래 이동 # print(&quot;down&quot;) newArray[i + 1][j] = array[i][j] elif i + j == n-1 and i &amp;gt;= n // 2 and j &amp;lt; m//2: # print(&quot;right&quot;) # 오른쪽 이동 newArray[i][j+1] = array[i][j] elif i + j == m - 1 and i &amp;lt; n // 2 and j &amp;gt;= m//2: # 왼쪽 이동 # print(&quot;left&quot;) newArray[i][j-1] = array[i][j] else: # 위로 이동 # print(&quot;up&quot;) newArray[i-1][j] = array[i][j] return newArrayif __name__ == &quot;__main__&quot;: import sys n,m,r = map(int, sys.stdin.readline().rstrip().split()) array = list() for i in range(n): array.append(list(map(int, sys.stdin.readline().rstrip().split()))) for i in range(r): array = rotate(n,m,array) printArray(n,m,array)아… 공포의 빡구현문제…정석으로 풀었다기 보다 머리를 좀 써서 인덱스별로 이동을 정의하려했다.인덱스 갖고 장난치는건 진짜 머리 아픈일이다…" }, { "title": "Restful Api란", "url": "/posts/RESTful-Api/", "categories": "Networkd", "tags": "RESTful API, API", "date": "2022-02-25 00:00:00 +0800", "snippet": "RestApi란 ?Rest Api란 말은 개발하면서 참 많이 들어보는 단어일 것이다.특히 웹 서비스를 개발한다면 클라이언트, 서버간의 통신에 api를 사용하게 된다.클라이언트는 원하는 데이터를 담아서 api 요청을 보내게 되고, 서버는 해당 요청을 받아서응답을 내려주는 것을 api를 통한 통신이라고 흔히 지칭하는데,api가 정확하게 무엇이고,또 Rest Api로 개발하는것의 중요성을 많이 얘기하는데,정확하게 Rest Api의 규격이 무엇인지 잘 모르는것 같아서 한번 정리해보려고 한다.APIAPI란 application programming interface의 약자이다.응용 프로그램에서 사용할 수 있도록 운영 체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 있게 만든 인터페이스이다.인터페이스라…처음 api의 정의에 대해서 들으면 당황스러울 것 같다.우리가 사용하는 api란 말은 클라이언트, 서버간의 통신을 의미했기 때문이다.하지만 실제로 api란 좀 더 다양하고 큰 의미로 사용한다.일단 interface란 말에 집중해보자.GUI는 그래픽을 통한 화면으로 시스템, 프로그램을 제어할 수 있는 인터페이스이다.즉 interface는 내가 원하는 기능을 정의하고 사용할 수 있게 해준다.api = application programming interface 도 interface이다.application간의 interface라고 보면 된다.즉 특 application 과 통신하거나 내가 원하는 기능을 위임하려면해당 application이 제공하는 interface인 api를 통해서 사용할 수 있다.RESTFUL APIRESTFUL API란 REST 아키텍쳐의 제약 조건을 준수하는 application programming interface이다.REST는 Representational state tranfer를 의미한다.REST란 ?REST는 protocol이나 표준이 아니라 아키텍쳐의 원칙 세트이다.그래서 누구나 rest api를 개발하지만 개발하는 방식이나 범위는 다르다.앞서서 우리는 api에 대해서 알아봤는데,웹 어플리케이션을 개발하는 사람들이 사용하는 api는 정확하게는 restful api를 지칭하는 일이 많다.물론 정확하게 restful하게 api를 설계하는 사람은 많이 없고, restful을 지향하면서 개발하게 되는것 같다.restful에서 rest란 다음의 약자이다. Representational State transfer자원의 표현을 통해서 해당 자원에 대한 정보를 주고 받는것을 의미한다.여기서 자원이란 소프트웨어가 관리하는 모든 것을 의미한다.예를 들어서 내가 간이 spring web을 만들었는데,해당 web의 기능으로는 다음이 있다. 회원가입 내 게시물 내 댓글그렇다면 이 소프트웨어에서 관리하는 자원에는 분명히 나의 id 나의 password 나의 게시물에 대한 정보 나의 댓글에 대한 정보등을 관리할 것이다. (데이터베이스나 nosql등으로…)그렇다면 클라이언트 입장에서 데이터를 받아서 화면에 렌더링해주고 싶다면,해당 정보를 서버에 요청해야 한다.그럴려면 두가지의 전제가 있어야 한다. 자원을 어떻게 표현할 것인가 ?여기서 interface의 특징이 나온다.클라이언트에서는 id라고 하고, 서버에서는 id대신에 uid라고 관리한다면 둘의 네이밍은 맞지 않게 된다.즉 자원에 대한 표현은 클라이언트는 서버의 표현을, 서버는 클라이언트의 표현에 대해서 알고 있어야 한다는 것이다.그래서 자원을 얻고 싶을때는 서버가 제공하는 interface에 따라서 질문을 던지게 된다. state의 전달예를 들어서 내가 원하는 정보가 회원에 대한 정보라고 쳐보자.그렇다면 어떤 회원인지 데이터를 관리하고 있는 서버에게 질문을 던져야 한다.예를 들어서그 회원의 id는 1번이다.그 회원의 name은 jk이다.그 회원의 age는 25이다. 등으로 말이다.즉 해당 회원 데이터를 갖고 오기 위해서는 해당 회원의 state를 전달해야 한다.여러가지 방식으로 state를 전달할 수 있다.URI를 생각해보자. URI는 자원의 위치뿐만 아니라 자원의 id(고유값)을 통해서 자원을 명시한다.여기서 자원의 id가 state가 될 수 있다.또 http body에 다음과 같은 json을 담을 수도 있다.{ &quot;id&quot; : &quot;1&quot;}이런 방식으로 state를 전달할 수 있다.정리해보면 rest란 http URI나 http body에 state를 담고여러가지 http method, GET, POST, PUT, DELETE를 통해서 해당 자원에 대한 interface를 제공하고 처리하는것을 의미한다.우리는 http protocol을 사용하기 때문에 REST API또한 http를 활용하면 된다.REST의 정의조금 더 정리해서 설명해보면 Http URI를 통해서 자원을 명시한다. HTTP method = GET, POST, PUT, DELETE를 사용한다. 자원에 대한 CRUD처리를 적용한다.REST의 구성요소 자원 - resource(어떤 자원인지) 행위 - GET, POST, PUT, DELETE 행위의 내용 - message(행위를 수행할 때 필요한 정보)RESTFUL API의 조건 늘 동일한 interface 어디서 요청이 오던 동일한 리소스에 대한 api 요청의 interface는 어떤 클라이언트에게나 적용되야 한다. 독립적인 clinet, server 두 application은 완전히 독립적이어야 한다. stateless하다. 서버의 세션을 필요로 하지 않는다. 서버 또한 client에 대한 정보를 저장하지 않는다. 캐싱이 가능해야 한다. 가급적이면 리소스를 클라이언트, 혹은 서버에서 캐싱할 수 있어야 한다. 계층 구조 클라이언트-서버 통신 중간에 다른 중개자가 있을 수 있고, 해당 중개자의 정보에 대해서는 클라이언트, 서버 둘다 고려하지 않아도 api가 작동해야 한다. 즉 interface만의 역할을 해야한다." }, { "title": "Map과 HashMap", "url": "/posts/Map%EA%B3%BCHashMap/", "categories": "Java", "tags": "Java, Map", "date": "2022-02-23 00:00:00 +0800", "snippet": "Map과 HashMap의 차이Map이던 HashMap이던 사용할 일이 굉장히 많다.실제로 실무에서 둘다 사용하는데 둘의 차이를 잘 모르고 사용하는 경우가 많다.하지만 둘은 명백한 차이점이 있다.이번 기회에 한번 그 차이점들을 정리해보자 !Map과 HashMap의 가장 큰 차이는 키에 대한 값, 즉 key-value를 찾는 과정이 다르다.HashMap은 HashTable을 통해서 key-value를 유지하고, Map은 Red-Black tree 를 사용한다.둘의 코드를 까보면, HashMap은 Map을 구현하는 구현체이다.물론 구현체는 더 다양하다.실무에서 static으로 사용할거면 concurrent hashmap을 사용해야 한다. 동시성 이슈가 있을 수 있으니까…MapMap은 key-value를 가진 집합이며, 중복을 허용하지 않는다.즉 한개의 key에 한개의 value가 매핑된다. key-value로 이뤄진 데이터의 집합이다. 순서가 존재하지 않는다. 키는 중복이 허용되지 않는다. 구현체로 TreeMap, HashTable, HashMap이 있다.HashMap HashMap은 Map interface 구현체이다. key또는 value에 null을 허용한다. 중복을 허용하지 않는다. hash 알고리즘을 통해서 구현되어 있다. -&amp;gt; 각 키값의 해시값을 버킷에 저장하고 그 값을 통해서 객체를 찾는다. O(1)의 속도이다.TreeMap 중복을 허용하지 않는다. key-value로 구성된다. SortedMap을 상속하며 key에 대한 정렬이 이루어진다.HashTableMap key-value로 구성된다. null을 허용하지 않는다.구글링해서 코드를 보다보면 Map&amp;lt;String, Object&amp;gt; map = new HashMap&amp;lt;String, Object&amp;gt;();다음과 같이 사용하는 경우가 왕왕 있는데, 다형성 때문에 이렇게 사용한다 !즉 어떤 map 구현체를 사용할지 모르니까, -&amp;gt; 변경의 여지가 있기 때문에…" }, { "title": "Python Set 자료형", "url": "/posts/python-set-%EC%82%AC%EC%9A%A9/", "categories": "Python", "tags": "Python, Set", "date": "2022-02-20 00:00:00 +0800", "snippet": "Python Set 다루기알고리즘을 공부하다 보면 set을 사용할 일이 은근 많은 것 같다.그래서 이번 기회에 공부한걸 깔끔하게 정리하고자 한다.집합 자료형이란set은 순서가 없고, 인덱스가 없는 데이터의 모음이다.파이썬 2,3부터 지원되는 자료형이다.set의 가장 큰 특징은 다음과 같다. 중복이 허용되지 않는다. 같은 set 내의 원소들 사이에는 인덱스(순서)가 존재하지 않는다.집합 자료형 선언하기 빈 집합 선언하기 setA = set() 집합을 초기화하면서 선언하기 집합을 초기화하면서 선언하는 방법은 두개가 있다. 집합 생성자 set() 함수의 파라미터를 봐보자. def __init__(self, seq=()): # known special case of set.__init__ &quot;&quot;&quot; set() -&amp;gt; new empty set object set(iterable) -&amp;gt; new set object Build an unordered collection of unique elements. # (copied from class doc) &quot;&quot;&quot; pass set(iterable)에서 iterable 한 객체는 뭐든 집합의 생성자 파라미터가 될 수 있다. iterable한 객체의 종류에는 뭐가 있을까 ? list, dict, set, str, bytes, tuple, range 이 대표적인 iterable 객체이다. 즉 위의 객체들이 iterable하며 이 객체들을 통해서 set을 만들 수 있다. list 를 통한 선언 setA = set([1,2,3]) print(setA) -&amp;gt; {1,2,3} dict 를 통한 선언 setA = set({&quot;a&quot; : 1, &quot;b&quot; : 2}) print(setA) -&amp;gt; {&quot;a&quot;, &quot;b&quot;} dict 를 통한 선언은 다음과 같이 key 값들이 set의 원소가 됨을 알 수 있다. set 을 통한 선언 setA = set({1,2}) print(setA) -&amp;gt; {1,2} str을 통한 선언 setA = set(&quot;aabcd&quot;) print(setA) -&amp;gt; {&#39;c&#39;, &#39;b&#39;, &#39;d&#39;, &#39;a&#39;} 유용하게 사용할 만한 친구들만 정리해봤다. 집합 연산집합은 여러 연산들이 있다.이건 딱히 프로그래밍한에서의 얘기가 아니라,수학에서 많이 들어본 연산이다.교집합, 차집합, 합집합들이 그 연산들이다.이런 연산들 같은 경우에는 중복이 되지 않는다는 집합의 성질때문에 굉장히 유용하게 쓰일 일이 많다.일단 샘플 집합 두개를 만들어서 하나씩 알아보자.set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) -&amp;gt; {&quot;a&quot;,&quot;b&quot;,1,&quot;2&quot;,&quot;c&quot;}set2 = set(&quot;ab221&quot;) -&amp;gt; {&quot;a&quot;,&quot;b&quot;,&quot;2&quot;,&quot;1&quot;} 교집합 set1.intersection(set2) set1 &amp;amp; set2 결과는 다음과 같다. {‘2’, ‘a’, ‘b’}{‘2’, ‘a’, ‘b’} 차집합 set1.difference(set2) set2.difference(set1) set1 - set2 set2 - set1 결과는 다음과 같다. {1, ‘c’}{‘1’}{1, ‘c’}{‘1’} 합집합 set1.union(set2) set1 | set2 {1, ‘c’, ‘1’, ‘2’, ‘b’, ‘a’}{1, ‘c’, ‘1’, ‘2’, ‘b’, ‘a’} set 내장 메소드set 내장 메소드에는 굉장히 유용한게 많다 !나도 기억해뒀다가 나중에 기회가 되면 유용하게 쓰려고 한다. add()기존 set에 새로운 원소를 추가하고 싶을때 사용한다. set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) set1.add(3) {1, 3, ‘2’, ‘b’, ‘a’, ‘c’} update()여러개의 값을 한꺼번에 추가하고 싶을때 사용한다. set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) set1.update(&quot;sav&quot;) print(set1) {‘a’, 1, ‘b’, ‘v’, ‘2’, ‘c’, ‘s’} remove(), discard()특정 값을 제거할때 사용한다.둘은 조금의 차이가 있다. remove 에서 없는 원소 삭제할 경우 set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) set1.remove(3) print(set1) key error 발생 없는 원소를 삭제하려고 하면 key error가 발생한다. remove에서 있는 원소 삭제 set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) set1.remove(&quot;a&quot;) print(set1) {1, ‘b’, ‘2’, ‘c’} discard에서 없는 원소 삭제할 경우 set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) set1.discard(3) print(set1) {‘a’, 1, ‘b’, ‘2’, ‘c’} 없는 원소를 삭제해도 key error가 발생하지 않는다. 없으면 아무 행동도 하지 않는다. discard를 사용하면 이런 차이가 있다. discard에서 있는 원소 삭제할 경우 set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) set1.discard(&quot;a&quot;) print(set1) {1, ‘b’, ‘2’, ‘c’} isdisjoint() 두 집합이 disjoint한지 = 겹치는 원소가 없는지 set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) print(set1.isdisjoint(&quot;df&quot;)) True set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) print(set1.isdisjoint(&quot;ab&quot;)) False a.issubset(b) a가 b의 subset인지 확인한다. set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) print(set1.issubset(set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;, 3]))) True set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) print(set1.issubset(set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;]))) False a.issuperset(b) a가 b의 super set인지 확인한다. set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) print(set1.issuperset(set([&quot;a&quot;,&quot;b&quot;]))) True set1 = set([&quot;a&quot;, &quot;b&quot; , 1, &quot;2&quot;, &quot;c&quot;, &quot;a&quot;]) print(set1.issuperset(set([&quot;b&quot;, &quot;f&quot;]))) False 정리set은 연산 속도도 빠르고, 중복이 없다는 큰 장점이 있다.하지만 인덱싱은 불가능하기 때문에 그걸 고려해서 사용해야 한다." }, { "title": "SOLID와 Spring", "url": "/posts/SOLID%EC%99%80Spring/", "categories": "Spring", "tags": "Spring, OOP", "date": "2022-02-17 00:00:00 +0800", "snippet": "스프링 기초스프링의 기술들스프링의 기술을 다양하다.가장 쉽게 접할 수 있는 Spring Framework, Spring Boot 부터각기 필요한 기능들을 구현하고 싶을때 사용하는 Spring Security, Spring Data, Spring session, Spring Rest Docs, Spring Batch, Spring Cloud,등이 있다.특히 스프링 부트 같은 경우에는 이 모든 기술들을 편리하게 사용할 수 있도록 도와준다.스프링 부트 같은 경우는 모든 실무에서 기본적으로 깔고 간다고 한다 - 김영한선생님.스프링 부트의 장점은 다음과 같다. 스프링을 편리하게 사용할 수 있도록 지원한다. 최근에는 모든 실무에서 기본으로 사용한다. 단독으로 실행 할 수 있는 스프링 어플리케이션을 쉽게 생성한다. Tomcat 같은 웹 서버를 내장해서 별도의 웹 서버를 설치하지 않아도 된다. 손쉬운 빌드 구성을 위한 starter 종속성을 제공한다. 스프링과 3rd party 라이브러리를 자동 구성한다. 메트릭, 상태 확인, 외부 구성같은 프로덕션 준비 기능을 제공한다. 관례에 의한 간결한 설정.왜 스프링이 필요할까 ?스프링을 사용하는 이유는 큰게 아니다.물론 웹 서버를 띄우고 데이터 베이스 커넥션을 잡아서 CRUD를 하고,다양한 기능을 제공하지만,스프링의 가장 큰 핵심은 객체 지향이다.결국 대규모의 자바 프로젝트에서 객체 지향을 지키면서 개발할 수 있게 해준다.스프링은 객체 지향의 특징중에서 다형성을 극대화해서 지원한다.의존관계 주입, IoC 컨테이너가 이런 역할을 해준다.SOLID와 스프링SOLID에 대해서 먼저 알아보자.SRPSingle Responsibility Principle의 약자이다.즉 하나의 클래스는 하나의 책임만 져야 한다.클래스가 여러 책임을 갖게 되면, 그 클래스는 각 책임에 따른 변경 이유가 발생하기 때문이다.즉 하나의 책임만 지면 하나의 변경 이유만 갖게 되는데, 책임이 여러개면 그만큼 변경될 일이 여러가지가 된다는 뜻이다.사실 책임이라는 말은 참 모호한 말이다.그래서 우리는 변경을 기준으로 잡으면 된다.예를 들어서 다음과 같은 클래스가 있다고 가정하자. public class service{ public service makeProduct() { List&amp;lt;Produce&amp;gt; produces = makeProduce(); List&amp;lt;Design&amp;gt; designs = design(produces); return develop(produces, designs); } }다음과 같은 클래스는 service하나를 만드는 과정이다.이 클래스에서는 produce를 만들고, produces를 받아서 design도 하고,그 결과로 develop을 해서 service를 반환한다.해당 클래스의 경우 1개 이상의 책임을 지고 있다.기획, 디자인, 개발 3개 이상의 책임을 지고 있는 상황에서,만약에 design에 해당하는 코드가 수정된다면,design만 수정하는것이 아닌 더 큰 클래스인 service 전체를 수정해야 한다.즉 service의 경우 변경이 발생할 수 있는 지점은 = 책임을 지고 있는 부분은produce, design, develop 세군데인 것이다.이런 클래스는 SRP를 잘 지켜서 만든 클래스가 아니다.그러면 이런 경우에 우리는 어떻게 클래스를 다시 설계해야 할까..? public class service { private Producer producer; private Designer designer; private Developer developer; public service makeProduct() { List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); return developer.develop(produces, designs); } }다음과 같이 각 책임을 따로 지고 있는 클래스를 만들어야 한다.이렇게 책임을 분산시키면 만약에 design의 코드가 수정된다고 하더라도,큰 클래스인 service가 수정될 일은 없다.즉 service의 책임 3개를 클래스 producer, designer, developer가 나눠갖는 것이다.변경이 일어나도 하나의 클래스만 수정하면 된다. !!OCPOpen/closed Principle 소프트웨어 요소는 확장에는 열려있으나, 변경에는 닫혀있어야 한다. 다형성을 활용하면 가능하다. 인터페이스를 만들고 해당 인터페이스를 재사용한다.실제로 개발을 하면서 가장 중요하게 느껴지는 원칙이다.이게 지켜지지 않으면 유지보수가 힘들어진다.인터페이스를 구현한 구현체를 새로 만들고 이를 적용하면 된다.그러면 기존 코드를 변경하지 않고도 확장이 가능하다.public class Service { private Producer producer; private Designer designer; private Developer developer; public service makeProduct() { List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); return developer.develop(produces, designs); }}해당 클래스에서 makeProduct가 바뀐다고 가정해보자.이제 단순히 produce -&amp;gt; desing -&amp;gt; develop의 절차에서조금 더 확장되서 우리가 중간에 새로운… 예를 들어서 develop의 절차를 조금 수정한다고 해보자.public class Service { private Producer producer; private Designer designer; private Developer developer; public service makeProduct() { List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); Develop = developer.develop(produces, designs) return Develop }}그러면 여기서 develop함수를 수정해야 한다.즉 변경은 불가피한것이다.그러면 OCP를 지키는 방향을 무엇일까..?일단은 makeProduct()를 인터페이스로 추상화하자.public interface MakeProductInterface { public service makeProduct();}그리고 이 인터페이스를 구현한 구현체를 만들자.아마 기존의 코드가 구현체로 구성되있다면 다음과 같을 것이다.public class Service { private Producer producer; private Designer designer; private Developer developer; private MakeProductInterface makeProduct = new MakeProductBefore(); public Service(Producer producer, Designer designer, Developer developer){ this.makeProduct = makeProduct(producer, designer, developer); }}public class MakeProductBefore implements MakeProductInterface{ @Override public service makeProduct(Producer producer, Designer designer, Developer developer){ List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); return developer.develop(produces, designs); }}여기서 새로운 구현체인 MakeProductAfter를 만들고 갈아끼우면 된다.public class Service { private Producer producer; private Designer designer; private Developer developer; private MakeProductInterface makeProduct = new MakeProductAfter(); public Service(Producer producer, Designer designer, Developer developer){ this.makeProduct = makeProduct(producer, designer, developer); }}public class MakeProductAfter implements MakeProductInterface{ @Override public service makeProduct(Producer producer, Designer designer, Developer developer){ List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); // 새로운 절차 뭔가 추가했음 return developer.develop(produces, designs); }}즉 우리는 기존 코드를 수정하지 않고 (물론 after로 수정하는 부분은 어쩔 수 없다. -&amp;gt; 스프링에서는 이걸 IoC로 더 편하게 해결한다.)새로운 구현체인 after를 만들어서 갈아끼우는 방식으로 확장에 성공했다.다형성을 사용한다고 해도 OCP를 완전하게 지키는건 어려웠다.다음에 스프링 IoC를 설명하면 다형성을 사용해서 OCP를 완전하게 지키는 방법에 대해서 알아보자.LSPLiskov Substitution Principle프로그램의 객체는 프로그램의 정확성을 깨뜨리지 않으면서 하위 타입의 인스턴스로 바꿀 수 있어야 한다.다형성을 사용하려면 상속, 구현하는 클래스, 인터페이스 내부 규약을 잘 지켜야 한다는 의미이다.예를 들어서public interface MakeProductInterface { public service makeProduct();}public class MakeProductBefore implements MakeProductInterface{ @Override public service makeProduct(Producer producer, Designer designer, Developer developer){ List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); return developer.develop(produces, designs); }}public class MakeProductAfter implements MakeProductInterface{ @Override public service makeProduct(Producer producer, Designer designer, Developer developer){ List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); // 새로운 절차 뭔가 추가했음 return developer.develop(produces, designs); }}MakeProductInterface를 구현한 두개의 구현체는 무조건적으로 MakeProductInterface가 의도한 결과물을 내야 한다.before의 결과물인 Develop과 after의 결과물인 Develop의 내부 규약이 다르거나 기능이 의도한 방향으로 작동하지 않으면 안된다.조금 더 쉬운 예시로는 우리가 스마트폰 인터페이스를 구현한 두개의 구현체 아이폰과 갤럭시가 있다고 가정했을때,새로운 구현체 jk폰을 낸다고 해보자.그런데 jk폰에서는 전화버튼을 눌렀을때 카카오톡을 실행한다.이건 LSP를 어기는 케이스이다.스마트폰 인터페이스의 내부 규약은 전화 버튼을 눌렀을때 전화가 가능해야 한다.이건 단순히 코딩의 단계에 문제가 아니라 객체를 설계하고 개발하는 단계의 이야기이다.ISPinterface segragation principle특정 클라이언트를 위한 인터페이스 여러개가 범용 인터페이스 하나보다 낫다.즉 하나의 거대한 인터페이스보다는 여러개의 인터페이스로 나누는것이 유지보수에 유리하다.예시를 들어보자.이전의 예시에서 우리는 Develop이라는 클래스가 있었다.public class Service { private Producer producer; private Designer designer; private Developer developer; private MakeProductInterface makeProduct = new MakeProduct(); public Service(Producer producer, Designer designer, Developer developer){ this.makeProduct = makeProduct(producer, designer, developer); }}public class MakeProduct implements MakeProductInterface{ @Override public service makeProduct(Producer producer, Designer designer, Developer developer){ List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); // 새로운 절차 뭔가 추가했음 return developer.develop(produces, designs); }}해당 클래스의 develop을 하나의 함수로 만들었다.음 develop 예시를 들어보면 다음과 같다.public class Developer implements DevelopInterface{ @Override public Develop develop() { return new Develop(); } }public interface DevelopInterface { public Develop develop();}develop은 사실 front develop, backend develop으로 나눠질 수 있다.그니까 기존의 develop interface를 두개의 interface로 나눈다.public interface FrontDevelopInterface { public FrontDevelop frontDevelop();}public interface BackeDevelopInterface { public BackDevelop backdevelop();}이렇게 큰 인터페이스를 작은 인터페이스로 나누면 작은 부분의 수정은 작은 부분에서 머무르게 된다.더 큰 develop 인터페이스를 수정하는 것보다 작은 interface를 수정하는것이 유지보수에 유리하다.실제로 스프링 코드를 까보면 철저하게 interface가 분리된것을 알 수 있다.DIPDependency Inversion Principle프로그래머는 추상화에 의존해야지 구체화에 의존하면 안된다.의존성 주입은 이 원칙에 따르는 방법이다.쉽게 설명하면 구현 클래스에 의존하지 말고 추상화된 인터페이스에 의존하라는 의미이다.예를 들어보자.public class Service { private Producer producer; private Designer designer; private Developer developer; private MakeProductInterface makeProduct = new MakeProduct(); public Service(Producer producer, Designer designer, Developer developer){ this.makeProduct = makeProduct(producer, designer, developer); }}public class MakeProduct implements MakeProductInterface{ @Override public service makeProduct(Producer producer, Designer designer, Developer developer){ List&amp;lt;Produce&amp;gt; produces = producer.makeProduce(); List&amp;lt;Design&amp;gt; designs = designer.design(produces); // 새로운 절차 뭔가 추가했음 return developer.develop(produces, designs); }}의 코드에서 클라이언트 코드는 service class이다.그리고 service 코드는 interface에도, 구현체인 MakeProduct에도 동시에 의존하고 있다.이건 DIP를 위반한 케이스이다.즉 우리는 다형성 하나 갖고는 DIP를 지키기는 어렵다.아무리 interface를 잘 만든다고 해도 결국에는 기존 코드를 수정해야 한다.그래서 우리가 스프링을 사용하게 된다.정리우리는 객체 지향적으로 설계하고 싶지만 다형성 하나로는 부족했다.아무리 다형성을 잘 활용한다고 해도 SOLID전부를 지킬 수는 없다….따라서 스프링이라는 프레임워크를 사용하게 된것이다." }, { "title": "객체 지향 프로그래밍 (1)", "url": "/posts/%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D(1)/", "categories": "OOP", "tags": "OOP", "date": "2022-02-15 00:00:00 +0800", "snippet": "객체 지향의 특징에는 여러가지가 있다.이번 기회에 한번 정리해보고, 실제로 스프링에서의 객체 지향이 어떻게 적용되는지까지 알아보자. 캡슐화 정보 은닉 다형성 상속 추상화이 5개 특징은 학교 수업에서도 많이 들어본 이야기이다.객체 지향적으로 프로그래밍한다는 것은 결국 이러한 특징을 잘 이용하면서 프로그래밍한다는 것이다.캡슐화캡슐화는 속성과 함수를 하나로 묶는 것이다.객체는 속성에 해당하는 데이터들과 메소드들을 갖는다.캡슐화는 이러한 정보들을 하나의 클래스에 담아서 관리함을 의미한다.객체로 캡슐화하게 되면, 객체의 세부 내용들이 외부에서 보이지 않기 때문에 변경이 발생했을 시 파급효과가 적다.예를 들어보면, 객체1이 객체2의 변수를 사용한다고 했을때, 해당 변수를 사용하는 방법은 객체2의 특정 함수를 호출해서이다.그 경우 만약에 객체2의 어떤 특징이 변화한다고 해서 객체1의 함수 호출 부분을 수정하는 일이 없다는 의미이다.정보 은닉객체1에서 객체2의 변수를 사용한다고 했을때, 다음과 같이 사용할 수 없다.객체1.변수1 = 어쩌구다음과 같이 직접 접근해서 사용하지 못하기 때문에다른 변수에서 함부로 직접 변수에 접근하는것을 막고 메소드를 통해서 접근해야만 한다.즉 객체들끼리는 함부로 객체의 변수를 알거나 접근하기가 어렵다.추상화추상화는 다음과 같다.우리가 여러 메소드를 만들때, 해당 메소드들이 가진 특성들이 중복될때가 있다.우리는 그럼 메소드들 혹은 변수들을 인터페이스 혹은 자식 클래스로 꺼낸다.즉 복잡한 기능들을 꺼내고 묶어서 보는것이 추상화이다.상속상속은 부모의 속성과 연산들을 자식들이 물려받는 것이다.이러면 개발하면서 자식 클래스를 만들때, 부모의 연산과 속성을 재정의할 필요가 없어진다.그리고 공통되는 특성들을 수정하고 싶을때, 부모 클래스를 수정하면 된다.다형성예를 들어서 특정 메시지가 있다고 해보자.더하기 메세지!이 더하기 메시지는 int 타입에게는 다음과 같이 사용된다. 1 + 2하지만 객체에서도 더하기 연산을 사용할 수 있을까 ?a + b = c이런식으로 정의한다면 객체간의 더하기 연산이 가능하다.좀 더 나아가서 생각해보자.우리가 MyServiceImpl에서 MyRepository의 구현체인 MyRepositoryImpl1을 사용한다고 생각해보자.이때 개발하면서 MyRepository의 새로운 구현체인 MyRepositoryImpl2으로 수정한다고 해보자.다형성은 이러한 상황에서 작용한다.이미 두개의 repository class는 동일한 interface를 구현했다.따라서 코드상에서 impl1에서 impl2로 교체해도 정상적으로 작동한다.즉 우리가 새로운 기능이 있는 구현체로 바꿔야 한다던가,기존의 기능을 조금 수정한 구현체로 바꿔야 한다고 하더라도,기존의 impl1을 수정할 필요가 없다.새로운 impl2를 만들고 적용시키면 된다.다형성은 객체 지향의 가장 큰 장점이다.객체 지향적으로 프로그래밍하는 것의 가장 큰 장점은 변경을 하지 않고 확장에는 용이하다는 것이다.다형성을 잘 활용하면 기존의 코드를 수정하지 않고 새로운 코드를 추가함으로써 확장할 수 있었다.코드를 변경하는 일은 사실 참 무서운 일이다.해당 코드를 어디서 사용하는지 직접 팔로우를 하고 있어야 하며,그 수정에 의한 파급효과가 발생하는지 체크해야 한다.하지만 다형성을 잘 활용하면 수정을 하지 않고 다른 블럭으로 교체하면서 수정이 가능하다." }, { "title": "Spring 의존관계 (2)", "url": "/posts/Spring-%EC%9D%98%EC%A1%B4%EA%B4%80%EA%B3%842/", "categories": "Spring", "tags": "Spring, Dependency Injection", "date": "2022-02-11 00:00:00 +0800", "snippet": "Spring 의존관계 (2)앞서 자바에서 의존관계를 어떻게 주입하는지, 또 의존관계를 어떻게 하면추상화 객체와 인터페이스를 사용해서 확장에 유리하게 주입하는지 알아봤다.의존관계 주입이라는 용어도 알아봤는데,런타임시에 어떤 구현체와 관계를 맺을지 결정하는 것이다.토비의 스프링에서는 의존관계 주입을 다음과 같이 설명한다. 클래스 모델이나 코드에는 런타임시점의 의존관계가 드러나지 않는다. 그러기 위해서는 인터페이스에 의존해야 한다. 런타임 시점의 의존관계는 컨테이너나 팩토리같은 제 3의 존재가 결정한다. (Potato인지 Combination인지) 의존관계는 사용할 오브젝트에 대한 레퍼런스를 외부에서 제공해줌으로써 만들어진다.여기서 제 3의 존재는 Appication Context, Bean Factory, Ioc Container 를 의미한다.public I() { Pizza pizza = new PotatoPizza();}의 코드의 문제점은 런타임시에 어떤 구현체와 의존관계를 맺을지 이미 코드레벨에서 결정되어 있다는 점이다.따라서 스프링에서는 IoC 방식을 사용해서 런타임 시점의 의존관계를 이미 보여주는 코드를 제거하고,구현체가 아닌 인터페이스를 파라미터로 받는다.그리고 해당 인터페이스의 구현체는 제 3의 존재가 결정한다.다음과 같다.import Spring.Pizza;import Spring.PotatoPizza;// 런타임 시에 의존관계가 드러나지 않도록 한다.public class I() { private Pizza pizza;}// 제 3의 존재가 어떤 구현체와 의존관계를 맺을지 결정한다.public class PizzaFactory() { public I i() { return new i(Pizza()); } public Pizza pizza() { return new PotatoPizza(); }}public class I() { private Pizza pizza; public I(Pizza pizza) { this.pizza = pizza; }}위와 같은 방식을 사용하면 런타임시 의존관계가 들러나지 않고 제 3의 존재 PizzaFactory가 외부에서 의존관계를 결정한다.. 그리고 PizzaFactory에서 생성자를 통해 의존관계를 주입힌다.위에서 의존관계를 결정하는 것을 컨테이너라고 부른다고 했다.따라서 PizzaFactory는 DI Factory이다.이제 스프링에서 어떻게 의존관계를 주입하고 또 가장 적절한 방법이 뭔지 알아보자.스프링에서 의존관계 주입 방식은 총 4가지이다. 필드 주입 setter 주입 일반 메소드 주입 생성자 주입4가지의 방법 전부 클래스 변수를 어떻게 설정하느냐에 따라 달렸다.필드 주입필드에 바로 주입하는 방식이다. 코드가 간결하다는 장점이 있다. 외부에서 변경이 불가능하다는 치명적인 단점이 있다. 테스트 코드나 config 클래스에서 주로 사용한다.필드 주입은 다음과 같다.@Servicepublic class OrderServiceImpl implements OrderService { /** * 필드 주입 */ @Autowired private OrderRepository orderRepository; }다음과 같이 해당 클래스 변수를 선언하고 위에 어노테이션 @Autowired를 사용한다.@Autowired가 부은 변수에 의존 객체를 주입하게 된다.해당 방법 같이 사용하면 어떤 문제가 있을까 ?public static void main(String[] args) { OrderServiceImpl orderService = new OrderServiceImpl(); }위와 같은 코드에서 내가 원하는대로 OrderRepository를 주입할 수 없다는 치명적인 단점이 있다.의존하는 객체가 바뀐다고 해도 변경하려면 직접 클래스의 코드를 수정해야 한다.간결하지만 가장 큰 문제가 있는 코드가 될 수 있다.setter 주입이전 포스트에서 작성한 의존관계 주입 코드가 setter를 이용한 의존관계 주입이다.@Servicepublic class OrderServiceImpl implements OrderService { /** * setter 주입 */ private OrderRepository orderRepository; @AutoWired public void setOrderRepository(OrderRepository orderRepository) { this.orderRepository = orderRepository; } }위와 같이 setter함수를 따로 만든다.그리고 setter 함수 위에 @Autowired 어노테이션을 붙인다.public static void main(String[] args) { OrderServiceImpl orderService = new OrderServiceImpl(); orderService.setOrderRepository(new OrderRepository());}그러면 위와 같은 방식으로 외부에서 setter를 통해서 원하는 repository를 주입할 수 있다.setter함수는 public으로 언제나 열려있으니, 선택, 변경의 가능성이 있는 의존관계에 사용한다.생성자 주입가장 마지막 방법인 생성자 주입이다.실제로 스프링에서 가장 권고하는 방법이기도 하다.코드로 살펴보고 왜 가장 좋은 방법이라고 하는지 그 이유도 알아보자.@Servicepublic class OrderServiceImpl implements OrderService { /** * 생성자 주입 */ private OrderRepository orderRepository; @Autowired public OrderServiceImpl(OrderRepository orderRepository) { this.orderRepository = orderRepository; }}위와 같은 방식이 생성자 주입 방식이다.외부에서는 어떻게 호출할까 ??public static void main(String[] args) { OrderServiceImpl orderService = new OrderServiceImpl(new OrderRepository());}다음과 같이 클래스를 생성할때 생성자에 파라미터로 원하는 repository를 넣는다.그렇다면 왜 생성자 주입 방식이 가장 좋다는 것일까 ?그 이유는 다음과 같다. 생성자 호출시점에 딱 1번 의존관계가 결정된다.실제로 개발을 하다보면 의존관계를 중간에 변경할 일은 거의 없다. 오히려 중간에 변경하면 문제가 될 수 있다.따라서 딱 1번으로 주입을 제한시키는것이 안전하다. 객체 지향적으로도 변경에 닫혀있는 방식이다. 무엇보다 스프링 빈은싱글톤이다. 값을 막 중간에 바꾸면 큰일난다. 테스트 코드 작성시 유리하다. 순수 자바 코드를 통해 스프링 단위 테스트를 진행한다고 가정하자. 테스트 코드가 spring 위에서 작동하지 않는다.따라서 테스트 하려는 코드에 주입받은 객체의 함수를 실행하거나 한다면, NullPointerException이 뜰것이다.만약에 생성자 패턴을 사용한다면, 컴파일 시점에 객체를 주입받을 수 있다.그렇다고 setter를 사용하면 싱글톤 기반의 객체의 변수를 마음대로 바꿀 수 있게 된다. 순환 참조를 방지한다.두개의 객체가 서로에 대해서 의존관계를 갖고 있다면 어떻게 될까 ?생성자가 호출되는 시점(스프링 빈이 생성되는 시점)에서 에러를 발생시키기 때문에 훨씬 안전하다.생성자가 아니라 필드 주입을 사용하면 무한하게 서로가 호출되는 상황이 발생한다.다음과 같은 이유로 생성자 주입 방식을 권장한다.그리고 개발하다보면 불편하게 생성자를 다 만들 필요도 없어진다.생성자 주입 방식으로 빠르고 간편하게 개발하는 방법이 있다.Lombok과 final을 사용하면 다음과 같은 코드로 간편하게 생성자 주입 방식을 사용할 수 있다.import lombok.RequiredArgsConstructor;@Service@RequiredArgsConstructorpublic class OrderServiceImpl implements OrderService { /** * 생성자 주입 */ private final OrderRepository orderRepository;}위와 같은 방식으로 사용하면 아주 편하다.Lombok의 @RequiredArgsConstructor를 사용하면 자동으로 생성자를 만들어 주고,final을 통해서 컴파일 시점에 해당 객체가 있는지 확인한다.또한 스프링에서는 생성자가 1개인 경우에 자동으로 @Autowired를 생략해도 되기때문에아주 편하게 생성자 주입이 가능하다.정리스프링의 의존관계 주입 종류에 대해서 알아보았다.기계처럼 롬복 + final만 썼다가 이렇게 원리를 자세하게 정리하니까 아주 좋다.또한 객체 지향은 도대체 어디까지 얽혀있는건가 하는 무서운 생각이 든다.다음에는 오늘 포스트에서 썼던 키워드인SOLID, IoC, Singleton 에 대해서 정리해볼 생각이다.끝 !!" }, { "title": "Spring 의존관계 (1)", "url": "/posts/Spring-%EC%9D%98%EC%A1%B4%EA%B4%80%EA%B3%841/", "categories": "Spring", "tags": "Spring, Dependency Injection", "date": "2022-02-10 00:00:00 +0800", "snippet": "의존 관계Spring에서는 의존관계를 잘 설정해야 한다.사실 Spring에서는 규격으로 정해진 방법이 있다.해당 방법을 사용하면 무탈하게 개발할 수는 있으나다른 방법들도 존재한다.Spring에서 어떻게 의존관계를 설정하는지 알아보기 전에일단 의존관계가 무엇인지 부터 차근차근 알아보자.의존관계한번 생각해보자.내가 피자를 먹는다.내가 피자를 먹을때마다 피자의 양은 줄을 것이다.피자를 먹는 주체는 누구인가 ? 바로 “나”다.하지만 객체지향의 세계에서는 이야기가 조금 다르다.피자를 먹는 함수인 eatPizza는 나에게 있겠지만,eatPizza를 호출하면 피자가 스스로 자신의 양을 줄이는 함수를 호출한다.코드로 살펴볼까 ?public class I { // 내 이름 private String name; // 내 피자 private Pizza pizza; // 피자를 먹는 함수 public void eatPizza() throws IllegalAccessException { // 피자의 내부 메소드인 eaten()을 호출한다. pizza.eaten(); }}public class Pizza { // 남은 피자 조각 수 private int leftPiece; // 생성자 (항상 8개의 조각으로 초기화한다.) public Pizza() { this.leftPiece = 8; } // 피자를 먹으면 조각이 하나 준다. 남은 조각이 없으면 에러를 던진다. public void eaten() throws IllegalAccessException { if (this.leftPiece == 0) { throw new IllegalAccessException(&quot;No left Piece !&quot;); } this.leftPiece -= 1; }}public static void main(String[] args) throws IllegalAccessException { I i = new I(); i.eatPizza(); }만약 I라는 클래스에 pizza가 없다면 피자를 먹는 I(나)는 피자를 먹을 수 없다.즉, I 클래스는 Pizza 클래스를 필요로 한다.이렇게 I클래스가 eatPizza()를 호출하기 위해서는 pizza가 필요하다.즉 pizza 객체를 I내부에 갖고 있어야 한다.이런 경우에 우리는 I는 Pizza에 의존한다. 라고 표현한다.다형성과 Dependency Inversion우리가 애플리케이션을 만들때 많은 인터페이스 또는 추상화 객체를 사용한다.위의 코드에도 인터페이스 또는 추상화 객체를 사용하지 않고 피자의 종류를 늘려보면 어떻게 될까우리는 Combination 피자 또는 Potato Pizza를 먹을거다.그리고 그 둘은 일반 피자보다 더 맛있어서 한번 먹을때마다 더 많은 조각을 먹게된다.코드로 살펴보자.public class I { private String name; private CombinationPizza pizza; public void setPizza(CombinationPizza pizza) { this.pizza = pizza; } public void eatPizza() throws IllegalAccessException { pizza.eaten(); }}public class PotatoPizza{ private int leftPiece; public void eaten() throws IllegalAccessException { if (this.leftPiece &amp;lt;= 0) { throw new IllegalAccessException(&quot;No left Piece !&quot;); } this.leftPiece -= 2; }}public class CombinationPizza{ private int leftPiece; public void eaten() throws IllegalAccessException { if (this.leftPiece &amp;lt;= 0) { throw new IllegalAccessException(&quot;No left Piece !&quot;); } this.leftPiece -= 3; }}우리가 이렇게 코드를 작성하면 나중에 유지보수가 정말 힘들어 진다…내가 Combination 을 먹다가 나중에 Potato로 바꾼다면 뒤에 나오는 로직을 직접 수정하게 될 수도 있고,클래스에서 먹는 피자의 종류 타입도 바꿔주고 피자가 쓰인 코드를 일일히 다 찾아서 combination에서 potato로 수정해야 한다.이런 현상을 방지하기 위해서 인터페이스와 추상화 객체가 있다.객체지향 방법론에서 가장 유명한 단어인 SOLID라는 단어를 들어봤을 것이다.거기서 가장 마지막 D는 Dependency inversion이다.결국 위의 코드는 DI 규칙이 제대로 지켜지지 않았다.다른 말로 설명하면 인터페이스와 추상화 객체를 적절하게 사용하지 않았다.만약 내가 먹고 싶은 피자가 Combination이 아니라 Potato면 어떻게 될까..?실제로 한번 해보자.import Spring.PotatoPizza;public class I { private String name; private PotatoPizza pizza; public void setPizza(PotatoPizza pizza) { this.pizza = pizza; } public void eatPizza() throws IllegalAccessException { pizza.eaten(); }}다음과 같이 일일히 코드를 수정해줘야 한다.만약에 내가 제대로 피자집을 차려서 피자의 수가 몇십개가 된다면 ??매번 코드를 수정해야 하는 대 참사가 발생한다.DI를 제대로 지키려면 다음과 같은 코드로 수정해야 한다.public class I { private String name; private Pizza pizza; public void setPizza(Pizza pizza) { this.pizza = pizza; } public void eatPizza() throws IllegalAccessException { pizza.eaten(); }}public class PotatoPizza extends Pizza{ @Override public void eaten() throws IllegalAccessException { if (this.leftPiece == 0) { throw new IllegalAccessException(&quot;No left Piece !&quot;); } this.leftPiece -= 2; }}public class CombinationPizza extends Pizza{ @Override public void eaten() throws IllegalAccessException { if (this.leftPiece == 0) { throw new IllegalAccessException(&quot;No left Piece !&quot;); } this.leftPiece -= 3; }}이렇게 상속을 통해서 해결할 수 있다.이러면 Pizza 객체를 상속받은 다른 여러피자를 난 원할때마다 코드의 수정이 없이 먹을 수 있다.위와 같은 코드가 DI를 제대로 지킨 코드라고 볼 수 있는데,기존의 의존성을 역전해서, 더이상 I는 피자의 종류에 의존하지 않게 된다.어떤 피자던 피자이기만 한다면 바꿀 수 있다.이처럼 DI를 지키면서 프로그래밍을 하면 확장성이 높고 재사용성이 높은 코드를 작성할 수 있다.이 과정을 정리하면, I는 Pizza라는 추상객체 또는 인터페이스에 의존한다.하지만 Pizza를 상속받은 Potato와 Comvination 객체(구현체)는 I와 의존관계가 없다.I는 Potato와 Combination이라는 객체에 대해서 아예 모른다.즉 추상화 객체 또는 인터페이스와의 의존관계만 만들어주면, 실제 구현체와는 의존관계의 정도가 낮아진다.결합도가 낮아진다.결합도 낮아지니까 다른 구현체를 추가해도 상관없다.다시 의존관계로 돌아가자.의존관계 주입의존관계를 주입한다는 건 무슨 말일까 ?앞에서는 의존관계에 대해서 알아보았다.의존관계 주입이라는 말은 런타임시에 오브젝트 사이에 만들어지는 의존관계를 의미한다.런타임 전에는 I는 실제 런타임시 사용할 오브젝트 무엇인지 모른다.의존관계 주입은 구체적인 의존 객체 여기서는 구현체(Combination, Potato)와 그것을 사용할 객체(I)를 런타임에 연결시켜주는 것을 의미한다.위의 DI가 지켜지지 않은 코드에서는 개발자가 원하는대로 의존관계를 주입하기 힘들었다.I - Combination 에서 I - Potato로의 변경(주입) 을 하려면 다시 코드를 수정해야 했다.개발자가 편하게 의존관계를 주입하는 코드는 DI를 지킨 밑의 코드다.예시를 들어보자.public class I { private Pizza pizza; public Pizza getPizza() { return this.pizza; } public void setPizza(Pizza pizza) { this.pizza = pizza; } public void eatPizza() throws IllegalAccessException { pizza.eaten(); } public static void main(String[] args) throws IllegalAccessException { // 의존관계를 주입하자. I i = new I(); // 처음에는 Combination으로 CombinationPizza combinationPizza = new CombinationPizza(); // 의존관계 주입. I의 Pizza는 Combination으로. i.setPizza(combinationPizza); // 피자 먹기 i.eatPizza(); // 피자 몇 조각 남았니 System.out.println(&quot;combinationPizza left piece = &quot; + i.getPizza().myLeftPiece()); // 나중에는 Potato로. PotatoPizza potatoPizza = new PotatoPizza(); // 의존관계 주입. 이번에는 Potato로. i.setPizza(potatoPizza); // 피자 먹기 i.eatPizza(); // 피자 몇조각 남았니 System.out.println(&quot;potatoPizza left piece = &quot; + i.getPizza().myLeftPiece()); } /** * 출력 * combinationPizza left piece = 5 * potatoPizza left piece = 6 */}즉 메인 메소드에서 원하는대로 내가 먹을 피자를 변경하는 것이 의존관계를 외부에서 주입하는 것이다.이러기 위해서 인터페이스와 추상화 객체를 적절하게 사용해야 한다.왜냐면, 클래스 모델(I)만을 봤을때는 어떤 피자를 먹을지 드러나지 않는다.= 사실 어떤 피자던 먹을 수 있어야 한다.위의 코드를 보자.내가 먹을 피자의 종류를 굳이 I 클래스 내부의 변수와 메소드를 수정하지 않고도수정할 수 있었다.SOLID 원칙에서 DI를 지킨 코드지만 사실은 ORP도 지켰다.다른 피자를 추가해도 해당 피자가 Pizza만 상속받으면 코드는 확장에는 열려있고 변경에는 닫혀있다.의존관계 주입의 여러 방법자바 의존관계 주입에는 여러 방법이 있다. setter constructor field위의 예시에는 1번 setter 형식을 사용해서 의존관계를 주입했다.스프링을 하면서 의존관계 주입에는 생성자 패턴인 좋다라고 외웠다.그 이유에 대해서는 큰 고찰이 없이 개발을 했었다.다음에는 각 의존관계 주입의 방법들을 분석하고 비교해보자.실제로 왜 생성자 패턴이 좋을지 검증해보자.끝 !" }, { "title": "spring security (2)", "url": "/posts/spring-security(2)/", "categories": "Spring", "tags": "인증/인가, Spring Security", "date": "2022-02-09 00:00:00 +0800", "snippet": "Servlet Authentication Architecture이전에 우리는 스프링 시큐리티에서 서블렛 딴의 구조를 알아봤다.즉 하나의 요청이 들어오고 어떻게 필터를 거치는지에 대해서 알아봤다.이번에는 spring security의 authentication의 구체적인 구조를 알아보자.서블렛 객체가 httprequest를 갖기 이전에 필터를 거친다고 했다.하지만 필터에서 제대로 걸러진다면 서블렛까지 요청이 도달하지 못한다.필터에서는 어떤 기준으로 요청을 거르는 걸까 ??전에도 설명했듯이 당연히 인증/인가의 과정이다. 적합한 유저인지 권한이 있는 유저인지스프링은 여러 레이어와 구조를 갖고 해당 인증/인가를 수행한다.여기에 어떤 구조들이 존재하는지 알아보자.Security Context HolderSecurity Context Holder는 스프링 시큐리티에서 핵심적인 역할을 한다.말그래도 Security Context를 포함한다.무슨 말이냐, 누가 적합한 유저인지 그 디테일을 갖고 있다.여기에 유저에 대한 값이 있으면 적합한 유저이다.위의 그림을 보자.context holder가 context를 갖고 있고,이 context안에는 authenticaiton이 존재한다.그리고 authentication 에는 세가지 종류 Principal, Credential, Authorities가 존재한다.먼저 각 용어들이 무엇을 의미하는지 살펴보자. Security Context는 authentication 객체들을 갖고 있다. Authentication은 authenticaiton manager의 input으로 해당 유저의 Principal, Credentials, Authorities에 대한 정보를 갖는다. Principal은 유저의 id를 의미한다. UserDetail의 인스턴스이다. Credential은 유저의 비밀번호다. Authorities는 권한이다. roles나 scope를 의미한다.일단은 대애충 훑어봤다. 더 자세한건 밑에서 다뤄보자.특정 유저가 적합한 유저라고 알려주고 싶다면 가장 빠른 방법은 이 context holder에 해당 유저에 대한 값을 넣어주면 된다.코드로 살펴보자.SecurityContext context = SecurityContextHolder.createEmptyContext();Authentication authentication =new TestingAuthenticationToken(&quot;username&quot;, &quot;password&quot;, &quot;ROLE_USER&quot;);context.setAuthentication(authentication);SecurityContextHolder.setContext(context);코드에서는 특정 유저에 대한 authentication 객체를 만든다음에 context holder의 빈 컨텍스트에 직접 넣어주고 있다.만약에 context에서 유저에 대한 정보를 갖고 오고 싶을 경우에는 어떻게 할까 ?SecurityContext context = SecurityContextHolder.getContext();Authentication authentication = context.getAuthentication();String username = authentication.getName();Object principal = authentication.getPrincipal();Collection&amp;lt;? extends GrantedAuthority&amp;gt; authorities = authentication.getAuthorities();여기서는 컨텍스트를 갖고와서 authentication객체에서 유저에 대한 정보를 갖고 온다.일단은 다음과 같은 방식으로 진행된다.Security ContextSecurity Context Holder에 의해서 유지되고, authentication 객체를 갖는다.Authentication유저는 authentication 객체를 생성한다.그리고 이 객체는 secutiry context에 의해서 보관되고 사용된다.두가지의 목적이 있는데, authentication manager의 input이다. 초기에 유저가 만들고 authentication manager에서 인증 과정을 거치기 전에 생성된다고 보면 된다. 이 경우에는 아직 isAuthenticated는 false이다.그니까 무슨 말이냐면 처음에 로그인을 시도하면 아직은 authentication 객체가 없는 상태이다.그래서 처음 만들고 authentication manager의 input으로 들어가서 실제 인증 과정을 거친다는 의미이다. Security context에 저장되서 적합한 유저의 데이터를 갖고 있다.authenticaiton 에는 세가지 부분이 있다고 했다. principal : 사용자의 아이디를 의미하는 경우가 많다. credentials : 사용자의 비밀번호 authorities : 사용자의 권한authentication 인터페이스를 살펴보자.public interface Authentication extends Principal, Serializable { Collection&amp;lt;? extends GrantedAuthority&amp;gt; getAuthorities(); // Authentication 저장소에 의해 인증된 사용자의 권한 목록 Object getCredentials(); Object getDetails(); Object getPrincipal(); boolean isAuthenticated(); void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException;}이렇게 ID, 비밀번호, 권한, 인증 여부, 디테일을 반환하는 함수들이 있다.Authentication Manager스프링 시큐리티가 어떻게 인증을 구현할지에 대해 정의하는 api이다.authentication manager가 로그인시 authentication을 생성하고 이를 security context에 저장하는 역할을 한다.구현체로는 가장 대표적으로 provide manager가 사용된다.Provide managerAuthentication Manager의 구현체이다.Provide Manager는 다수의 authentication provider를 대리한다.하나의 authentication provider는 해당 authentication의 성공, 실패를 결정할 수 있다.만약의 다수의 authentication provider가 다 처리할 수 없는 authentication의 경우ProviderNotFoundException이 발생한다.각각의 authentication provider는 다른 종류의 authentication을 수행한다.Authentication Provider여러개의 authentication provider가 위의 provider manager에 주입되는데,각각의 authentication provider는 다른 종류의 authentication을 수행한다.Authentication Entry Point와authentication entry point는 말그대로 인증의 진입점이다. 이 진입점에서는 client에게 response를 보내는 역할을 하게 된다.무슨 response냐면, 만약 유저가 인증이 안된 유저이면 인증을 요청하는 response를 보낸다.예를 들면 리다이렉를 수행하게 한다던지…만약 인증이 된 유저라면 인증 요청 response를 보낼 필요가 없고 유저의 요청에 응답하면 되기 때문에항상 response를 보내지는 않는다.Abstract Authentication Processing FilterAbstract Authentication Processing Filter는 security filter chain에 포함되서인증된 유저인지 필터링한다.시나리오는 다음과 같다. abstract authentication processing filter에서 해당 요청에 인증이 되어 있는지 하기 위해서 authentication 객체를 생성한다. 그리고 이 authentication 객체는 authentication manager로 보내진다. authentication manager의 구현체인 authentication provider가 실제 인증을 수행하고 성공과 실패에 따라서 다른 분기를 타게 된다. 실제로는 다른 핸들러가 처리하게 되는거다.그림에서 위의 시나리오가 잘 설명되어 있다.하지만 실제의 구현의 abstract Authentication Filter를 사용하지 않는다.이건 추상화된 필터고 이 추상화 객체를 구현한 구현체 예를 들면,UsernamePasswordAuthenticationFilter 같은걸 사용하게 된다.위의 그림에서는 전부 구현체가 없다.실제로 구현해보자..!드디어 구현이다.지루한 이론에 대해서 훑어봤으니 실제로 어떻게 작동되는지 직접 구현해보자…!위에서 설명한 인터페이스들을 실제로 어떤 구현체를 사용할지 정해야하고spring security를 좀 편리하게 사용하는 방법에 대해서 알아보자.근데 이건 다음 시간에…" }, { "title": "spring security (1)", "url": "/posts/spring-security(1)/", "categories": "Spring", "tags": "인증/인가, Spring Security", "date": "2022-02-08 00:00:00 +0800", "snippet": "Spring SecuritySpring Security에 대해서 알아볼 시간이 됬다 !지난 시간동안 개발하면서 스프링을 사용했고, 스프링 시큐리티는 필수로 사용했는데 깊은 이해가 없이 진행했었다.따라서 이번 기회에 한번 정리해볼 생각이다.지난 포스트들에서 우리는 인증/인가, 토큰/세션, 대표적인 토큰 JWT에 대해서 정리했다.이번에는 스프링 시큐리티에 대해서 정리하고, 이 스프링의 하위 프레임워크가 인증/인가, 토큰/세션이라는키워드와 어떤 연관이 있는지 알아보자.그리고 이번 spring security를 정리하면서 코드를 통해서 기본적인 security를 구현해볼 생각이고,다음 포스트에서는 oauth2 -&amp;gt; spring security + oauth2 에 대해서 알아보고 구현해볼 생각이다.여기에 정리하는 대부분의 내용은 spring 공식 문서에 정리되어 있는 내용이다.필요한 사람은 공식 문서를 보면 되겠다.https://docs.spring.io/spring-security/reference/index.htmlSpring Security란 뭘까 ?Spring 이라는 걸출한 프레임워크는 거대한 생태계로 유명하다.정말로 여러가지 기능들을 인터페이스로 제공한다.우리는 필요한 인터페이스를 구현하면 된다.스프리에서 보안을 담당하는 하위 프레임워크가 spring security이다.여기서의 보안은 인증/인가/공격방어 를 의미한다.이런 기능들을 개발자 입장에서 편리하고 간편하게 구현할 수 있도록 인터페이스를 제공한다.많은 보안 관련 옵션을 제공해주기 때문에 개발자 입장에서는 정말 간편하다.Spring security의 종류총 두가지이다. Servlet application Reactive application그 중 우리는 Servlet application에 대해서 다뤄볼 예정이다.간단하게 종류에 대해서만 설명해보면,Servlet applcation은 Spring Security integrates with the Servlet Container by using a standard Servlet Filter. This means it works with any application that runs in a Servlet Container. More concretely, you do not need to use Spring in your Servlet-based application to take advantage of Spring Security.다음과 같다. 무슨 말이냐면, 스프링 시큐리티는 서블릿 컨테이너와 결합되는데, 뭘 이용해서 결합하냐, 표쥰 서블릿 필터를 이용해서다.이게 무슨 말이냐면 서블릿 컨테이너에서는 스프링을 굳이 사용하지 않아도 스프링 시큐리티를 사용할 수 있다는 의미이다.핵심만 요약하면 서블릿 컨테이너에서의 보안 서블릿 필터를 사용여기에 있는 용어중에 서블릿 필터는 모를 수 있어도 서블릿 컨테이너는 알고 가야 한다.서블릿 컨테이너는 나중에 was + spring application 에 대해서 다루면서 자세히 정리할 예정이지만,간단하게만 설명하면, 서블릿들의 컨테이너. 서블릿들을 모아서 관리하는게 서블릿 컨테이너이다.이게 얘기가 길어질 수 밖에 없는데,서블릿은 클라이언트에서 서버로 보낸 요청을 처리하고 서버가 반환해주는 일련의 프로세스를 처리하는 자바의 인터페이스이다.그냥 요청이 오면 서블릿이 생긴다고 편하게 생각하자 !그런 서블릿을 모아서 관리하고 동작시킬 수 있는 환경을 제공하는게 서블릿 컨테이너이며,대표적인 얘로는 톰캣이 있다. 톰캣 설치할때 JRE이 필요한 이유가 자바에 종속되있기 때문이다.서블릿 컨테이너는 요청이 올때마다 새로운 스레드를 생성하고 요청에 맞는 서블릿 객체를 생성한다.그리고 스레드가 이 서블릿 객체를 맡게 된다.그래서 클라이언트 요청 반환의 프로세스를 이 서블릿 객체를 통해서 스레드가 처리한다.어쨋든 다시 돌아가면, 서블릿 컨테이너에서의 보안을 할 수 있게 해준다.스프링을 사용하지 않아도 자바 진영에서는 사용할 수 있다느 얘기이다.뭐 이건 그렇게 중요한 이야기는 아니고스프링 시큐리티의 핵심은 서블릿 필터이다.핵심으로 들어가기 전에 코드로 한번 정체를 확인해보자.서블릿 필터위에서 spring security의 servlet application에 대해서 이야기 했다.스프링 시큐리티는 서블렛 필터에 기반하고 있다.단순하게 이해해보자.서블렛은 위에서 요청, 반환의 과정을 처리해주는 자바 인터페이스였다.인증/인가/보안은 어떠한 요청이 들어오면 해당 요청이 적합한 유저이며, 권한이 있고, 보안상 안전한지 평가하는 것을 의미한다.즉 서블렛에 필터를 씌우는 과정이 필요하다.흔히 스프링 어플리케이션을 띄우면 컨트롤러가 그 요청을 받아서 처리하게 되는데,그 이전에 서버딴에서는 was(= 톰캣)에서 우선적으로 네트워크 요청을 처리한다.따라서 컨트롤러에 요청이 도달하기 전에 서블렛 컨테이너에 먼저 요청을 보게 된다.스프링 시큐리티는 was가 요청을 받으면서 해당 요청이 컨트롤러에 도달하게끔 하는 서블렛위에 필터를 씌운다.실제로 스프링 시큐리티를 프로젝트에 적용을 시켜보면, 컨트롤러에 로그를 찍어놔도로그가 찍히기 전에 요청이 차단되거나 하는 현상을 확인할 수 있다.밑의 이미지는 스프링 시큐리티 공식 문서의 스프링 시큐리티 아키텍처이다.클라이언트의 요청이 서블렛에 닫기 전에 필터 체인을 거치는 모습을 볼 수 있다.이렇게 생각해보면 무슨 생각이 드는가 ?개발자는 스프링 컨트톨러 딴에서 인증/인가/보안에 관한 개발을 상당히 덜 할 수 있게 될것이다.필터 설정만 잘 해주면 된다.서블릿 필터 체인위의 그림에서 리퀘스트가 겪는 시나리오를 먼저 살펴보자. 클라이언트는 요청을 서버로 보낸다. 서블렛 컨테이너는 필터 다수 + 서블렛에 해당하는 필터 체인을 생성한다. 필터 체인을 거치면서 인증/인가가 처리되고 서블렛에 도달한다. 이 과정에서 HttpServletRequest가 생성된다. 서블렛이 리퀘스트의 HttpServletRequest를 생성 컨트롤러에게 전달한다. 비즈니스 로직 처리. HttpServletResponse에 담아서 반환하면 서블렛이 위의 객체를 was에게 전달. was가 네트워크로 통신을 쏜다.위와 같은 과정에서 필터들은 순서대로 처리된다.즉 필터의 순서는 매우 중요하다.필터를 어떤 순서로 설정하느냐에 따라서 컨트롤러가 받는 HttpServletRequest가 달라진다.개발자의 필터 구현그럼 개발자는 필터를 커스터마이징해야할 텐데 이걸 어떻게 할까 ?그건 밑의 그림을 보자.기존의 필터 1이 DelegatingFilterProxy로 교체되어 있다.스프링이 제공하는 필터의 구현체가 이거다.기본적으로 필터는 스프링 빈으로 인식되지 못하기 때문에 이렇게 구현체를 만들 수 있게끔 이런 빈 대체용 필터를 제공한다.그러니까 빈 하나로는 안되니까 대체 필터를 만들고 거기에 빈을 넣으면 된다.수도 코드로 살펴보자.// 공식문서랑 똑같다 !public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) { // delegate는 스프링 빈을 필터로 만들어준다. 즉 커스터마이징한 필터를 만들 수 있게끔. Filter delegate = getFilterBean(someBeanName); // 필터링 delegate.doFilter(request, response);}자 근데 여기서 끝나기는 아쉽다.예를 들어서 개발자가 아 난 /api/v1/jk에는 필터 1,2,3번 걸고/api/v2/jk2에는 다른 필터들을 걸고 싶어라고 한다면 ?스프링 시큐리티에서는 FilterChainProxy와 SecurityFilterChain을 제공한다.그림을 보면 FilterChainProxy가 SecurityFilterChain을 사용하고,어떤 Spring security filter가 발동할지 결정한다.다음과 같이 요청의 종류에 따라서 다른 필터들을 거치게 할 수 있다.생각해보자. 이건 필수적으로 해야되는 사항이다.우리가 스프링 시큐리티를 사용하지 않고 인증/인가를 구현한다고 했을때,각 api마다 특성이 다르기때문에 = 로그인안해도 사용가능, 로그인해야지 사용가능각 컨트롤러에서는 인증/인가 로직을 다르게 구현해야 하는데,FilterChainProxy와 SecurityFilterChain을 사용해서 상황에 맞게 인증/인가를 설정할 수 있게 된다.##정리여기까지 해서 Spring Security의 정말 잘 추상화된 구조를 살펴봤다.다음에는 구체적으로 들어가서 설명해볼 생각이다.코드 구현까지하면 언제 끝날지 모르겠다.." }, { "title": "Copy의 종류", "url": "/posts/Copy%EC%9D%98%EC%A2%85%EB%A5%98/", "categories": "Python", "tags": "Python, 알고리즘", "date": "2022-02-07 00:00:00 +0800", "snippet": "shallow copy vs deep copy파이썬으로 심심할때 알고리즘 문제를 풀다가정말 당황스러운 상황에 직면한적이 있었다.문제는 이 카피 메소드에 대한 낮은 이해였는데이번 기회에 copy의 종류를 알아보고 정리해본다.Copy에는 두 종류가 있다. shallow copy는 주소값을 복사하는것. deep copy는 실제값을 새로운 메모리 공간에 부여하는 것.어떤 copy인지 모르고 생각없이 객체나 자료형을 복사하면아주 큰 이슈가 발생할 수도 있다.Shallow Copy예를 들어서 이런 코드가 있다고 해보자.실제로 내가 만들었다가 상당히 당황했던 코드다.list1 = [[0,1,2,3]] * 100 list2 = [[j for j in range(4)] for i in range(100)]여기서 하면 안되는 방법은 1번이다.첫번째 줄의 파이썬 코드는 shallow copy를 사용했다.만약에 이런 코드를 실행시킨다고 해보자.난 list1의 4번째 row 2번째 column의 해당하는 곳의 값을 5로 바꾸고 싶다. list1[4][2] = 5 이렇게 하고 list1을 프린트 찍어보면 어떻게 나올까…?for i in range(100): for j in range(4): print(list1[i][j], end=&quot; &quot;) print() 위와 같은 코드를 실행하면 놀랍게도 다음과 같은 결과가 나온다.[1,5,3,4][1,5,3,4][1,5,3,4] &#39; &#39; &#39;[1,5,3,4][1,5,3,4]실제로 겪어보면 내가 파이썬의 리스트 자체에 대해서 잘못 이해하고 있나라는 착각을 하기 쉽다.하지만 실제로는 간단한 원리이다.바로 방금 위에 list1의 선언은 shallow copy였기 때문이다.일단은 한번 주소값을 직접 찍어보자.print(id(list1[0]))print(id(list1[1]))print(id(list1[2][0]))print(id(list1[3][0]))print(id(list1[0][1]))print(id(list1[3][1]))결과는 다음과 같다.171228163782417122816378241712274893072171227489307217122748931041712274893104이렇게 생각하면 된다.처음 [1,2,3,4] 의 시작주소 = (첫번째 원소의 주소값)값을 1712281637824 이라고 한다면,list1의 내부 리스트들은 전부 이 주소를 참조하고 있다.여기서 하나의 원소만을 바꾼다고 프로그래머는 생각하겠지만실제로는 모든 원소, 즉 모든 리스트를 바꾸게 된다.정확히 말하면 프로그래머는 하나의 메모리 위치의 값을 바꿨다.그건 맞다. 그저 많은 리스트가 그 주소를 참조하고 있다는게 문제다.Deep CopyDeep Copy는 뭘까 ?shallow 하지 않다. 즉, 주소값만을 복사하는게 아니라실제로 객체 내부의 값을 다 복사하고 새로운 객체안에 넣어주는 복사다.새로운 객체안에 값이 들어가니까, 당연히 각 객체는 주소값이 다르다.deep copy는 원본의 데이터를 변경하거나 손상 시키고 싶지 않기 때문에 사용한다.새로운 객체에 내부 오브젝트들이 다 새롭게 메모리에 할당된다.파이썬으로 deep copy를 하는 방법은 여러가지인데,가장 많이 쓰는 방법 몇개만 소개해보면, maxVal = 10000 pleaseCopy = [[j for j in range(maxVal)] for i in range(maxVal)] copy 모듈의 deepcopy를 사용하는 방법 import copy list1 = copy.deepcopy(pleaseCopy) # 리스트안에 이중 for문 사용 list2 = [[j for j in i ] for i in pleaseCopy] 오브젝트의 copy 메소드 사용개발자가 커스텀하게 만드는 객체들은 모두 파이썬 object 클래스를 상속한다.object 클래스에는 copy()라는 매소드가 내장되어 있다. list3 = list() for i in pleaseCopy: temp = i.copy() list3.append(i) 시간으로 따지면 1번. time spent : 32.2756681442260742번. time spent : 2.6221497058868413번. time spent : 0.46498489379882813번이 압도적으로 빠르다.결국, deepcopy 매소드는 사용을 자제하자..복잡해도 시간 차이가 너무 심하다.그리고 pleaseCopy.copy()는 제대로 deepcopy되지 않는다.copy()는 리스트 내부의 리스트는 shallow copy가 되기 때문이다.정리원본의 데이터를 손상시키면 안되는 경우 deepcopy를 사용하고,손상시켜도 상관없다면 shallowcopy를 사용한다.deepcopy를 하는 경우 방법마다 시간이 다르기 때문에가장 효율적인 방법이었던 하나의 row를 copy()해서 append하는 방식을 선택하자." }, { "title": "JWT", "url": "/posts/JWT/", "categories": "인증/인가", "tags": "JWT, 인증/인가", "date": "2022-02-06 00:00:00 +0800", "snippet": "JWT (Json Web Token)늘 개발하면서 인증처리는 JWT를 사용했다.자연스럽게 사용했는데 구체적인 원리에 대해서 알아본적은 없다.JWT의 정체가 뭔지 이번에 한번 정리해보자.JWT가 뭘까 ?Json Web Token 말만 이해해보면,토큰 기반 인증에서 쓰이는 토큰의 종류인데 뭔가 json과 연관이 있는것 같다.클라이언트와 서버에서 json 객체를 사용해서 가벼우면서 자가 수용적인 방식으로 데이터를 전송하는것을 말한다.현대 웹 대부분이 사용하는 인터넷 표준 인증 방식이라고 볼 수 있다.기본적으로 유저인지 아닌지 파악은 세션과 동일하다.다른점은 JWT는 서명된 토큰이라는 점이다.간단하게 설명하면,“JWT = 데이터 + 서명” 일때,데이터는 누구나 베낄 수 있지만 서명은 그렇지 않다.정말로 서버에서 발급해준 토큰만이 올바른 서명을 가진다.따라서 데이터 자체는 탈취에 위험하다.JWT의 강점은 서명이다.JWT의 또다른 특징으로는 JWT는 자가 수용적이라는 것이다.자가 수용적이라는 말은 필요한 정보를 자체적으로 갖고 있다는 말이다.필요한 정보란 뭘까 ? 토큰에 대한 기본 정보 전송되는 데이터. 즉 클라이언트, 서버에서 인증에 사용하는 데이터. (로그인이라면 유저에 대한 데이터) 검증됐다는 것을 증명하는 signature.2번을 좀더 자세히 보자.토큰 인증 방식에서는 토큰안에 사용자의 정보가 암호화되서 들어가 있다.이 암호를 복호화하면 key-value의 형태로 데이터가 저장되있다.즉 json 형태로 verification용 데이터를 저장하고이걸 토큰으로 인코딩 + 암호화해서 서버에서 인증용으로 발급하는 방식이다.예를 들면 이런식이다.{ &quot;name&quot; : &quot;jk&quot;, &quot;address&quot; : &quot;집&quot;, &quot;status&quot; : &quot;피곤&quot;}같이 유저에 대한 정보를 담는 json을 해싱과 인코딩을 통해서 토큰으로 만든다.그러면 eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9이런식의 스트링이 만들어지고 이를 토큰으로 사용하게 된다.JWT가 현대 웹에서의 인증 표준처럼 쓰여지고 있다는데왜 그럴까 ?JWT의 특징JWT의 특징(장점)들을 알아보자. 많은 프로그래밍 언어, 프레임워크에서 지원한다.JWT 같은 경우, 대부분의 주류 프로그래밍 언어에서 지원된다. http 통신에서 용이하게 전달가능하다.헤더에 담을 수도. 쿼리 스트링에 파라미터로 담을 수도 있다.헤더에 담는다면 흔히 bearer token을 사용한다.bearer token과 OAUTH2에 대해서는 다음에 알아보자. self-contained하다.위에서 설명한 것처럼 session과는 다르게 유저에 대한 정보를 서버가 갖고 있지 않고토큰 그 자체가 들고 있다. 다수의 디바이스에서 용이하게 인증이 가능하다.sessionID가 디바이스가 달라지면서 공유되지 않는 반면에토큰은 그 자체가 데이터를 들고 있기 때문에 다른 기기에서 같은 토큰을 사용할 수 있다. 다수의 서버에서 용이하게 운영가능하다.요청이 들어오면 L4 로드밸런서에 의해서 각각의 서버로 요청이 분배되는데, session을 사용한다면각 서버에서 sessionID : user 의 key-pair 데이터가 공유되어야 한다. `세션 클러스터링이라고 하는 기술인데 이 기술에다가 추가로 sessionID를 쿠키에 담는다면 CORS문제도 신경써야 한다.반면에 토큰은 그 자체에 데이터가 있기 때문에 그런 수고로움을 갖지 않아도 된다.JWT의 사용 시나리오내가 JWT를 썻을때는 인증과 인가 처리었다.흔히 로그인을 할때 사용하게 되는데, 다음과 같은 시나리오로 JWT가 발급되고 사용된다. 유저가 로그인을 한다. (signIn api request 보냄.) 서버가 유저의 정보에 기반한 토큰을 발행해서 유저에게 전달한다. (signIn api의 반환) 그 후 유저가 로그인한 상태에서만 사용할 수 있는 기능(마이 페이지, 내 열람 목록, 내 구매 목록, 등등..)을 사용하기 위해api 를 사용한다면 request를 보낼때마다 JWT를 http에 담아서 보낸다. 서버는 해당 토큰이 유효한지 검증하고 권한이 있는지 확인해서(인가) 응답으로 response를 보낸다.JWT의 구조.JWT는 .을 기준으로 3가지 부분으로 나눠어져 있다.헤더(Header)header는 두가지의 정보를 갖고 있다.typ: 토큰의 타입을 지정한다. JWT이다.alg: 해싱 알고리즘을 지정한다.해싱 알고리즘으로는 주로 HMAC SHA256, RSA가 사용되며 이 알고리즘은 토큰을 검증할 때 사용되는 signature에서 사용된다. import json import base64 SECRET_KEY = &#39;secret_key&#39; ## header dictionary 선언 header = { &quot;typ&quot; : &quot;JWT&quot;, &quot;alg&quot; : &quot;HS256&quot; } ## header json stringify header_json = json.dumps(header, separators=(&#39;,&#39;,&#39;:&#39;)) ## encode to base64 encodedHeader = base64.urlsafe_b64encode(header_json.encode()) encodedHeader = encodedHeader.rstrip(b&#39;=&#39;) ## print header print(&quot;encoded header : &quot;,encodedHeader)헤더의 정보를 살펴보면, typ은 당연히 JWT이고, 해싱 알고리즘은 HMAC sha256을 지정해줬다.이 json을 stringify해서 문자열로 만든후, base64로 인코딩을 하면, header가 완성된다.b&#39;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9&#39; 참고! HMAC sha256과 sha256은 비밀키를 사용하냐 안하냐의 차이다. HMAC이 비밀키를 사용한다. 참고! byte encoding된 문자열에 = 가 존재할 수도 있는데, 이걸 base64의 padding문자라고 부른다. 이 패딩 문자를 jwt에서는 제거해줘야한다. 그 이유는 마지막에 나온다.내용(payload)토큰에 담을 정보가 포함된다. 여기에 담은 정보의 한 조각을 클레임(claim)이라고 부른다.이는 json 처럼 key-value pair의 구조를 가진다.토큰에는 여러개의 claim을 넣을 수 있다.클레임의 종류는 크게 세가지로 구분된다. 등록된(registered) 클레임 공개(public) 클레임 비공개(private) 클레임등록된 클레임은 규격으로 등록하는 거라고 보면 되고,공개, 비공개는 사용자가 커스텀하게 등록하는 클레임이라고 보면 된다.더 자세하게 알아보면,등록된 클레임등록된 클레임은 서비스에서 필요한 정보들이 아닌, 토큰에 대한 정보를 담기 위해서 이름이 이미 정해진 클레임이다.등록된 클레임의 사용은 선택적이다. 하지만 많은 경우 사용할 것을 권장한다.간단하게 생각하면 토큰에 대한 메타데이터이다.다음과 같은 종류가 있다. iss : 토큰 발급자 (issuer) sub : 토큰 제목 (subject) -&amp;gt; 주로 사용자 이메일을 사용하낟. aud : 토큰 대상자 (audience) exp : 토큰의 만료 시간(expiration), 포멧은 numericDate 형식이어야 하며 언제나 현재보다 이후로 설정되어야 한다. nbf : not before = 토큰의 활성 날짜. 여기도 numericDate 형식이고, 이 날짜가 지나기 전까지는 토큰이 처리되지 않는다. iat : 토큰이 발급된 시간(issued at), 이 값을 사용하여 토큰의 age가 얼마나 되었는지 판단할 수 있다. jti : JWT의 고유 식별자로서, 주로 중복적인 처리를 방지하기 위해 사용된다. 일회용 토큰에 사용하면 유용하다.공개 클레임사용자 정의 클레임으로 공개된 정보를 위해서 사용된다.공개 클레임은 충돌이 방지된(collision-resistant) 이름을 갖고 있어야 한다.사용자 정의 클레임이다.충돌을 방지하기 위해서는, 클레임 이름을 URI형식으로 짓는다.충돌 방지라는 건 공개 클레임간에 같은 이름을 갖는 경우를 말한다.따라서 클레임을 이름이 겹치지 않을 만한 이름 URI나 UUID, OID를 사용한다.{ &quot;https://hmcck27.github.io&quot; : true,}비공개 클레임등록된 클레임도 아니고, 공개된 클레임들도 아니다. 서버와 클라이언트 간의 협의된 데이터이다.여기에 유저의 데이터가 담긴다.{ &quot;username&quot;: &quot;jk&quot;, &quot;email&quot; : &quot;hmcck27@gmail.com&quot;}예제로 payload를 만들어보자.{ &quot;iss&quot; : &quot;hmcck27.github.io&quot;, &quot;sub&quot; : &quot;token for you&quot;, &quot;aud&quot; : &quot;jk&quot;, &quot;exp&quot; : &quot;지금 + 1일&quot;, &quot;iat&quot; : &quot;지금&quot;, &quot;https://hmcck27.github.io/jwt_claims/is_jk&quot; : true, &quot;username&quot;: &quot;jk&quot;, &quot;email&quot; : &quot;hmcck27@gmail.com&quot;}코드로 살펴보자.위와 같은 payload을 만든다고 가정해보자. import datetime ## payload 선언 payload = { &quot;iss&quot; : &quot;hmcck27.github.io&quot;, &quot;sub&quot; : &quot;token for you&quot;, &quot;aud&quot; : &quot;jk&quot;, &quot;exp&quot; : int((datetime.datetime.now() + datetime.timedelta(days=1)).timestamp()), &quot;iat&quot; : int(datetime.datetime.now().timestamp()), &quot;https://hmcck27.github.io/jwt_claims/is_jk&quot; : True, &quot;username&quot;: &quot;jk&quot;, &quot;email&quot; : &quot;hmcck27@gmail.com&quot; } ## json stringify payload_json = json.dumps(payload, separators=(&#39;,&#39;, &#39;:&#39;)) ## base 64 인코딩 encodedPayload = base64.urlsafe_b64encode(payload_json.encode()) encodedPayload = encodedPayload.rstrip(b&#39;=&#39;) print(&quot;encoded payload : &quot; , encodedPayload)encoded payload : b&#39;eyJpc3MiOiJobWNjazI3LmdpdGh1Yi5pbyIsInN1YiI6InRva2VuIGZvciB5b3UiLCJhdWQiOiJqayIsImV4cCI6MTY0Mzk0MTg1MSwiaWF0IjoxNjQzODU1NDUxLCJodHRwczovL2htY2NrMjcuZ2l0aHViLmlvL2p3dF9jbGFpbXMvaXNfamsiOnRydWUsInVzZXJuYW1lIjoiamsiLCJlbWFpbCI6ImhtY2NrMjdAZ21haWwuY29tIn0&#39;다음과 같이 잘 인코딩된다.자 여기서 하나 의문점이 들수도 있다.지금 payload를 만드는 걸 보니까, 단순하게 stringify + base64 인코딩이다.그리고 이렇게 만드는 방식이 JWT의 표준이다.?? 그러면 누가 헤더 뜯어서 Bear Token 뒤 문자열 가져와서 역순으로 base64디코딩하고 역직렬화하면 다 털리잖아 ? 그렇다.JWT의 payload는 암호화되지 않는다.그래서 payload에는 민감한 정보를 담아서는 안된다.중요한건 밑에 나올 signature이다.signatureJWT의 마지막 부분은 서명이다.이 서명은 header의 인코딩값과 payload의 인코딩값을 합친후 주어진 비밀키로 해쉬를 하여 생성한다.header와 payload를 합칠때에는 concatenate의 방식이고, 두 문자열 사이에 . 이 하나가 들어간다.위의 예시에서 합쳐진 string은 다음과 같다.&quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9&quot; + &quot;.&quot; + &quot;eyJpc3MiOiJobWNjazI3LmdpdGh1Yi5pbyIsInN1YiI6InRva2VuIGZvciB5b3UiLCJhdWQiOiJqayIsImV4cCI6MTY0Mzk0MTg1MSwiaWF0IjoxNjQzODU1NDUxLCJodHRwczovL2htY2NrMjcuZ2l0aHViLmlvL2p3dF9jbGFpbXMvaXNfamsiOnRydWUsInVzZXJuYW1lIjoiamsiLCJlbWFpbCI6ImhtY2NrMjdAZ21haWwuY29tIn0&quot;= eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJobWNjazI3LmdpdGh1Yi5pbyIsInN1YiI6InRva2VuIGZvciB5b3UiLCJhdWQiOiJqayIsImV4cCI6MTY0Mzk0MTg1MSwiaWF0IjoxNjQzODU1NDUxLCJodHRwczovL2htY2NrMjcuZ2l0aHViLmlvL2p3dF9jbGFpbXMvaXNfamsiOnRydWUsInVzZXJuYW1lIjoiamsiLCJlbWFpbCI6ImhtY2NrMjdAZ21haWwuY29tIn0이 값을 비밀키로 해싱을 하고 base64로 인코딩한다. import hashlib import hmac ## 두 인코딩 string 합치기 encodedHeaderPayload = encodedHeader + b&quot;.&quot; + encodedPayload ## 비밀키 세팅 secret_key = &quot;jk_sunfish&quot; # 해싱 + base64 인코딩 module = hmac.new(secret_key.encode(), encodedHeaderPayload, hashlib.sha256) digest = module.digest() crypted = base64.urlsafe_b64encode(digest) crypted = crypted.rstrip(b&quot;=&quot;) print(&quot;crypted : &quot; ,crypted) print(&#39;JWT : &#39;, encodedHeader + b&#39;.&#39; + encodedPayload + b&#39;.&#39; + crypted)출력은 다음과 같다.crypted : b&#39;NBWuqtdxrj2VNBS7xy5Nach30L9Qp4MFYIPijPLinuA&#39; JWT 통합이 3개의 파트를 합치면 완성된 jwt가 된다.한번 합쳐보고, 정말로 잘 토크나이징이 됐는지 검증해보자.3개를 합친 결과는 이러하다. JWT : b&#39;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJobWNjazI3LmdpdGh1Yi5pbyIsInN1YiI6InRva2VuIGZvciB5b3UiLCJhdWQiOiJqayIsImV4cCI6MTY0Mzk1MTAzOCwiaWF0IjoxNjQzODY0NjM4LCJodHRwczovL2htY2NrMjcuZ2l0aHViLmlvL2p3dF9jbGFpbXMvaXNfamsiOnRydWUsInVzZXJuYW1lIjoiamsiLCJlbWFpbCI6ImhtY2NrMjdAZ21haWwuY29tIn0.NBWuqtdxrj2VNBS7xy5Nach30L9Qp4MFYIPijPLinuA&#39;JWT를 잘 만들었는지 확인해보자 !https://jwt.io/ 에서 직접 확인해 볼 수 있다.잘 만들었다 !의문점다른 블로그 글과 문서들을 뒤적거리면서 해결되지 않았던 JWT의 여러 의문들에 대해서 정리해보자. url-safe하게 base64 인코딩 하는 이유위의 코드에서 단순히 base64.b64encode()를 사용하지 않았다. 이 메소드를 사용해서 해보면 제대로 signature가 만들어지지 않는다.왜냐하면 url-safe하지 않기 때문이다. url에서 예약어처럼 쓰이는 특수문자들이 있는데, url 값 자체에 그러한 특수문자들이 들어가면 안된다.그냥 base64인코딩하면 url-safe하지 않아서 “+”라던가 “/”, “=” 라던가의 특수문자들이 그대로 남아있다.url-safe하게 하면 이런 특수문자는 - 또는 _ 또는 공백으로 교체된다. 왜 payload는 암호화 안하는가 ? 아니 그냥 payload나 header도 암호화하면 안되요 ?해도 된다.개발자의 역량이고 클라이언트와 서버가 약속만 되어 있으면 상관없다. 근데 잘 생각해보자.우리는 인증을 구현하는데 JWT를 사용한다.인증이라는건 적합한 유저임을 서버가 알고 리소스를 내주는 것이다. 적합한 유저라는 건 서버가 직접 토큰을 내려준 유저를 의미한다.그리고 그걸 증명하는건 payload도 header도 아닌 signature이다. 간단한 예시.payload를 보고 서버는 생각한다. “아 너 이름이 개복치고, 이메일은 어쩌구라고 ?”signature를 보고 서버는 생각한다. “근데 너가 그렇다고 했는데 진짜 너인지 확인해보자 ! 너만 아는 퀴즈를 낼거야”의 프로세스이다. 따라서 굳이 payload나 header를 암호화할 필요는 없다 ! (하면 안된다가 아니다.)물론 한다면 클라이언트에서 암호화 + 서버에서 복호화하는 작업이 추가적으로 필요할 뿐이다. 공개 클레임은 도대체 뭐하는 클레임인가 ? 그럼 왜 공개 클레임과 비공개 클레임 ? 둘다 공개잖아.. 클레임 암호화 안되잖아 ! 실제로 이 이유에 대해서 말해주는 블로그 글이나 구글링해도 잘 안나와서 웹 rfc7519 표준을 뒤져봤다.JWT의 공식문서인데, 거기에 공개 클레임에 대해서 이렇게 설명한다. 클레임의 종류는 다른 관점으로 분류해보면 두가지 이다.충돌 가능 or 충돌 불가능여기서 충돌 가능은 비공개 클레임을 의미한다.비공개 클레임이 애초에 클라이언트와 서버의 멋대로 규칙이니까.근데 충돌 불가능한 클레임은 뭘까 ?여기서는 등록된 클레임과 공개 클레임을 말한다.등록된 클레임은 규격이다.근데 공개 클레임은 규격도 아니고 커스텀이다.?? 커스텀인데 어떻게 충돌이 안생겨 그니까 비공개는 다른 클라이언트-서버의 JWT랑 겹칠 수 있는것도 알아.등록된 클레임은 어차피 규격이니까 신경 안써도 돼.근데 공개 클레임은 겹칠수 없는건데 커스텀하다는 건 무슨 말이지 ? 갑자기 이상한 얘기로 새는데, 궁금해서 더 찾아봤다. 공개 클레임은 Collision-Resistant Name이라고 설명된다.collision-resistant name의 name은 namespace의 name이다. namespace가 뭐냐면 name들의 집합 + 각 개체에 name을 할당하는 시스템이다.namespace의 예시로 파일시스템은 파일에 이름을 할당하는 name space이다.namespace에는 collision-resistant namespace가 있는데 말 그래도 겹치지 않게 이름을 할당하는 namespace를 의미한다.네트워크라는 namespace는 웹에 연결된 개체 (컴퓨터, 서버, 핸드폰, 등등) 에게 name을 할당한다.그게 도메인, ip, 등등이 있다.그리고 이 name들은 전부 다르다.단 하나도 겹치는게 없다 !즉 collision-resistant 하다.위에서 공개 클레임의 예시로 도메인을 썻는데, 도메인은 collision-resistant하게 네트워크라는 namespace가 할당한 name이다.또 다른 공개 클레임의 예시로는 UUID, OID가 있다.다 겹치지 않는 친구들이다.그래서 공개 클레임은 커스텀한데 충돌은 없는 클레임이다. 뿌듯 정리직접 JWT를 만들어 봤는데 실제로 이런 과정을 직접 할 일은 없다.왜냐하면 대부분의 언어, 프레임워크에 JWT구현체가 있다. 그래도 직접 만들어 보는게 더 재밌다..!JWT가 세션의 문제점들을 모두 해결하고 현대 웹의 인증이 가진 모든 문제를 해결하는건 아니다.단점도 있다. 인코딩하니까 당연히 데이터가 뻥튀기된다. = 전달할 http 패킷의 바이트가 많아진다. = 속도 느림 = 손실 가능성 올라감 payload에는 민감한 정보를 못담는다. 토큰이 탈취당하면 만료될때까지 대처가 불가능하다.이 단점들을 해결하는 방법인유효시간과 재발급에 대해서는 다음에 정리해보자.여튼 끝 !" }, { "title": "토큰과 세션", "url": "/posts/%ED%86%A0%ED%81%B0%EA%B3%BC%EC%84%B8%EC%85%98/", "categories": "인증/인가", "tags": "토큰, 세션, 인증/인가", "date": "2022-02-05 00:00:00 +0800", "snippet": "토큰 vs 세션앞서 인증을 하는 방법에는 토큰과 세션이 있다고 했다.둘의 원리, 차이점, 장단점에 대해서 정리해보자.왜 필요할까 ?서버와 클라이언트의 통신에는 인증과 인가가 존재한다.클라이언트는 인증된 유저여야 하며, 해당 요청에 대한 권한이 존재해야 한다.서버-클라이언트 통신에는 주로 HTTP 프로토콜을 사용하는데, 이 HTTP 프로토콜은 stateless하다.stateful하다는 것은 요청을 보낸 클라이언트의 속성을 저장하고 있다는 의미이다.반대로 stateless라는 뜻은 기본적으로 http통신에 아무런 조치를 하지 않으면 서버는 누가 요청을 보냈는지 모른다는 의미이다.stateless하기 때문에 누가 요청을 보냈는지 별도로 확인 작업을 해줘야 한다.그게 인증/인가 작업이 필요하다.귀찮게 왜 stateless를 사용하는지는 다음에 http에 대해서 정리하면서 알아가보자.이 인증을 관리하는 방식에는 두가지 방식이 있는데,그게 바로 토큰과 세션이다.1. 세션기반 인증세션 기반 인증을 위해서는 session과 cookie가 사용된다.session과 cookie는 뭘까 ?위에서 우리는 http는 stateless하다고 했다.서버와 클라리언트는 한번 연결됬다고 그 연결상태를 저장하지 않는다.따라서 http를 보낼때 뭔가 추가적으로 담아서 보내거나 서버에서 그 추가된 무언가를 확인하는 데이터가 없다면,서버는 누구의 요청인지 절대로 모를것이다.따라서 클라이언트와 서버는 누구인지 확인하기 위해서 별도로 뭔가를 저장하게 되는데,클라이언트가 저장하는게 쿠키, 서버가 저장하는게 세션이다.세션 기반 인증이 어떻게 진행되는지 flow를 살펴보자. 유저는 로그인을 시도한다. 서버는 적합한 유저임을 확인하고, {sessionId : 멤버정보} key-value를 세션저장소에 저장한다. 그리고 그 sessionId를 클라이언트에게 반환한다. 클라이언트(브라우저)는 응답을 받아서 cookie에 sessionId를 저장한다. 이제 클라이언트는 요청에 sessionId를 cookie에 담아서 보내기 시작한다. 서버는 sessionId를 받고 아까 로그인한 유저임을 확인하고 로그인을 요구하지 않게 된다. 로그아웃 버튼을 누르게 되면 서버는 sessionId를 삭제한다.stateless하기 때문에 별도로 데이터를 저장하고 비교하는 작업을 거치는 것이다.세션 기반 인증의 장점 클라이언트가 가진 sessionId는 그냥 key값이고, value(회원정보)는 실제로 서버가 들고 있다. 누군가가 sessionId를 알아도 어떤 유저인지 확인하기 어렵기 때문에 보안에 유리하다. 구현 방법이 명확하다.세션 기반 인증의 단점 sessionId를 서버 메모리에 저장해야한다. 모종의 이유로 메모리가 터지거나 하면, 큰일난다. 메모리에 저장되기 때문에 서버를 교체할때 메모리를 잘 교체해야 한다. 서버의 수가 두대 이상으로 늘어나면, 여러 서버가 공유할 수 있는 메모리에 저장해야 한다. -&amp;gt; 세션 클러스터링이라고 한다. 하나의 유저가 여러 기기로 접속하면 서버에서는 계속해서 재로그인을 요구하게 된다. 유저는 하나인데 sessionID는 기기별로 다르니까.정리하면, 좋은 방법이지만 이제는 많이 사용하지 않는 방식이다. 보안이 중요해서 하나의 기기만 접속해야 하는 환경이거나 유저가 많이 없고 서버의 성능, 서비스의 트래픽 부하가 늘지 않는다면 사용해도 괜찮을것 같다.(실제로는 이렇게 까지 고려해서 쓰지는 않고 그냥 될것 같으면 쓴다.) 반성중이다.2. 토큰 기반 인증위의 세션기반 인증의 단점들은 사실 sessionId를 서버에 저장하기 때문에 발생하는 일이다.서버가 아무 정보도 안들고 있으면 다 없어질 문제점들이다.토큰은 세션의 이러한 문제점을 해결한다.즉 서버는 유저의 정보를 저장하지 않는다.토큰을 발행하는 대표적인 방법은 JWT이다.JWT는 json web token의 줄임말인데 현대 웹서비스의 인증은 대부분 jwt를 통해서 이뤄진다.JWT는 복잡하기 때문에 나중에 그 원리에 대해서 정리할 예정이다.토큰기반 인증은 다음과 같은 flow로 진행횐다. 유저는 로그인을 시도한다. 서버는 적합한 유저임을 확인하고 클라이언트에게 토큰을 발급한다. 클라이언트(브라우저)는 받은 토큰을 저장한다. 클라이언트는 매 요청시 발급 받은 토큰을 header에 포함시켜 전송한다. 서버는 요청이 오면 header의 토큰을 통해 적합한 유저인지 확인하고 권한을 준다. 앞으로 클라이언트는 매 요청마다 토큰을 통해서 내가 어떤 유저인지 서버에게 알릴 수 있다.자 여기서 생기는 의문은 서버는 토큰을 보고 어떤 유저인지 어떻게 알까 ?토큰은 보통 그냥 아주 긴 랜덤 스트링이다.JWT에 대해서 간단한 설명을 하면,JWT에는 사용자 정보가 담겨있다.물론 암호화된 상태이다.그리고 이 토큰이 어떻게 암호화됬는지 그 방식을 보낸다.복호화를 위한 키는 서버가 갖고 있다.복호화하지 않아도 어떤 유저인지는 알 수 있지만,진짜 해당 유저인지 확인하는 건 복호화를 통해서 진행된다.토큰 기반 방식의 장점 클라이언트만 정보를 갖고 있으니 서버를 늘리거나 교체하거나 해도 부담이 없다. 여러개의 기기로 접속해도 동일한 토큰을 갖게되니 문제가 없다.토큰 기반 방식의 단점 클라이언트가 정보를 들고 있으니 토큰이 손상될 위험이 있다. 서버가 토큰을 어떻게든 처리해줘야 한다.복호화라던가 갱신이라던가 악의적으로 탈취되면 블락한다던가… sessionId보다 길다.정리인증을 구현하는 두가지 방법인 세션과 토큰에 대해서 알아보았다.어떤걸 사용할지는 이 서비스에게 어떤 방식이 더 적합할지 개발자가 판단해야 한다.판단 기준은 당연히 위에 적은 장단점이다.난 둘다 해봤는데, 스프링 시큐리티를 사용하면 세션, 토큰 둘다 편하게 구현이 가능하다.하지만 난 토큰을 좀 더 선호한다.최근에는 많은 트래픽을 처리하는 문제가 나에게는 중요하기 때문이다.트래픽 처리 = scaleout, scaleup, msa -&amp;gt; 서버의 분산, 교체가 잦을 수 있다.세션을 사용하면 골치 아플수도 있다.그럼 끝 !" }, { "title": "인증과 인가", "url": "/posts/%EC%9D%B8%EC%A6%9D%EA%B3%BC%EC%9D%B8%EA%B0%80/", "categories": "인증/인가", "tags": "인증, 인증/인가, 인가", "date": "2022-02-04 00:00:00 +0800", "snippet": "인증과 인가어플리케이션을 개발할때, 로그인 기능이 필요하다면우리는 회원가입, 로그인 기능을 개발한다.나도 실제로 서비스를 개발하면서 회원가입, 로그인을 개발할 일이 있었는데자세하게 정리해본 적이 없어서 이번 기회에 정리해보려 한다.인증/인가에 대해서 먼저 알아보자.인증과 인가는 무엇이 다를까 ?간단한 예시를 들어 생각해보자.내가 직장 상사의 집에 초대받았다.직장 상사는 내 얼굴과 이름을 알고있다.문을 두드리고 직장 상사는 나를 확인하고 들어간다.(여기까지가 인증이다.)집에 들어온 나는 거실에 있다.상사의 집에 초대됬으니 함부로 다른 방에 들어가서는 안된다.이 집에서 내 신분은 손님이다.함부로 집에서 돌아다니면 앞으로 내 직장생활이 평탄하지 못할 것이다.즉 난 직장 상사 집의 안방같은 private한 공간은 들어갈 수 없다.나에게 허락된 공간은 거실과 주방이다.(이게 인가이다.)인증유저가 누구인지 파악하는 절차즉 회원가입하고 로그인하는 것.회원가입의 과정은 ID과 Password를 생성한다. password를 암호화해서 DB에 저장한다.로그인의 과정은 유저가 자신의 ID와 password를 입력한다. ID-password pair가 실제로 DB에 존재하는지 확인한다. 존재한다면 로그인이 성공되고 해당 유저에게 토큰/세션을 준다. 존재하지 않는다면, 로그인이 실패한다. 발행된 토큰/세션은 유저에 요청에 첨부되어 서버에 요청을 보내서 매번 로그인하는 과정을 생략할 수 있다.이게 인증의 과정이다.토큰과 세션 대표적으로 두가지 방법이 있는데현대 웹서비스에서는 토큰을 주로 사용하고, 토큰을 발행하는 대표적인 방법은 JWT이다.JWT에 대해서는 다음에 더 자세히 정리해보자. -&amp;gt; JWT란 뭘까 ?인가유저가 요청에 대한 권한이 있는지 확인하는 것.애플리케이션에 요청을 보내는 클라이언트가 누구이고 언제 어떻게 요청을보내고 있는지 알기 위해서 인증/인가를 구현한다.기본적으로 로그인을 해야만 사용할 수 있는 기능들은인증/인가를 동반한 api를 사용하게 된다.흔히 role이라고 하는데 예를 들어서 유저를 삭제 처리하는 api가 있다고 해보자.해당 유저를 삭제하는 api를 다른 유저가 사용할 수 있다면 난리가 날것이다.유저를 삭제하는 이 api는 유저가 아닌 관리자 role을 가진 사람만 사용할 수 있다.이 role을 확인해서 해당 리소스를 사용할 권한이 있는지 확인하는게 인가이다.정리인증과 인가는 어느 서비스를 개발하던 꼭 필요한 부분이다.현대 웹에서의 보안이 중요한 이슈로 떠오르고 있고인증과 인가에 대해서는 어느정도 표준이 정해진듯 하다.이번에 인증과 인가가 정확히 뭔지 알아봤다.그리고 인증과 인가는 워낙 중요한 필드라서 키워드 중심으로 정리해볼 생각이다.일하는 곳에서 인증/인가에 해당하는 부분을 리팩토링할 일이 생길것 같아서이번 기회에 싹 정리해본다.키워드 : 토큰vs세션, JWT, Oauth2, Spring security 다음과 같은 순서로 정리해볼 생각이다.끝 !" }, { "title": "동기 vs 비동기", "url": "/posts/%EB%8F%99%EA%B8%B0%EC%99%80%EB%B9%84%EB%8F%99%EA%B8%B0/", "categories": "운영체제, 동기와 비동기", "tags": "동기, 비동기", "date": "2022-02-03 00:00:00 +0800", "snippet": "Synchronous vs Asynchronous 데이터를 어떻게 처리할까 ?동기, 비동기에 대해서 실제로 면접에서 질문을 받았었다.하지만 명확하게 대답하지 못해서 너무 아쉬워서 한번 정리해보고자 한다.동기, 비동기에 대해서 검색해보면 흔히 다음과 같은 예시를 본다.동기는 한줄에 주루룩 사람들이 서서 업무를 처리하는 것을 말한다면,비동기는 여러 줄에서 동시에 사람들의 다른 업무를 처리한다.일단은 그림에서는 카페니까 어떤 방식이 효율적일까 ?당연히 비동기 방식 2번째 방식이 효율적이다.동기로 일하면 커피가 나오는데는 시간이 소모되고, 해당 시간동안 다른 업무를 처리하지 못한다.클라이언트가 서버에게 요청을 보냈을때,동기라면 클라이언트는 서버가 응답을 내려줄 때까지 기다린다.비동기는 요청을 보내고 다른 작업을 하다가 응답이 내려오면 다시 기존 작업으로 돌아간다.동기 Synchronous동기방식은 서버에서 요청을 보냈을 때 응답이 돌아와야 다음 동작을 수행할 수 있다.즉 A작업이 모두 진행 될때까지 B작업은 대기해야 한다.작업들은 마치 큐의 작동방식처럼 차례대로 들어가서 차례대로 처리된다.특정 하나의 작업이 실행중이면 다른 작업들은 대기하게 된다.비동기 Asynchronous비동기 방식은 반대로 요청을 보냈을 때 응답과 상관없이 다음 동작을 수행 할 수 있다.즉 A작업이 시작하면 동시에 B작업이 실행된다.A작업은 결과값이 나오는대로 출력된다.작업들은 동시에 진행되는 듯하지만 실제로는쓰레드가 이리저리 작업하는 프로세스를 교체하면서 기다리는 시간은 줄인다.파이썬은 asyncio를 사용하고, 자바에서는 multi-thread를 활용한다.일단은 왜 비동기를 사용해야 할까 ?예를 들어서, 서버딴에서 여러 사이트를 스크래핑하고 싶다.이 사이트들은 무제한적으로 하나의 ip에서 많은 request를 보내도 block당하지 않는다.그렇다면 우리는 어떤 로직으로 스크래핑을 해야할까 ?우선은 동기적으로 request를 보내본다고 가정하자.동기적으로 진행한다면 웹사이트에서 응답을 내려주는 시간동안 서버는 놀게 된다.비동기적으로 진행한다면 웹사이트에서 응답을 내려주는 시간동안 기존 응답의 html을 파싱한다.즉 여러개의 작업을 순차적으로 진행하는 것보다 비동기로 휴식시간이 없게 진행해야지 효율적이다.public class Async { public static void main(String[] args) { Thread req1 = new Thread(() -&amp;gt; { String res = req(&quot;www.mySite1.com&quot;); System.out.println(&quot;res = &quot; + res); }); Thread req2 = new Thread(() -&amp;gt; { String res = req(&quot;www.mySite2.com&quot;); System.out.println(&quot;res = &quot; + res); }); Thread req3 = new Thread(() -&amp;gt; { String res = req(&quot;www.mySite3.com&quot;); System.out.println(&quot;res = &quot; + res); }); Thread req4 = new Thread(() -&amp;gt; { String res = req(&quot;www.mySite4.com&quot;); System.out.println(&quot;res = &quot; + res); }); Thread req5 = new Thread(() -&amp;gt; { String res = req(&quot;www.mySite5.com&quot;); System.out.println(&quot;res = &quot; + res); }); req1.start(); req2.start(); req3.start(); req4.start(); req5.start(); } public static String req(String url) { /** * 1. 요청을 보내고 * 2. html을 파싱하고 * 3. 데이터를 정제해서 리턴하는 과정 */ return new String(url + &quot; 을 처리 완료했습니다.&quot;); }}해당 코드는 5개의 쓰레드를 만들어서 각 사이트를 총 다섯번 스크래핑했다.동기적으로 작동한다면 당연히 순차적으로 사이트1부터 사이트5까지 스크래핑할것이다.JAVA의 Multi-thread는 각 쓰레드의 실행을 비동기로 처리하기 때문에결과는 다음과 같다.순차적으로 처리가 되지 않았다.물론 이건 자바의 스케쥴러가 처리 순서를 결정하기 때문에실행하는 환경, 시간에 따라서 결과가 다르다.그렇다면 시간 차이는 어느정도 걸릴까 ?// 비동기public class Async { public static void main(String[] args) { Thread req1 = new Thread(() -&amp;gt; { String res = null; try { res = req(&quot;www.mySite1.com&quot;); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;res = &quot; + res); }); Thread req2 = new Thread(() -&amp;gt; { String res = null; try { res = req(&quot;www.mySite2.com&quot;); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;res = &quot; + res); }); Thread req3 = new Thread(() -&amp;gt; { String res = null; try { res = req(&quot;www.mySite3.com&quot;); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;res = &quot; + res); }); Thread req4 = new Thread(() -&amp;gt; { String res = null; try { res = req(&quot;www.mySite4.com&quot;); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;res = &quot; + res); }); Thread req5 = new Thread(() -&amp;gt; { String res = null; try { res = req(&quot;www.mySite5.com&quot;); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;res = &quot; + res); }); long beforeTime = System.currentTimeMillis(); //코드 실행 전에 시간 받아오기 req1.start(); req2.start(); req3.start(); req4.start(); req5.start(); try{ // 스레드 종료 대기 req1.join(); req2.join(); req3.join(); req4.join(); req5.join(); } catch (InterruptedException e) { e.printStackTrace(); } long afterTime = System.currentTimeMillis(); // 코드 실행 후에 시간 받아오기 long secDiffTime = (afterTime - beforeTime)/1000; //두 시간에 차 계산 System.out.println(&quot;시간차이(m) : &quot;+secDiffTime); } public static String req(String url) throws InterruptedException { /** * 1. 요청을 보내고 * 2. html을 파싱하고 * 3. 데이터를 정제해서 리턴하는 과정 */ Thread.sleep(2000); return new String(url + &quot; 을 처리 완료했습니다.&quot;); }}해당 요청에 걸리는 시간은 다음과 같다.동기로 보내면 어떨까?뭐 다 예상하겠지만 2초 걸리는걸 5번보냈으니 10초다.public class Sync { public static void main(String[] args) throws InterruptedException { long beforeTime = System.currentTimeMillis(); //코드 실행 전에 시간 받아오기 String res1 = req(&quot;www.mySite1.com&quot;); System.out.println(&quot;res1 = &quot; + res1); String res2 = req(&quot;www.mySite2.com&quot;); System.out.println(&quot;res2 = &quot; + res2); String res3 = req(&quot;www.mySite3.com&quot;); System.out.println(&quot;res3 = &quot; + res3); String res4 = req(&quot;www.mySite4.com&quot;); System.out.println(&quot;res4 = &quot; + res4); String res5 = req(&quot;www.mySite5.com&quot;); System.out.println(&quot;res5 = &quot; + res5); long afterTime = System.currentTimeMillis(); // 코드 실행 후에 시간 받아오기 long secDiffTime = (afterTime - beforeTime)/1000; //두 시간에 차 계산 System.out.println(&quot;시간차이(m) : &quot;+secDiffTime); } public static String req(String url) throws InterruptedException { /** * 1. 요청을 보내고 * 2. html을 파싱하고 * 3. 데이터를 정제해서 리턴하는 과정 */ Thread.sleep(2000); return new String(url + &quot; 을 처리 완료했습니다.&quot;); }}결과는 다음과 같다.정리그렇다고 항상 비동기가 좋은건 아니다. 멀티 쓰레딩 환경에서는 쓰레드가 공유하는 변수를 바꾸거나 등등의 일이 있다면 원하는 결과를 못 얻을 수 있다.(스프링 같은 경우에서 singleton 객체에서 state를 바꾸면 안된것처럼) 디버깅이 힘들다. 비동기는 언제 해당 프로세스가 처리되는지 개발자가 알기가 힘들다. 설계가 복잡하다.등의 문제가 있으니, 언제 비동기를 써야 할까 충분한 고민을 하고 사용해야 한다.나같은 경우에는 예전에 하던 서비스에서 pdf에 워터마크를 박는데 비동기를 사용했었다.워터마크를 커스텀하게 박아야하고 pdf 용량도 커서 시간이 많이 걸렸다.이런 작업에는 비동기를 써서 메인 쓰레드를 잡아먹지 않게해줘야 한다.안그러면 계속 저거만 하다가 다른 요청 들어왔을때 느리게 처리하거나 한다.끝 !" }, { "title": "💻마크다운 사용법 정리", "url": "/posts/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4-%EC%82%AC%EC%9A%A9%EB%B2%95-%EC%A0%95%EB%A6%AC/", "categories": "마크다운", "tags": "마크다운", "date": "2022-02-02 00:00:00 +0800", "snippet": " 💪개발자가 익숙해져야 할 핵심 문서 에디터 !ㄴ라고 다들 알고계시겠지만, 정작 많은 사람들이 마크다운을 사용하는 가장 큰 이유는 모르는것 같습니다 !ㄴ사실 그게 접니다. 왜 마크다운을 사용할까 ? 마크다운을 어떻게 사용할까 ?에 대해서 정리해보겠습니다.1. 마크 다운이란 ?개발을 하면서 .md 형식의 파일을 많이 보셨을 겁니다. 벨로그 글도, 깃헙의 README도 마크다운이죵. 간단하게 생각하면 텍스트 파일이라고 보셔도 됩니다. 거기에 다양한 포멧 적용과 링크등을 곁들인…Markdown은 마크업 언어로 간단한 기호를 사용해서 읽고 쓰기 편한 문서를 만들 수 있으며, HTML과 상호 변환이 가능합니다.많은 개발자 분들이 개발 명세, 개발한 코드에 대한 설명을 정리할때, 마크다운을 사용하고 계시죠.개발자 라면 ! 소통, 메모, 협업 문서 작성을 마크다운으로 할 줄 알아야 합니다. 참고 : 마크업 언어가 뭔가요 ?자, 정리하면 markdown은 개발자들이 굉장히 많이 쓴다. 사용하기 편하다. HTML과 상호 변환이 가능하다. 텍스트로 저장되기 때문에 용량이 적다. 버전 관리가 가능하다. 지원하는 툴이 많다.정도로 markdown을 사용하는 이유를 정리할 수 있겠습니다.2. 마크다운 툴 소개메모장부터 전용 에디터까지 다양한 곳에서 써볼 수 있습니다. atom, Typora 등등 다양한 에디터가 있습니다. 저 같은 경우는 시작할때는 Typora로 시작했습니다. 사실 함정은 Typora는 윈도우는 정식 버전이 있는데 맥은 정식 버전이 없어서 맥을 사용하게 되면서 자연스럽게 안쓰게 되더라구요.사실 대부분의 ide에서 다 마크다운이 제공되기 때문에, 저 같은 경우는 그냥 ide에서 작성을 합니다.ㄴ 뭐 다운받고 귀찮으시면, 그냥 편한 ide에서 하는게 제일 좋은 것 같습니다. atom 다운 : 여기서 !Typora 다운 : 여기서 !3. 마크다운 문법 정리1. HeaderHeader는 마크다운의 주제목 및 부제목등 제목을 설정할때 사용할 수 있습니다. H1~H6까지 가능합니다. HTML에서 사용하는 것과 비슷합니다. 주의할 점은 반드시 # 뒤에 한칸을 띄우고 작성을 해야합니다.입력# H1## H2### H3#### H4##### H5###### H6출력 H1 H2 H3 H4 H5 H62. 강조글을 쓸때 보면 이렇게 -&amp;gt; 기울임또는 이렇게 -&amp;gt; 굵게아니면 이렇게 -&amp;gt; 취소선텍스트 자체를 강조할 일이 있습니다.이때 사용하는 문법이 강조 문법이라고 할 수 있습니다.총 3가지가 있다고 보시면 됩니다. 텍스트 기울임, 텍스트 굵게, 텍스트 취소선 처리.입력*기울임*_기울임_**굵게**__굵게__**_굵은데 기울이기_**~~취소선~~출력 기울임기울임 굵게굵게 굵은데 기울이기취소선 3. 인용구인용구를 작성하고 싶다면 다음과 같이 사용하면 됩니다. 인용구라고 말하면, 인용한 것만 적어야 될것 같지만, 그냥 텍스트를 둘러싸는 칸, 블록을 따로 만든다고 생각하시면 됩니다. 강조하고 싶은 부분이 있거나, 따로 텍스트 블록을 만들고 싶으실때 사용하면 됩니다.입력&amp;gt; 나는 개발하는 개복치다. &amp;lt;br&amp;gt;###### *by 개복치*출력 나는 개발하는 개복치다. by 개복치*참고로 인용구 내부에서도 마크다운 문법이 적용됩니다.만약에 인용구내에서 다른 인용구를 들여쓰기 하고 싶다면 이렇게 하면됩니다.입력&amp;gt; 나는 개발하는 개복치다. &amp;lt;br&amp;gt;###### *by 개복치*&amp;gt;&amp;gt; 나는 공부하는 개복치이다.###### *by 개복치*&amp;gt;&amp;gt;&amp;gt; 나는 낡고 병든 개복치이다.###### *by 개복치* 탭을 쓰게되면 이렇게 인용 들여쓰기가 아닌 코드 블럭이 생성됩니다. 인용구 안에서는 또 다른 마크다운 문법이 사용가능합니다.출력 나는 개발하는 개복치다. by 개복치 나는 공부하는 개복치이다. by 개복치 나는 낡고 병든 개복치이다. by 개복치 탭을 쓰게되면 이렇게 인용 들여쓰기가 아닌 코드 블럭이 생성됩니다.인용구 안에서는 또 다른 마크다운 문법이 사용가능합니다. 4. 리스트마크다운을 사용하면 리스트(목록)을 간단하게 작성할 수 있습니다.두 종류의 리스트가 작성가능합니다. 순서(숫자)가 있는 목록 순서(숫자)가 없는 목록1)순서(숫자)가 있는 목록입력1. first2. second3. third4. fourth출력 first second third fourth 와 같이 보입니다. 그런데 이런 의문이 드실 수도 있습니다. “이거 그냥 내가 숫자 쓰면 되는거 아니야 ? 이게 왜 마크다운 기능이지..?”예를 들어서 다음과 같이 작성해보겠습니다.입력1. first2. second10. third8. fourth만약 사용자가 직접 숫자를 적는다면, 당연히 위와 같이 숫자를 혼동하거나, 역순으로 사용할 수도 있습니다. 그런데 마크다운에서는 저렇게 작성해도 알작딱깔하게출력 first second third fourth 이렇게 작성됩니다. 번호를 사용하게 되면 알아서 1씩 증가하는 올림차순으로 정렬됩니다.2) 순서(숫자)가 없는 리스트리스트의 인덱스를 숫자로 구성하지 않는 경우입니다.입력* 별 하나* 별 둘* 별 셋+ 더하기 하나+ 더하기 둘+ 더하기 셋- 빼기 하나- 빼기 둘- 빼기 셋출력 별 하나 별 둘 별 셋 더하기 하나 더하기 둘 더하기 셋 빼기 하나 빼기 둘 빼기 셋 만약에 리스트 안에 또 다른 리스트를 들여쓰기 하고 싶다면 ?입력1. 숫자 1 * 별 하나 * 별 둘 - 별 셋2. 숫자 2 1. 숫자 11 3. 숫자 22 * 별 하나하나3. 숫자 3출력 숫자 1 별 하나 별 둘 별 셋 숫자 2 숫자 11 숫자 22 * 별 하나하나 숫자 3 다음과 같이 리스트안에 리스트를 집어 넣을 수 있습니다. 근데 이거 굉장히 불편하다… 생각되로 잘 안됩니다.5. 링크마크다운 내부에 외부 링크를 삽입할 수 있습니다.[Title](link)의 형식으로 사용가능합니다.입력[구글 링크](https://google.com)출력 구글 링크입력https://google.com 와 같이 일반적인 URL 형태인경우 자동으로 링크를 형성합니다.출력 https://google.com 와 같이 일반적인 URL 형태인경우 자동으로 링크를 형성합니다.6. 코드 블럭코드 블럭을 사용하는 방법은 다양합니다. 탭 공백 4개 &amp;lt;code&amp;gt; 사용 ’’’ 사용4개의 공백 또는 하나의 탭으로 들여쓰기 또는 &amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;를 만나면 코드 블럭으로 렌더링됩니다.전 개인적으로 탭이나 공백으로 코드 블럭을 만들기보단, &amp;lt;code&amp;gt;를 사용합니다. 탭이나 공백은 잘 안되는 경우가 많습니다. ‘&#39;’은 뭔가 지저분한 느낌이구요.입력코드 블럭 시작 전입니다.&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt; @SpringBootApplicationpublic class SunfishDevApplication { public static void main(String[] args) { SpringApplication.run(SunfishDevApplication.class, args); }}&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;코드 블럭 끝입니다.출력 코드 블럭 시작 전입니다. @SpringBootApplicationpublic class SunfishDevApplication { public static void main(String[] args) { SpringApplication.run(SunfishDevApplication.class, args); }}코드 블럭 끝입니다.7. 수평선위와 같은 수평선을 사용할 수 있는 방법은 여러가지입니다.입력* * ******************************- - ------------------------------&amp;lt;hr/&amp;gt;출력 8. 이미지단순하게 이미지를 넣는 방법은 아래와 같습니다.![Alt text](/path/to/img.jpg)의 형식을 사용합니다. [] 안에는 비어있어도 상관없습니다. Alt text는 이미지의 alt 속성입니다. 그림이 렌더링 되지 않을때, 나타날 문자열을 지정합니다.입력이미지 삽입하기![개복치](https://images.velog.io/images/hmcck27/post/5f1cba37-6f70-43cc-84a1-1bf1c0f3472a/Mola_mola.jpeg)이미지 삽입 끝출력 이미지 삽입하기![개복치](https://images.velog.io/images/hmcck27/post/5f1cba37-6f70-43cc-84a1-1bf1c0f3472a/Mola_mola.jpeg)이미지 삽입 끝이미지의 크기를 조정하고 싶다면, HTML에 이미지의 크기를 조정하는 height, width를 사용하면 됩니다. 하지만 이건 HTML 문법을 쓰는거라서 밑에서 정리하겠습니다.이미지에도 링크를 걸 수 있습니다.이미지 삽입하기![개복치(https://images.velog.io/images/hmcck27/post/5f1cba37-6f70-43cc-84a1-1bf1c0f3472a/Mola_mola.jpeg)](https://images.velog.io/images/hmcck27/post/5f1cba37-6f70-43cc-84a1-1bf1c0f3472a/Mola_mola.jpeg)이미지 삽입 끝 이미지 삽입하기이미지 삽입 끝9. 기호 표시마크 다운 문법에 쓰이는 특수 기호들을 그대로 렌더링하고 싶으시다면, 역방향 슬래시를 붙이면 됩니다.ㄴ 문자열안에 “ 쓰고 싶어요..입력\\*\\_\\()\\{}\\[]\\#\\+\\-\\.\\!\\\\출력 *_(){}[]#+-.!\\10. 체크 박스 빈 체크박스입력- [ ] 빈 체크 박스 -&amp;gt; 중간에 공백출력 빈 체크 박스 -&amp;gt; 중간에 공백 체크된 체크박스입력- [X] 체크된 체크 박스 -&amp;gt; 대문자 X- [x] 체크된 체크 박스 -&amp;gt; 소문자 x출력 체크된 체크 박스 -&amp;gt; 대문자 X 체크된 체크 박스 -&amp;gt; 소문자 x 11. 이모지이모지를 사용하기 위해서 가장 편한 방법은 복붙입니다..! 물론 이모지 코드를 사용하면 됩니다.:joy:라고 쓰면, 😂 가 나오듯이요. 근데 벨로그에선 제가 모르는건지 안되네요.https://kr.piliapp.com/twitter-symbols/ 요기 링크에서 이모지를 찾아서 복붙하는 방식으로 하는걸 추천 드립니다.4. HTML 문법 사용하기마크다운의 강점은 HTML 문법이 사용가능하다는 겁니다. 하지만 무턱대고 쓰면 큰 코 다칠 수도 있습니다. 마크다운은 표준이 없거든요. 그 말인 즉슨, 될때고 있고, 안될 때도 있다…제가 생각하기에 굳이 마크다운 문법을 쓰지 않고 HTML로 쓰는게 편한 부분만 정리하겠습니다.1. 테이블입력&amp;lt;table&amp;gt; &amp;lt;tr&amp;gt; &amp;lt;td&amp;gt;Foo&amp;lt;/td&amp;gt; &amp;lt;/tr&amp;gt;&amp;lt;/table&amp;gt;출력 Foo &amp;lt;/table&amp;gt;2. 이미지위에서 마크다운 기능으로 이미지를 넣을 수 있었지만, 이미지의 크기 조정은 img 태그를 써서 해야 합니다 !픽셀 지정도 가능하고, HTML5에서 도입된 %도 가능합니다.입력이미지 삽입하기&amp;lt;img src=&quot;https://images.velog.io/images/hmcck27/post/5f1cba37-6f70-43cc-84a1-1bf1c0f3472a/Mola_mola.jpeg&quot; width=&quot;20%&quot; height=&quot;20%&quot;&amp;gt;이미지 삽입 끝출력 이미지 삽입하기이미지 삽입 끝ㄴ 벨로그 에디터에서는 작게 나오는데, 반영은 또 안되네요.3. 기타위에서 마크다운 기능을 설명할때, 제가 마구 HTML 태그를 썼습니다.당연히 이것들 전부 마크다운으로 가능합니다.입력수평선&amp;lt;hr&amp;gt;수평선 끝줄 바꿈 &amp;lt;br&amp;gt;줄 바꿈 끝출력 수평선수평선 끝줄 바꿈 줄 바꿈 끝뭐 등등 다 됩니다..! 애매하시면 그냥 써보고 되는구나 넘어가시면 될것 같습니다.5. 마치며서치해보면서 안거지만, 역시 마크다운을 설명하는 블로그 글이 정말 많습니다. 마크다운을 잘 못쓰는 사람들을 위해서 = 나를 위해서 정리해봤습니다. 참고 링크https://daringfireball.net/projects/markdown/syntaxhttps://www.markdownguide.org/extended-syntax/" } ]
